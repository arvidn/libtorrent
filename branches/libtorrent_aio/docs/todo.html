<html><head>
<script type="text/javascript">
/* <![CDATA[ */
	var expanded = -1
	function expand(id) {
		if (expanded != -1) {
			var ctx = document.getElementById(expanded);
			ctx.style.display = "none";
			// if we're expanding the field that's already
			// expanded, just collapse it
			var no_expand = id == expanded;
			expanded = -1;
			if (no_expand) return;
		}
		var ctx = document.getElementById(id);
		ctx.style.display = "table-row";
		expanded = id;
	}
/* ]]> */
</script>

</head><body>
<h1>libtorrent todo-list</h1>
<span style="color: #f00">0 urgent</span>
<span style="color: #f77">8 important</span>
<span style="color: #3c3">14 relevant</span>
<span style="color: #77f">12 feasible</span>
<span style="color: #999">72 notes</span>
<table width="100%" border="1" style="border-collapse: collapse;"><tr style="background: #fcc"><td>relevance&nbsp;3</td><td><a href="javascript:expand(0)">src/disk_io_thread.cpp:220</a></td><td>it would be nice to have the number of threads be set dynamically</td></tr><tr id="0" style="display: none;" colspan="3"><td colspan="3"><h2>it would be nice to have the number of threads be set dynamically</h2><h4>src/disk_io_thread.cpp:220</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	{
		DLOG("destructing disk_io_thread\n");

#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
		// by now, all pieces should have been evicted
		std::pair&lt;block_cache::iterator, block_cache::iterator&gt; pieces
			= m_disk_cache.all_pieces();
		TORRENT_ASSERT(pieces.first == pieces.second);
#endif

#ifdef TORRENT_DISK_STATS
		if (g_access_log)
		{
			FILE* f = g_access_log;
			g_access_log = NULL;
			fclose(f);
		}
#endif
	}

<div style="background: #ffff00" width="100%">	void disk_io_thread::set_num_threads(int i, bool wait)
</div>	{
		if (i == m_num_threads) return;

		if (i &gt; m_num_threads)
		{
			while (m_num_threads &lt; i)
			{
				int thread_id = (++m_num_threads) - 1;
				thread_type_t type = generic_thread;

				// the magic number 3 is also used in add_job()
				// every 4:th thread is a hasher thread
				if ((thread_id &amp; 0x3) == 3) type = hasher_thread;
				m_threads.push_back(boost::shared_ptr&lt;thread&gt;(
					new thread(boost::bind(&amp;disk_io_thread::thread_fun, this, thread_id, type))));
			}
		}
		else
		{
			while (m_num_threads &gt; i) { --m_num_threads; }
			mutex::scoped_lock l(m_job_mutex);
			m_job_cond.notify_all();
			m_hash_job_cond.notify_all();
			l.unlock();
			if (wait) for (int i = m_num_threads; i &lt; m_threads.size(); ++i) m_threads[i]-&gt;join();
			// this will detach the threads
			m_threads.resize(m_num_threads);
		}
	}

</pre></td></tr><tr style="background: #fcc"><td>relevance&nbsp;3</td><td><a href="javascript:expand(1)">src/peer_connection.cpp:2947</a></td><td>since we throw away the queue entry once we issue the disk job, this may happen. Instead, we should keep the queue entry around, mark it as having been requested from disk and once the disk job comes back, discard it if it has been cancelled. Maybe even be able to cancel disk jobs?</td></tr><tr id="1" style="display: none;" colspan="3"><td colspan="3"><h2>since we throw away the queue entry once we issue
the disk job, this may happen. Instead, we should keep the
queue entry around, mark it as having been requested from
disk and once the disk job comes back, discard it if it has
been cancelled. Maybe even be able to cancel disk jobs?</h2><h4>src/peer_connection.cpp:2947</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		std::vector&lt;peer_request&gt;::iterator i
			= std::find(m_requests.begin(), m_requests.end(), r);

		if (i != m_requests.end())
		{
			m_ses.inc_stats_counter(counters::cancelled_piece_requests);
			m_requests.erase(i);

			if (m_requests.empty())
				m_ses.inc_stats_counter(counters::num_peers_up_requests, -1);

#ifdef TORRENT_VERBOSE_LOGGING
			peer_log("==&gt; REJECT_PIECE [ piece: %d s: %x l: %x ]"
				, r.piece , r.start , r.length);
#endif
			write_reject_request(r);
		}
		else
		{
<div style="background: #ffff00" width="100%">#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_ERROR_LOGGING
</div>			peer_log("*** GOT CANCEL NOT IN THE QUEUE");
#endif
		}
	}

	// -----------------------------
	// --------- DHT PORT ----------
	// -----------------------------

	void peer_connection::incoming_dht_port(int listen_port)
	{
		INVARIANT_CHECK;

#ifdef TORRENT_VERBOSE_LOGGING
		peer_log("&lt;== DHT_PORT [ p: %d ]", listen_port);
#endif
#ifndef TORRENT_DISABLE_DHT
		m_ses.add_dht_node(udp::endpoint(
			m_remote.address(), listen_port));
#endif
	}

	// -----------------------------
	// --------- HAVE ALL ----------
	// -----------------------------

	void peer_connection::incoming_have_all()
	{
		INVARIANT_CHECK;

</pre></td></tr><tr style="background: #fcc"><td>relevance&nbsp;3</td><td><a href="javascript:expand(2)">src/piece_picker.cpp:3030</a></td><td>it would be nice if this could be folded into lock_piece() the main distinction is that this also maintains the m_num_passed counter and the passed_hash_check member</td></tr><tr id="2" style="display: none;" colspan="3"><td colspan="3"><h2>it would be nice if this could be folded into lock_piece()
the main distinction is that this also maintains the m_num_passed
counter and the passed_hash_check member</h2><h4>src/piece_picker.cpp:3030</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">#ifdef TORRENT_DEBUG
		check_piece_state();
#endif

#ifdef TORRENT_PICKER_LOG
		std::cerr &lt;&lt; "[" &lt;&lt; this &lt;&lt; "] " &lt;&lt; "lock_piece(" &lt;&lt; piece &lt;&lt; ")" &lt;&lt; std::endl;
#endif

		int state = m_piece_map[piece].state;
		if (state == piece_pos::piece_open) return;
		std::vector&lt;downloading_piece&gt;::iterator i = find_dl_piece(state - 1, piece);
		if (i == m_downloads[state - 1].end()) return;

		TORRENT_ASSERT(i-&gt;passed_hash_check == false);
		i-&gt;passed_hash_check = false;

		// prevent this piece from being picked until it's restored
		i-&gt;locked = true;
	}

<div style="background: #ffff00" width="100%">	void piece_picker::write_failed(piece_block block)
</div>	{
		TORRENT_PIECE_PICKER_INVARIANT_CHECK;

#ifdef TORRENT_DEBUG
		check_piece_state();
#endif

#ifdef TORRENT_PICKER_LOG
		std::cerr &lt;&lt; "[" &lt;&lt; this &lt;&lt; "] " &lt;&lt; "write_failed( {" &lt;&lt; block.piece_index &lt;&lt; ", " &lt;&lt; block.block_index &lt;&lt; "} )" &lt;&lt; std::endl;
#endif

		int state = m_piece_map[block.piece_index].state;
		if (state == piece_pos::piece_open) return;
		std::vector&lt;downloading_piece&gt;::iterator i = find_dl_piece(state - 1, block.piece_index);
		if (i == m_downloads[state - 1].end()) return;

		block_info&amp; info = i-&gt;info[block.block_index];
		TORRENT_ASSERT(info.piece_index == block.piece_index);
		TORRENT_ASSERT(info.state == block_info::state_writing);
		TORRENT_ASSERT(info.num_peers == 0);

		TORRENT_ASSERT(i-&gt;writing &gt; 0);
		TORRENT_ASSERT(info.state == block_info::state_writing);

		if (info.state == block_info::state_finished) return;
		if (info.state == block_info::state_writing) --i-&gt;writing;

		info.peer = 0;
		info.state = block_info::state_none;
		if (i-&gt;passed_hash_check)
</pre></td></tr><tr style="background: #fcc"><td>relevance&nbsp;3</td><td><a href="javascript:expand(3)">src/torrent.cpp:7131</a></td><td>if peer is a really good peer, maybe we shouldn't disconnect it</td></tr><tr id="3" style="display: none;" colspan="3"><td colspan="3"><h2>if peer is a really good peer, maybe we shouldn't disconnect it</h2><h4>src/torrent.cpp:7131</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">#if defined TORRENT_LOGGING || defined TORRENT_ERROR_LOGGING
		debug_log("incoming peer (%d)", int(m_connections.size()));
#endif

#ifdef TORRENT_DEBUG
		error_code ec;
		TORRENT_ASSERT(p-&gt;remote() == p-&gt;get_socket()-&gt;remote_endpoint(ec) || ec);
#endif

		TORRENT_ASSERT(p-&gt;peer_info_struct() != NULL);

		// we need to do this after we've added the peer to the policy
		// since that's when the peer is assigned its peer_info object,
		// which holds the rank
		if (maybe_replace_peer)
		{
			// now, find the lowest rank peer and disconnect that
			// if it's lower rank than the incoming connection
			peer_connection* peer = find_lowest_ranking_peer();

<div style="background: #ffff00" width="100%">			if (peer &amp;&amp; peer-&gt;peer_rank() &lt; p-&gt;peer_rank())
</div>			{
				peer-&gt;disconnect(errors::too_many_connections, peer_connection_interface::op_bittorrent);
				p-&gt;peer_disconnected_other();
			}
			else
			{
				p-&gt;disconnect(errors::too_many_connections, peer_connection_interface::op_bittorrent);
				// we have to do this here because from the peer's point of
				// it wasn't really attached to the torrent, but we do need
				// to let policy know we're removing it
				remove_peer(p);
				return false;
			}
		}

#if defined TORRENT_DEBUG &amp;&amp; !defined TORRENT_DISABLE_INVARIANT_CHECKS
		if (m_policy) m_policy-&gt;check_invariant();
#endif

		if (m_share_mode)
			recalc_share_mode();

		return true;
	}

	bool torrent::want_tick() const
	{
		if (m_abort) return false;

		if (!m_connections.empty()) return true;
</pre></td></tr><tr style="background: #fcc"><td>relevance&nbsp;3</td><td><a href="javascript:expand(4)">include/libtorrent/block_cache.hpp:201</a></td><td>could this be a scoped_array instead? does cached_piece_entry really need to be copyable? cached_piece_entry does need to be copyable since it's part of a container, but it's possible it could be a raw pointer or boost::unique_ptr perhaps</td></tr><tr id="4" style="display: none;" colspan="3"><td colspan="3"><h2>could this be a scoped_array instead? does cached_piece_entry really need to be copyable?
cached_piece_entry does need to be copyable since it's part of a container, but it's possible
it could be a raw pointer or boost::unique_ptr perhaps</h2><h4>include/libtorrent/block_cache.hpp:201</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		// on this piece to complete. These are executed at that point.
		tailqueue read_jobs;

		int get_piece() const { return piece; }
		void* get_storage() const { return storage.get(); }

		bool operator==(cached_piece_entry const&amp; rhs) const
		{ return storage.get() == rhs.storage.get() &amp;&amp; piece == rhs.piece; }

		// if this is set, we'll be calculating the hash
		// for this piece. This member stores the interim
		// state while we're calulcating the hash.
		partial_hash* hash;

		// set to a unique identifier of a peer that last
		// requested from this piece.
		void* last_requester;

		// the pointers to the block data. If this is a ghost
		// cache entry, there won't be any data here
<div style="background: #ffff00" width="100%">		boost::shared_array&lt;cached_block_entry&gt; blocks;
</div>
		// the last time a block was written to this piece
		// plus the minimum amount of time the block is guaranteed
		// to stay in the cache
</pre></td></tr><tr style="background: #fcc"><td>relevance&nbsp;3</td><td><a href="javascript:expand(5)">include/libtorrent/policy.hpp:103</a></td><td>this class should be renamed peer_list</td></tr><tr id="5" style="display: none;" colspan="3"><td colspan="3"><h2>this class should be renamed peer_list</h2><h4>include/libtorrent/policy.hpp:103</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		// these are used only by find_connect_candidates in order
		// to implement peer ranking. See:
		// http://blog.libtorrent.org/2012/12/swarm-connectivity/
		external_ip const* ip;
		int port;

		// this is set by policy::add_peer to either true or false
		// true means the peer we just added was new, false means
		// we already knew about the peer
		bool first_time_seen;

		// this must be set to a torrent_peer allocator
		torrent_peer_allocator_interface* peer_allocator;

		// if any peer were removed during this call, they are returned in
		// this vector. The caller would want to make sure there are no
		// references to these torrent_peers anywhere
		std::vector&lt;torrent_peer*&gt; erased;
	};

<div style="background: #ffff00" width="100%">	class TORRENT_EXTRA_EXPORT policy : single_threaded
</div>	{
	public:

		policy();

#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_LOGGING || defined TORRENT_ERROR_LOGGING
		static void print_size(logger&amp; l);
#endif

#if TORRENT_USE_I2P
		torrent_peer* add_i2p_peer(char const* destination, int src, char flags
			, torrent_state* state);
#endif

		enum
		{
			// these flags match the flags passed in ut_pex
			// messages
			flag_encryption = 0x1,
			flag_seed = 0x2,
			flag_utp = 0x4,
			flag_holepunch = 0x8,
		};

		// this is called once for every torrent_peer we get from
		// the tracker, pex, lsd or dht.
		torrent_peer* add_peer(const tcp::endpoint&amp; remote
			, int source, char flags, torrent_state* state);

		// false means duplicate connection
</pre></td></tr><tr style="background: #fcc"><td>relevance&nbsp;3</td><td><a href="javascript:expand(6)">include/libtorrent/kademlia/dht_tracker.hpp:80</a></td><td>take a udp_socket_interface here instead. Move udp_socket_interface down into libtorrent core</td></tr><tr id="6" style="display: none;" colspan="3"><td colspan="3"><h2>take a udp_socket_interface here instead. Move udp_socket_interface down into libtorrent core</h2><h4>include/libtorrent/kademlia/dht_tracker.hpp:80</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	struct counters;
}

namespace libtorrent { namespace dht
{

#ifdef TORRENT_DHT_VERBOSE_LOGGING
	TORRENT_DECLARE_LOG(dht_tracker);
#endif

	struct dht_tracker;

	TORRENT_EXTRA_EXPORT void intrusive_ptr_add_ref(dht_tracker const*);
	TORRENT_EXTRA_EXPORT void intrusive_ptr_release(dht_tracker const*);	

	struct dht_tracker : udp_socket_interface, udp_socket_observer
	{
		friend void intrusive_ptr_add_ref(dht_tracker const*);
		friend void intrusive_ptr_release(dht_tracker const*);

<div style="background: #ffff00" width="100%">		dht_tracker(libtorrent::aux::session_impl&amp; ses, rate_limited_udp_socket&amp; sock
</div>			, dht_settings const&amp; settings, counters&amp; cnt, entry const* state = 0);
		virtual ~dht_tracker();

		void start(entry const&amp; bootstrap);
		void stop();

		void add_node(udp::endpoint node);
		void add_node(std::pair&lt;std::string, int&gt; const&amp; node);
		void add_router_node(udp::endpoint const&amp; node);

		entry state() const;

		void announce(sha1_hash const&amp; ih, int listen_port, bool seed
			, boost::function&lt;void(std::vector&lt;tcp::endpoint&gt; const&amp;)&gt; f);

		void dht_status(session_status&amp; s);
		void network_stats(int&amp; sent, int&amp; received);

		// translate bittorrent kademlia message into the generic kademlia message
		// used by the library
		virtual bool incoming_packet(error_code const&amp; ec
			, udp::endpoint const&amp;, char const* buf, int size);

	private:
	
		boost::intrusive_ptr&lt;dht_tracker&gt; self()
		{ return boost::intrusive_ptr&lt;dht_tracker&gt;(this); }

		void on_name_lookup(error_code const&amp; e
			, udp::resolver::iterator host);
</pre></td></tr><tr style="background: #fcc"><td>relevance&nbsp;3</td><td><a href="javascript:expand(7)">include/libtorrent/kademlia/find_data.hpp:60</a></td><td>rename this class to find_peers, since that's what it does find_data is an unnecessarily generic name</td></tr><tr id="7" style="display: none;" colspan="3"><td colspan="3"><h2>rename this class to find_peers, since that's what it does
find_data is an unnecessarily generic name</h2><h4>include/libtorrent/kademlia/find_data.hpp:60</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">#include &lt;libtorrent/kademlia/node_id.hpp&gt;
#include &lt;libtorrent/kademlia/routing_table.hpp&gt;
#include &lt;libtorrent/kademlia/rpc_manager.hpp&gt;
#include &lt;libtorrent/kademlia/observer.hpp&gt;
#include &lt;libtorrent/kademlia/msg.hpp&gt;

#include &lt;boost/optional.hpp&gt;
#include &lt;boost/function/function1.hpp&gt;
#include &lt;boost/function/function2.hpp&gt;

namespace libtorrent { namespace dht
{

typedef std::vector&lt;char&gt; packet_t;

class rpc_manager;
class node_impl;

// -------- find data -----------

<div style="background: #ffff00" width="100%">class find_data : public traversal_algorithm
</div>{
public:
	typedef boost::function&lt;void(std::vector&lt;tcp::endpoint&gt; const&amp;)&gt; data_callback;
	typedef boost::function&lt;void(std::vector&lt;std::pair&lt;node_entry, std::string&gt; &gt; const&amp;, bool)&gt; nodes_callback;

	void got_peers(std::vector&lt;tcp::endpoint&gt; const&amp; peers);
	void got_write_token(node_id const&amp; n, std::string const&amp; write_token)
	{ m_write_tokens[n] = write_token; }

	find_data(node_impl&amp; node, node_id target
		, data_callback const&amp; dcallback
		, nodes_callback const&amp; ncallback
		, bool noseeds);

	virtual char const* name() const { return "get_peers"; }

	node_id const target() const { return m_target; }

protected:

	void done();
	observer_ptr new_observer(void* ptr, udp::endpoint const&amp; ep, node_id const&amp; id);
	virtual bool invoke(observer_ptr o);

private:

	data_callback m_data_callback;
	nodes_callback m_nodes_callback;
	std::map&lt;node_id, std::string&gt; m_write_tokens;
	node_id const m_target;
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(8)">src/file.cpp:1424</a></td><td>use vm_copy here, if available, and if buffers are aligned</td></tr><tr id="8" style="display: none;" colspan="3"><td colspan="3"><h2>use vm_copy here, if available, and if buffers are aligned</h2><h4>src/file.cpp:1424</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		CloseHandle(native_handle());
		m_path.clear();
#else
		if (m_file_handle != INVALID_HANDLE_VALUE)
			::close(m_file_handle);
#endif

		m_file_handle = INVALID_HANDLE_VALUE;

		m_open_mode = 0;
	}

	// defined in storage.cpp
	int bufs_size(file::iovec_t const* bufs, int num_bufs);
	
	void gather_copy(file::iovec_t const* bufs, int num_bufs, char* dst)
	{
		int offset = 0;
		for (int i = 0; i &lt; num_bufs; ++i)
		{
<div style="background: #ffff00" width="100%">			memcpy(dst + offset, bufs[i].iov_base, bufs[i].iov_len);
</div>			offset += bufs[i].iov_len;
		}
	}

	void scatter_copy(file::iovec_t const* bufs, int num_bufs, char const* src)
	{
		int offset = 0;
		for (int i = 0; i &lt; num_bufs; ++i)
		{
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(9)">src/file.cpp:1435</a></td><td>use vm_copy here, if available, and if buffers are aligned</td></tr><tr id="9" style="display: none;" colspan="3"><td colspan="3"><h2>use vm_copy here, if available, and if buffers are aligned</h2><h4>src/file.cpp:1435</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	}

	// defined in storage.cpp
	int bufs_size(file::iovec_t const* bufs, int num_bufs);
	
	void gather_copy(file::iovec_t const* bufs, int num_bufs, char* dst)
	{
		int offset = 0;
		for (int i = 0; i &lt; num_bufs; ++i)
		{
			memcpy(dst + offset, bufs[i].iov_base, bufs[i].iov_len);
			offset += bufs[i].iov_len;
		}
	}

	void scatter_copy(file::iovec_t const* bufs, int num_bufs, char const* src)
	{
		int offset = 0;
		for (int i = 0; i &lt; num_bufs; ++i)
		{
<div style="background: #ffff00" width="100%">			memcpy(bufs[i].iov_base, src + offset, bufs[i].iov_len);
</div>			offset += bufs[i].iov_len;
		}
	}

	bool coalesce_read_buffers(file::iovec_t const*&amp; bufs, int&amp; num_bufs, file::iovec_t* tmp)
	{
		int buf_size = bufs_size(bufs, num_bufs);
		// this is page aligned since it's used in APIs which
		// are likely to require that (depending on OS)
		char* buf = (char*)page_aligned_allocator::malloc(buf_size);
		if (!buf) return false;
		tmp-&gt;iov_base = buf;
		tmp-&gt;iov_len = buf_size;
		bufs = tmp;
		num_bufs = 1;
		return true;
	}

	void coalesce_read_buffers_end(file::iovec_t const* bufs, int num_bufs, char* buf, bool copy)
	{
		if (copy) scatter_copy(bufs, num_bufs, buf);
		page_aligned_allocator::free(buf);
	}

	bool coalesce_write_buffers(file::iovec_t const*&amp; bufs, int&amp; num_bufs, file::iovec_t* tmp)
	{
		// coalesce buffers means allocate a temporary buffer and
		// issue a single write operation instead of using a vector
		// operation
		int buf_size = 0;
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(10)">src/piece_picker.cpp:1899</a></td><td>m_downloads size will be > 0 just by having pad-files in the torrent. That should be taken into account here.</td></tr><tr id="10" style="display: none;" colspan="3"><td colspan="3"><h2>m_downloads size will be > 0 just by having pad-files
in the torrent. That should be taken into account here.</h2><h4>src/piece_picker.cpp:1899</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	//     ignores the prefer_whole_pieces parameter (as if
	//     it was 0)

	// only one of rarest_first, sequential can be set

	void piece_picker::pick_pieces(bitfield const&amp; pieces
		, std::vector&lt;piece_block&gt;&amp; interesting_blocks, int num_blocks
		, int prefer_whole_pieces, void* peer, piece_state_t speed
		, int options, std::vector&lt;int&gt; const&amp; suggested_pieces
		, int num_peers
		, counters&amp; pc
		) const
	{
		TORRENT_ASSERT(peer == 0 || static_cast&lt;torrent_peer*&gt;(peer)-&gt;in_use);

		// prevent the number of partial pieces to grow indefinitely
		// make this scale by the number of peers we have. For large
		// scale clients, we would have more peers, and allow a higher
		// threshold for the number of partials

<div style="background: #ffff00" width="100%">		if (m_downloads[0].size() &gt; num_peers * 3 / 2)
</div>		{
			// if we have too many partial pieces, prioritize completing
			// them. In order for this to have an affect, also disable
			// prefer whole pieces (otherwise partial pieces would be de-prioritized)
			options |= prioritize_partials;
			prefer_whole_pieces = 0;
		}

		if (options &amp; ignore_whole_pieces) prefer_whole_pieces = 0;

		// only one of rarest_first and sequential can be set.
		TORRENT_ASSERT(((options &amp; rarest_first) ? 1 : 0)
			+ ((options &amp; sequential) ? 1 : 0) &lt;= 1);
#ifdef TORRENT_EXPENSIVE_INVARIANT_CHECKS
		TORRENT_PIECE_PICKER_INVARIANT_CHECK;
#endif
		TORRENT_ASSERT(num_blocks &gt; 0);
		TORRENT_ASSERT(pieces.size() == m_piece_map.size());

		TORRENT_ASSERT(!m_priority_boundries.empty()
			|| m_dirty);

		// this will be filled with blocks that we should not request
		// unless we can't find num_blocks among the other ones.
		// blocks that belong to pieces with a mismatching speed
		// category for instance, or if we prefer whole pieces,
		// blocks belonging to a piece that others have
		// downloaded to
		std::vector&lt;piece_block&gt; backup_blocks;
		std::vector&lt;piece_block&gt; backup_blocks2;
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(11)">src/session_impl.cpp:4500</a></td><td>make a list for torrents that want to be announced on the DHT so we don't have to loop over all torrents, just to find the ones that want to announce</td></tr><tr id="11" style="display: none;" colspan="3"><td colspan="3"><h2>make a list for torrents that want to be announced on the DHT so we
don't have to loop over all torrents, just to find the ones that want to announce</h2><h4>src/session_impl.cpp:4500</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		if (!m_dht_torrents.empty())
		{
			boost::shared_ptr&lt;torrent&gt; t;
			do
			{
		  		t = m_dht_torrents.front().lock();
				m_dht_torrents.pop_front();
			}
			while (!t &amp;&amp; !m_dht_torrents.empty());
			if (t)
			{
				t-&gt;dht_announce();
				return;
			}
		}
		if (m_torrents.empty()) return;

		if (m_next_dht_torrent == m_torrents.end())
			m_next_dht_torrent = m_torrents.begin();
		m_next_dht_torrent-&gt;second-&gt;dht_announce();
<div style="background: #ffff00" width="100%">		++m_next_dht_torrent;
</div>		if (m_next_dht_torrent == m_torrents.end())
			m_next_dht_torrent = m_torrents.begin();
  	}
#endif

	void session_impl::on_lsd_announce(error_code const&amp; e)
	{
#if defined TORRENT_ASIO_DEBUGGING
		complete_async("session_impl::on_lsd_announce");
#endif
		inc_stats_counter(counters::on_lsd_counter);
		TORRENT_ASSERT(is_single_thread());
		if (e) return;

		if (m_abort) return;

#if defined TORRENT_ASIO_DEBUGGING
		add_outstanding_async("session_impl::on_lsd_announce");
#endif
		// announce on local network every 5 minutes
		int delay = (std::max)(m_settings.get_int(settings_pack::local_service_announce_interval)
			/ (std::max)(int(m_torrents.size()), 1), 1);
		error_code ec;
		m_lsd_announce_timer.expires_from_now(seconds(delay), ec);
		m_lsd_announce_timer.async_wait(
			bind(&amp;session_impl::on_lsd_announce, this, _1));

		if (m_torrents.empty()) return;

		if (m_next_lsd_torrent == m_torrents.end())
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(12)">src/session_impl.cpp:5831</a></td><td>if we still can't find the torrent, we should probably look for it by url here</td></tr><tr id="12" style="display: none;" colspan="3"><td colspan="3"><h2>if we still can't find the torrent, we should probably look for it by url here</h2><h4>src/session_impl.cpp:5831</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">					}
				}
#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_LOGGING || defined TORRENT_ERROR_LOGGING
				else
				{
					session_log("metadata info-hash failed");
				}
#endif
			}
#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_LOGGING || defined TORRENT_ERROR_LOGGING
			else
			{
				session_log("no metadata found");
			}
#endif
		}

		// is the torrent already active?
		boost::shared_ptr&lt;torrent&gt; torrent_ptr = find_torrent(*ih).lock();
		if (!torrent_ptr &amp;&amp; !params.uuid.empty()) torrent_ptr = find_torrent(params.uuid).lock();
<div style="background: #ffff00" width="100%">
</div>		if (torrent_ptr)
		{
			if ((params.flags &amp; add_torrent_params::flag_duplicate_is_error) == 0)
			{
				if (!params.uuid.empty() &amp;&amp; torrent_ptr-&gt;uuid().empty())
					torrent_ptr-&gt;set_uuid(params.uuid);
				if (!params.url.empty() &amp;&amp; torrent_ptr-&gt;url().empty())
					torrent_ptr-&gt;set_url(params.url);
				if (!params.source_feed_url.empty() &amp;&amp; torrent_ptr-&gt;source_feed_url().empty())
					torrent_ptr-&gt;set_source_feed_url(params.source_feed_url);
				return torrent_handle(torrent_ptr);
			}

			ec = errors::duplicate_torrent;
			return torrent_handle();
		}

		int queue_pos = ++m_max_queue_pos;

		torrent_ptr.reset(new torrent(*this
			, 16 * 1024, queue_pos, params, *ih));
		torrent_ptr-&gt;start();

#ifndef TORRENT_DISABLE_EXTENSIONS
		add_extensions_to_torrent(torrent_ptr, params.userdata);
#endif

#ifndef TORRENT_DISABLE_DHT
		if (m_dht &amp;&amp; params.ti)
		{
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(13)">src/torrent.cpp:9320</a></td><td>will pick_pieces ever return an empty set?</td></tr><tr id="13" style="display: none;" colspan="3"><td colspan="3"><h2>will pick_pieces ever return an empty set?</h2><h4>src/torrent.cpp:9320</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">				if (added_request)
				{
					peers_with_requests.insert(peers_with_requests.begin(), &amp;c);
					if (i-&gt;first_requested == min_time()) i-&gt;first_requested = now;

					if (!c.can_request_time_critical())
					{
						peers.erase(p);
					}
					else
					{
						// resort p, since it will have a higher download_queue_time now
						while (p != peers.end()-1 &amp;&amp; (*p)-&gt;download_queue_time() &gt; (*(p+1))-&gt;download_queue_time())
						{
							std::iter_swap(p, p+1);
							++p;
						}
					}
				}

<div style="background: #ffff00" width="100%">			} while (!interesting_blocks.empty());
</div>
			peers.insert(peers.begin(), ignore_peers.begin(), ignore_peers.end());
			ignore_peers.clear();
		}

		// commit all the time critical requests
		for (std::set&lt;peer_connection*&gt;::iterator i = peers_with_requests.begin()
			, end(peers_with_requests.end()); i != end; ++i)
		{
			(*i)-&gt;send_block_requests();
		}
	}

	std::set&lt;std::string&gt; torrent::web_seeds(web_seed_entry::type_t type) const
	{
		TORRENT_ASSERT(m_ses.is_single_thread());
		std::set&lt;std::string&gt; ret;
		for (std::list&lt;web_seed_entry&gt;::const_iterator i = m_web_seeds.begin()
			, end(m_web_seeds.end()); i != end; ++i)
		{
			if (i-&gt;type != type) continue;
			ret.insert(i-&gt;url);
		}
		return ret;
	}

	void torrent::remove_web_seed(std::string const&amp; url, web_seed_entry::type_t type)
	{
		std::list&lt;web_seed_entry&gt;::iterator i = std::find_if(m_web_seeds.begin(), m_web_seeds.end()
			, (boost::bind(&amp;web_seed_entry::url, _1)
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(14)">src/utp_stream.cpp:609</a></td><td>support the option to turn it off</td></tr><tr id="14" style="display: none;" colspan="3"><td colspan="3"><h2>support the option to turn it off</h2><h4>src/utp_stream.cpp:609</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		UTP_STATE_ERROR_WAIT,

		// there are no more references to this socket
		// and we can delete it
		UTP_STATE_DELETE
	};

	// this is the cursor into m_delay_sample_hist
	boost::uint8_t m_delay_sample_idx:2;

	// the state the socket is in
	boost::uint8_t m_state:3;

	// this is set to true when we receive a fin
	bool m_eof:1;

	// is this socket state attached to a user space socket?
	bool m_attached:1;

	// this is true if nagle is enabled (which it is by default)
<div style="background: #ffff00" width="100%">	bool m_nagle:1;
</div>
	// this is true while the socket is in slow start mode. It's
	// only in slow-start during the start-up phase. Slow start
	// (contrary to what its name suggest) means that we're growing
	// the congestion window (cwnd) exponetially rather than linearly.
	// this is done at startup of a socket in order to find its
	// link capacity faster. This behaves similar to TCP slow start
	bool m_slow_start:1;
	
	// this is true as long as we have as many packets in
	// flight as allowed by the congestion window (cwnd)
	bool m_cwnd_full:1;

	// this is set to one if the current read operation
	// has a null-buffer. i.e. we're not reading into a user-provided
	// buffer, we're just signalling when there's something
	// to read from our internal receive buffer
	bool m_null_buffers:1;

	// this is set to true when this socket has added itself to
	// the utp socket manager's list of deferred acks. Once the
	// burst of incoming UDP packets is all drained, the utp socket
	// manager will send acks for all sockets on this list.
	bool m_deferred_ack:1;

	// this is true if this socket has subscribed to be notified
	// when this receive round is done
	bool m_subscribe_drained:1;

	// if this socket tries to send a packet via the utp socket
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(15)">src/utp_stream.cpp:1873</a></td><td>we might want to do something else here as well, to resend the packet immediately without it being an MTU probe</td></tr><tr id="15" style="display: none;" colspan="3"><td colspan="3"><h2>we might want to do something else here
as well, to resend the packet immediately without
it being an MTU probe</h2><h4>src/utp_stream.cpp:1873</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	// simulate 1% packet loss
//	if ((rand() % 100) &gt; 0)
#endif
	m_sm-&gt;send_packet(udp::endpoint(m_remote_address, m_port)
		, (char const*)h, p-&gt;size, ec
		, p-&gt;mtu_probe ? utp_socket_manager::dont_fragment : 0);

	++m_out_packets;

	if (ec == error::message_size)
	{
#if TORRENT_UTP_LOG
		UTP_LOGV("%8p: error sending packet: %s\n", this, ec.message().c_str());
#endif
		// if we fail even though this is not a probe, we're screwed
		// since we'd have to repacketize
		TORRENT_ASSERT(p-&gt;mtu_probe);
		m_mtu_ceiling = p-&gt;size - 1;
		if (m_mtu_floor &gt; m_mtu_ceiling) m_mtu_floor = m_mtu_ceiling;
		update_mtu_limits();
<div style="background: #ffff00" width="100%">		p-&gt;mtu_probe = false;
</div>		if (m_mtu_seq == m_ack_nr)
			m_mtu_seq = 0;
		ec.clear();

#if TORRENT_UTP_LOG
		UTP_LOGV("%8p: re-sending\n", this);
#endif
		m_sm-&gt;send_packet(udp::endpoint(m_remote_address, m_port)
			, (char const*)h, p-&gt;size, ec, 0);
	}

	if (ec == error::would_block || ec == error::try_again)
	{
#if TORRENT_UTP_LOG
		UTP_LOGV("%8p: socket stalled\n", this);
#endif
		if (!m_stalled)
		{
			m_stalled = true;
			m_sm-&gt;subscribe_writable(this);
		}
	}
	else if (ec)
	{
		TORRENT_ASSERT(stack_alloced != bool(payload_size));
		if (payload_size) free(p);
		m_error = ec;
		m_state = UTP_STATE_ERROR_WAIT;
		test_socket_state();
		return false;
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(16)">src/kademlia/dht_tracker.cpp:651</a></td><td>fix this stats logging. For instance, the stats counters could be factored out into its own class, and dht_tracker could take an optional reference to it ++m_replies_sent[e["r"]]; m_replies_bytes_sent[e["r"]] += int(m_send_buf.size());</td></tr><tr id="16" style="display: none;" colspan="3"><td colspan="3"><h2>fix this stats logging. For instance,
the stats counters could be factored out into its own
class, and dht_tracker could take an optional reference to it
++m_replies_sent[e["r"]];
m_replies_bytes_sent[e["r"]] += int(m_send_buf.size());</h2><h4>src/kademlia/dht_tracker.cpp:651</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">#endif

		if (m_sock.send(addr, &amp;m_send_buf[0], (int)m_send_buf.size(), ec, send_flags))
		{
			if (ec)
			{
				m_counters.inc_stats_counter(counters::dht_messages_out_dropped);
				return false;
			}

			// account for IP and UDP overhead
			m_sent_bytes += m_send_buf.size() + (addr.address().is_v6() ? 48 : 28);

			m_counters.inc_stats_counter(counters::dht_bytes_out, m_send_buf.size());
			m_counters.inc_stats_counter(counters::dht_messages_out);
#ifdef TORRENT_DHT_VERBOSE_LOGGING
			m_total_out_bytes += m_send_buf.size();
		
			if (e["y"].string() == "r")
			{
<div style="background: #ffff00" width="100%">			}
</div>			else if (e["y"].string() == "q")
			{
				m_queries_out_bytes += m_send_buf.size();
			}
			TORRENT_LOG(dht_tracker) &lt;&lt; "==&gt; " &lt;&lt; addr &lt;&lt; " " &lt;&lt; log_line.str();
#endif
			return true;
		}
		else
		{
			m_counters.inc_stats_counter(counters::dht_messages_out_dropped);

#ifdef TORRENT_DHT_VERBOSE_LOGGING
			TORRENT_LOG(dht_tracker) &lt;&lt; "==&gt; " &lt;&lt; addr &lt;&lt; " DROPPED " &lt;&lt; log_line.str();
#endif
			return false;
		}
	}

}}

</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(17)">src/kademlia/node.cpp:64</a></td><td>make this configurable in dht_settings</td></tr><tr id="17" style="display: none;" colspan="3"><td colspan="3"><h2>make this configurable in dht_settings</h2><h4>src/kademlia/node.cpp:64</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">#include "libtorrent/socket.hpp"
#include "libtorrent/random.hpp"
#include "libtorrent/aux_/session_impl.hpp"
#include "libtorrent/kademlia/node_id.hpp"
#include "libtorrent/kademlia/rpc_manager.hpp"
#include "libtorrent/kademlia/routing_table.hpp"
#include "libtorrent/kademlia/node.hpp"

#include "libtorrent/kademlia/refresh.hpp"
#include "libtorrent/kademlia/find_data.hpp"
#include "libtorrent/rsa.hpp"
#include "libtorrent/performance_counters.hpp" // for counters

namespace libtorrent { namespace dht
{

void incoming_error(entry&amp; e, char const* msg);

using detail::write_endpoint;

<div style="background: #ffff00" width="100%">enum { announce_interval = 30 };
</div>
#ifdef TORRENT_DHT_VERBOSE_LOGGING
TORRENT_DEFINE_LOG(node)

extern int g_failed_announces;
extern int g_announces;

#endif

// remove peers that have timed out
void purge_peers(std::set&lt;peer_entry&gt;&amp; peers)
{
	for (std::set&lt;peer_entry&gt;::iterator i = peers.begin()
		  , end(peers.end()); i != end;)
	{
		// the peer has timed out
		if (i-&gt;added + minutes(int(announce_interval * 1.5f)) &lt; time_now())
		{
#ifdef TORRENT_DHT_VERBOSE_LOGGING
			TORRENT_LOG(node) &lt;&lt; "peer timed out at: " &lt;&lt; i-&gt;addr;
#endif
			peers.erase(i++);
		}
		else
			++i;
	}
}

void nop() {}

</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(18)">include/libtorrent/intrusive_ptr_base.hpp:44</a></td><td>remove this class and transition over to using shared_ptr and make_shared instead</td></tr><tr id="18" style="display: none;" colspan="3"><td colspan="3"><h2>remove this class and transition over to using shared_ptr and make_shared instead</h2><h4>include/libtorrent/intrusive_ptr_base.hpp:44</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.

*/

#ifndef TORRENT_INTRUSIVE_PTR_BASE
#define TORRENT_INTRUSIVE_PTR_BASE

#include &lt;boost/checked_delete.hpp&gt;
#include &lt;boost/intrusive_ptr.hpp&gt;
#include "libtorrent/config.hpp"
#include "libtorrent/assert.hpp"
#include "libtorrent/atomic.hpp"

namespace libtorrent
{
<div style="background: #ffff00" width="100%">	template&lt;class T&gt;
</div>	struct intrusive_ptr_base
	{
		intrusive_ptr_base(intrusive_ptr_base&lt;T&gt; const&amp;)
			: m_refs(0) {}

		intrusive_ptr_base&amp; operator=(intrusive_ptr_base const&amp; rhs)
		{ return *this; }

		friend void intrusive_ptr_add_ref(intrusive_ptr_base&lt;T&gt; const* s)
		{
			TORRENT_ASSERT(s != 0);
			TORRENT_ASSERT(s-&gt;m_refs &gt;= 0);
			++s-&gt;m_refs;
		}

		friend void intrusive_ptr_release(intrusive_ptr_base&lt;T&gt; const* s)
		{
			TORRENT_ASSERT(s != 0);
			TORRENT_ASSERT(s-&gt;m_refs &gt; 0);
			if (--s-&gt;m_refs == 0)
				boost::checked_delete(static_cast&lt;T const*&gt;(s));
		}

		boost::intrusive_ptr&lt;T&gt; self()
		{ return boost::intrusive_ptr&lt;T&gt;((T*)this); }

		boost::intrusive_ptr&lt;const T&gt; self() const
		{ return boost::intrusive_ptr&lt;const T&gt;((T const*)this); }

		int refcount() const { return m_refs; }
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(19)">include/libtorrent/peer_connection.hpp:649</a></td><td>temporary hack until the stats counters are moved out from the session_interface.</td></tr><tr id="19" style="display: none;" colspan="3"><td colspan="3"><h2>temporary hack until the stats counters are moved out
from the session_interface.</h2><h4>include/libtorrent/peer_connection.hpp:649</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		size_type uploaded_since_unchoked() const
		{ return m_statistics.total_payload_upload() - m_uploaded_at_last_unchoke; }

		// called when the disk write buffer is drained again, and we can
		// start downloading payload again
		void on_disk();

		void on_allocate_disk_buffer(char* buffer, int buffer_size);

		int num_reading_bytes() const { return m_reading_bytes; }

		enum sync_t { read_async, read_sync };
		void setup_receive(sync_t sync = read_sync);

		boost::shared_ptr&lt;peer_connection&gt; self()
		{
			TORRENT_ASSERT(!m_in_constructor);
			return shared_from_this();
		}

<div style="background: #ffff00" width="100%">		aux::session_interface&amp; ses() { return m_ses; }
</div>
	protected:

		size_t try_read(sync_t s, error_code&amp; ec);

		virtual void get_specific_peer_info(peer_info&amp; p) const = 0;

		virtual void write_choke() = 0;
		virtual void write_unchoke() = 0;
		virtual void write_interested() = 0;
		virtual void write_not_interested() = 0;
		virtual void write_request(peer_request const&amp; r) = 0;
		virtual void write_cancel(peer_request const&amp; r) = 0;
		virtual void write_have(int index) = 0;
		virtual void write_dont_have(int index) = 0;
		virtual void write_keepalive() = 0;
		virtual void write_piece(peer_request const&amp; r, disk_buffer_holder&amp; buffer) = 0;
		virtual void write_suggest(int piece) = 0;
		virtual void write_bitfield() = 0;
		
		virtual void write_reject_request(peer_request const&amp; r) = 0;
		virtual void write_allow_fast(int piece) = 0;

		virtual void on_connected() = 0;
		virtual void on_tick() {}
	
		virtual void on_receive(error_code const&amp; error
			, std::size_t bytes_transferred) = 0;
		virtual void on_sent(error_code const&amp; error
			, std::size_t bytes_transferred) = 0;
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(20)">include/libtorrent/torrent_info.hpp:497</a></td><td>these strings (m_comment, m_created_by, m_ssl_root_cert) could be lazy_entry* to save memory</td></tr><tr id="20" style="display: none;" colspan="3"><td colspan="3"><h2>these strings (m_comment, m_created_by, m_ssl_root_cert) could be lazy_entry* to save memory</h2><h4>include/libtorrent/torrent_info.hpp:497</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		std::vector&lt;announce_entry&gt; m_urls;
		std::vector&lt;web_seed_entry&gt; m_web_seeds;
		nodes_t m_nodes;

		// if this is a merkle torrent, this is the merkle
		// tree. It has space for merkle_num_nodes(merkle_num_leafs(num_pieces))
		// hashes
		std::vector&lt;sha1_hash&gt; m_merkle_tree;

		// this is a copy of the info section from the torrent.
		// it use maintained in this flat format in order to
		// make it available through the metadata extension
		boost::shared_array&lt;char&gt; m_info_section;

		// this is a pointer into the m_info_section buffer
		// pointing to the first byte of the first sha-1 hash
		char const* m_piece_hashes;

		// if a comment is found in the torrent file
		// this will be set to that comment
<div style="background: #ffff00" width="100%">		std::string m_comment;
</div>
		// an optional string naming the software used
		// to create the torrent file
		std::string m_created_by;

#ifdef TORRENT_USE_OPENSSL
		// for ssl-torrens, this contains the root
		// certificate, in .pem format (i.e. ascii
		// base64 encoded with head and tails)
		std::string m_ssl_root_cert;
#endif

		// the info section parsed. points into m_info_section
		// parsed lazily
		mutable lazy_entry m_info_dict;

		// if a creation date is found in the torrent file
		// this will be set to that, otherwise it'll be
		// 1970, Jan 1
		time_t m_creation_date;

		// the hash that identifies this torrent
		sha1_hash m_info_hash;

		// the number of bytes in m_info_section
		boost::uint32_t m_info_section_size:24;

		// this is used when creating a torrent. If there's
		// only one file there are cases where it's impossible
		// to know if it should be written as a multifile torrent
</pre></td></tr><tr style="background: #cfc"><td>relevance&nbsp;2</td><td><a href="javascript:expand(21)">include/libtorrent/aux_/session_interface.hpp:105</a></td><td>the IP voting mechanism should be factored out to its own class, not part of the session</td></tr><tr id="21" style="display: none;" colspan="3"><td colspan="3"><h2>the IP voting mechanism should be factored out
to its own class, not part of the session</h2><h4>include/libtorrent/aux_/session_interface.hpp:105</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	struct ip_filter;
	class port_filter;
	struct settings_pack;
	struct torrent_peer_allocator_interface;
	struct counters;

#ifndef TORRENT_DISABLE_DHT
	namespace dht
	{
		struct dht_tracker;
	}
#endif
}

namespace libtorrent { namespace aux
{
	// TOOD: make this interface a lot smaller
	struct session_interface
		: buffer_allocator_interface
	{
<div style="background: #ffff00" width="100%">		enum
</div>		{
			source_dht = 1,
			source_peer = 2,
			source_tracker = 4,
			source_router = 8
		};

		virtual void set_external_address(address const&amp; ip
			, int source_type, address const&amp; source) = 0;
		virtual external_ip const&amp; external_address() const = 0;

		virtual disk_interface&amp; disk_thread() = 0;

		virtual alert_manager&amp; alerts() = 0;

		virtual torrent_peer_allocator_interface* get_peer_allocator() = 0;
		virtual io_service&amp; get_io_service() = 0;

		virtual bool has_connection(peer_connection* p) const = 0;
		virtual void insert_peer(boost::shared_ptr&lt;peer_connection&gt; const&amp; c) = 0;
		
		virtual void add_redundant_bytes(size_type b, int reason) = 0;
		virtual void add_failed_bytes(size_type b) = 0;

		virtual void queue_async_resume_data(boost::shared_ptr&lt;torrent&gt; const&amp; t) = 0;
		virtual void done_async_resume() = 0;
		virtual void evict_torrent(torrent* t) = 0;

		virtual void remove_torrent(torrent_handle const&amp; h, int options = 0) = 0;
		virtual void remove_torrent_impl(boost::shared_ptr&lt;torrent&gt; tptr, int options) = 0;
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(22)">src/http_seed_connection.cpp:120</a></td><td>in chunked encoding mode, this assert won't hold. the chunk headers should be subtracted from the receive_buffer_size</td></tr><tr id="22" style="display: none;" colspan="3"><td colspan="3"><h2>in chunked encoding mode, this assert won't hold.
the chunk headers should be subtracted from the receive_buffer_size</h2><h4>src/http_seed_connection.cpp:120</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	boost::optional&lt;piece_block_progress&gt;
	http_seed_connection::downloading_piece_progress() const
	{
		if (m_requests.empty())
			return boost::optional&lt;piece_block_progress&gt;();

		boost::shared_ptr&lt;torrent&gt; t = associated_torrent().lock();
		TORRENT_ASSERT(t);

		piece_block_progress ret;

		peer_request const&amp; pr = m_requests.front();
		ret.piece_index = pr.piece;
		if (!m_parser.header_finished())
		{
			ret.bytes_downloaded = 0;
		}
		else
		{
			int receive_buffer_size = receive_buffer().left() - m_parser.body_start();
<div style="background: #ffff00" width="100%">			TORRENT_ASSERT(receive_buffer_size &lt;= t-&gt;block_size());
</div>			ret.bytes_downloaded = t-&gt;block_size() - receive_buffer_size;
		}
		// this is used to make sure that the block_index stays within
		// bounds. If the entire piece is downloaded, the block_index
		// would otherwise point to one past the end
		int correction = ret.bytes_downloaded ? -1 : 0;
		ret.block_index = (pr.start + ret.bytes_downloaded + correction) / t-&gt;block_size();
		ret.full_block_bytes = t-&gt;block_size();
		const int last_piece = t-&gt;torrent_file().num_pieces() - 1;
		if (ret.piece_index == last_piece &amp;&amp; ret.block_index
			== t-&gt;torrent_file().piece_size(last_piece) / t-&gt;block_size())
			ret.full_block_bytes = t-&gt;torrent_file().piece_size(last_piece) % t-&gt;block_size();
		return ret;
	}

	void http_seed_connection::write_request(peer_request const&amp; r)
	{
		INVARIANT_CHECK;

		boost::shared_ptr&lt;torrent&gt; t = associated_torrent().lock();
		TORRENT_ASSERT(t);

		TORRENT_ASSERT(t-&gt;valid_metadata());
		// http_seeds don't support requesting more than one piece
		// at a time
		TORRENT_ASSERT(r.length &lt;= t-&gt;torrent_file().piece_size(r.piece));

		std::string request;
		request.reserve(400);

</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(23)">src/session_impl.cpp:6235</a></td><td>report the proper address of the router as the source IP of this understanding of our external address, instead of the empty address</td></tr><tr id="23" style="display: none;" colspan="3"><td colspan="3"><h2>report the proper address of the router as the source IP of
this understanding of our external address, instead of the empty address</h2><h4>src/session_impl.cpp:6235</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	void session_impl::on_port_mapping(int mapping, address const&amp; ip, int port
		, error_code const&amp; ec, int map_transport)
	{
		TORRENT_ASSERT(is_single_thread());

		TORRENT_ASSERT(map_transport &gt;= 0 &amp;&amp; map_transport &lt;= 1);

		if (mapping == m_udp_mapping[map_transport] &amp;&amp; port != 0)
		{
			m_external_udp_port = port;
			if (m_alerts.should_post&lt;portmap_alert&gt;())
				m_alerts.post_alert(portmap_alert(mapping, port
					, map_transport));
			return;
		}

		if (mapping == m_tcp_mapping[map_transport] &amp;&amp; port != 0)
		{
			if (ip != address())
			{
<div style="background: #ffff00" width="100%">				set_external_address(ip, source_router, address());
</div>			}

			if (!m_listen_sockets.empty()) {
				m_listen_sockets.front().external_address = ip;
				m_listen_sockets.front().external_port = port;
			}
			if (m_alerts.should_post&lt;portmap_alert&gt;())
				m_alerts.post_alert(portmap_alert(mapping, port
					, map_transport));
			return;
		}

		if (ec)
		{
			if (m_alerts.should_post&lt;portmap_error_alert&gt;())
				m_alerts.post_alert(portmap_error_alert(mapping
					, map_transport, ec));
		}
		else
		{
			if (m_alerts.should_post&lt;portmap_alert&gt;())
				m_alerts.post_alert(portmap_alert(mapping, port
					, map_transport));
		}
	}

	session_status session_impl::status() const
	{
//		INVARIANT_CHECK;
		TORRENT_ASSERT(is_single_thread());
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(24)">src/session_impl.cpp:6452</a></td><td>report errors as alerts</td></tr><tr id="24" style="display: none;" colspan="3"><td colspan="3"><h2>report errors as alerts</h2><h4>src/session_impl.cpp:6452</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	}

	void session_impl::add_dht_router(std::pair&lt;std::string, int&gt; const&amp; node)
	{
#if defined TORRENT_ASIO_DEBUGGING
		add_outstanding_async("session_impl::on_dht_router_name_lookup");
#endif
		char port[7];
		snprintf(port, sizeof(port), "%d", node.second);
		tcp::resolver::query q(node.first, port);
		m_host_resolver.async_resolve(q,
			boost::bind(&amp;session_impl::on_dht_router_name_lookup, this, _1, _2));
	}

	void session_impl::on_dht_router_name_lookup(error_code const&amp; e
		, tcp::resolver::iterator host)
	{
#if defined TORRENT_ASIO_DEBUGGING
		complete_async("session_impl::on_dht_router_name_lookup");
#endif
<div style="background: #ffff00" width="100%">		if (e) return;
</div>		while (host != tcp::resolver::iterator())
		{
			// router nodes should be added before the DHT is started (and bootstrapped)
			udp::endpoint ep(host-&gt;endpoint().address(), host-&gt;endpoint().port());
			if (m_dht) m_dht-&gt;add_router_node(ep);
			m_dht_router_nodes.push_back(ep);
			++host;
		}
	}
#endif

	void session_impl::maybe_update_udp_mapping(int nat, int local_port, int external_port)
	{
		int local, external, protocol;
		if (nat == 0 &amp;&amp; m_natpmp.get())
		{
			if (m_udp_mapping[nat] != -1)
			{
				if (m_natpmp-&gt;get_mapping(m_udp_mapping[nat], local, external, protocol))
				{
					// we already have a mapping. If it's the same, don't do anything
					if (local == local_port &amp;&amp; external == external_port &amp;&amp; protocol == natpmp::udp)
						return;
				}
				m_natpmp-&gt;delete_mapping(m_udp_mapping[nat]);
			}
			m_udp_mapping[nat] = m_natpmp-&gt;add_mapping(natpmp::udp
				, local_port, external_port);
			return;
		}
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(25)">src/session_impl.cpp:7171</a></td><td>we only need to do this if our global IPv4 address has changed since the DHT (currently) only supports IPv4. Since restarting the DHT is kind of expensive, it would be nice to not do it unnecessarily</td></tr><tr id="25" style="display: none;" colspan="3"><td colspan="3"><h2>we only need to do this if our global IPv4 address has changed
since the DHT (currently) only supports IPv4. Since restarting the DHT
is kind of expensive, it would be nice to not do it unnecessarily</h2><h4>src/session_impl.cpp:7171</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	void session_impl::set_external_address(address const&amp; ip
		, int source_type, address const&amp; source)
	{
#if defined TORRENT_VERBOSE_LOGGING
		session_log(": set_external_address(%s, %d, %s)", print_address(ip).c_str()
			, source_type, print_address(source).c_str());
#endif

		if (!m_external_ip.cast_vote(ip, source_type, source)) return;

#if defined TORRENT_VERBOSE_LOGGING
		session_log("  external IP updated");
#endif

		if (m_alerts.should_post&lt;external_ip_alert&gt;())
			m_alerts.post_alert(external_ip_alert(ip));

		// since we have a new external IP now, we need to
		// restart the DHT with a new node ID
#ifndef TORRENT_DISABLE_DHT
<div style="background: #ffff00" width="100%">		if (m_dht)
</div>		{
			entry s = m_dht-&gt;state();
			int cur_state = 0;
			int prev_state = 0;
			entry* nodes1 = s.find_key("nodes");
			if (nodes1 &amp;&amp; nodes1-&gt;type() == entry::list_t) cur_state = nodes1-&gt;list().size();
			entry* nodes2 = m_dht_state.find_key("nodes");
			if (nodes2 &amp;&amp; nodes2-&gt;type() == entry::list_t) prev_state = nodes2-&gt;list().size();
			if (cur_state &gt; prev_state) m_dht_state = s;
			start_dht(m_dht_state);
		}
#endif
	}

	// decrement the refcount of the block in the disk cache
	// since the network thread doesn't need it anymore
	void session_impl::reclaim_block(block_cache_reference ref)
	{
		m_disk_thread.reclaim_block(ref);
	}

	char* session_impl::allocate_disk_buffer(char const* category)
	{
		return m_disk_thread.allocate_disk_buffer(category);
	}

	char* session_impl::async_allocate_disk_buffer(char const* category
		, boost::function&lt;void(char*)&gt; const&amp; handler)
	{
		return m_disk_thread.async_allocate_disk_buffer(category, handler);
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(26)">src/torrent.cpp:1185</a></td><td>make this depend on the error and on the filesystem the files are being downloaded to. If the error is no_space_left_on_device and the filesystem doesn't support sparse files, only zero the priorities of the pieces that are at the tails of all files, leaving everything up to the highest written piece in each file</td></tr><tr id="26" style="display: none;" colspan="3"><td colspan="3"><h2>make this depend on the error and on the filesystem the
files are being downloaded to. If the error is no_space_left_on_device
and the filesystem doesn't support sparse files, only zero the priorities
of the pieces that are at the tails of all files, leaving everything
up to the highest written piece in each file</h2><h4>src/torrent.cpp:1185</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			alerts().post_alert(file_error_alert(j-&gt;error.ec
				, resolve_filename(j-&gt;error.file), j-&gt;error.operation_str(), get_handle()));

		// put the torrent in an error-state
		set_error(j-&gt;error.ec, j-&gt;error.file);

		// if a write operation failed, and future writes are likely to
		// fail, while reads may succeed, just set the torrent to upload mode
		// if we make an incorrect assumption here, it's not the end of the
		// world, if we ever issue a read request and it fails as well, we
		// won't get in here and we'll actually end up pausing the torrent
		if (j-&gt;action == disk_io_job::write
			&amp;&amp; (j-&gt;error.ec == boost::system::errc::read_only_file_system
			|| j-&gt;error.ec == boost::system::errc::permission_denied
			|| j-&gt;error.ec == boost::system::errc::operation_not_permitted
			|| j-&gt;error.ec == boost::system::errc::no_space_on_device
			|| j-&gt;error.ec == boost::system::errc::file_too_large))
		{
			// if we failed to write, stop downloading and just
			// keep seeding.
<div style="background: #ffff00" width="100%">			set_upload_mode(true);
</div>			return;
		}

		// if the error appears to be more serious than a full disk, just pause the torrent
		pause();
	}

	void torrent::on_piece_fail_sync(disk_io_job const* j, piece_block b)
	{
		update_gauge();
		// some peers that previously was no longer interesting may
		// now have become interesting, since we lack this one piece now.
		for (peer_iterator i = begin(); i != end();)
		{
			peer_connection* p = *i;
			// update_interest may disconnect the peer and
			// invalidate the iterator
			++i;
			// no need to do anything with peers that
			// already are interested. Gaining a piece may
			// only make uninteresting peers interesting again.
			if (p-&gt;is_interesting()) continue;
			p-&gt;update_interest();
			if (request_a_block(*this, *p))
				m_ses.inc_stats_counter(counters::hash_fail_piece_picks);
			p-&gt;send_block_requests();
		}
	}

	void torrent::on_disk_read_complete(disk_io_job const* j, peer_request r, read_piece_struct* rp)
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(27)">src/torrent.cpp:6354</a></td><td>save the send_stats state instead of throwing them away it may pose an issue when downgrading though</td></tr><tr id="27" style="display: none;" colspan="3"><td colspan="3"><h2>save the send_stats state instead of throwing them away
it may pose an issue when downgrading though</h2><h4>src/torrent.cpp:6354</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">						? (1 &lt;&lt; k) : 0;
					bitmask.append(1, v);
					TORRENT_ASSERT(bits == 8 || j == num_bitmask_bytes - 1);
				}
				piece_struct["bitmask"] = bitmask;
				// push the struct onto the unfinished-piece list
				up.push_back(piece_struct);
			}
		}

		// save trackers
		if (!m_trackers.empty())
		{
			entry::list_type&amp; tr_list = ret["trackers"].list();
			tr_list.push_back(entry::list_type());
			int tier = 0;
			for (std::vector&lt;announce_entry&gt;::const_iterator i = m_trackers.begin()
				, end(m_trackers.end()); i != end; ++i)
			{
				// don't save trackers we can't trust
<div style="background: #ffff00" width="100%">				if (i-&gt;send_stats == false) continue;
</div>				if (i-&gt;tier == tier)
				{
					tr_list.back().list().push_back(i-&gt;url);
				}
				else
				{
					tr_list.push_back(entry::list_t);
					tr_list.back().list().push_back(i-&gt;url);
					tier = i-&gt;tier;
				}
			}
		}

		// save web seeds
		if (!m_web_seeds.empty())
		{
			entry::list_type&amp; url_list = ret["url-list"].list();
			entry::list_type&amp; httpseed_list = ret["httpseeds"].list();
			for (std::list&lt;web_seed_entry&gt;::const_iterator i = m_web_seeds.begin()
				, end(m_web_seeds.end()); i != end; ++i)
			{
				if (i-&gt;type == web_seed_entry::url_seed)
					url_list.push_back(i-&gt;url);
				else if (i-&gt;type == web_seed_entry::http_seed)
					httpseed_list.push_back(i-&gt;url);
			}
		}

		// write have bitmask
		// the pieces string has one byte per piece. Each
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(28)">src/torrent.cpp:7045</a></td><td>ideally, we would disconnect the oldest connection i.e. the one that has waited the longest to connect.</td></tr><tr id="28" style="display: none;" colspan="3"><td colspan="3"><h2>ideally, we would disconnect the oldest connection
i.e. the one that has waited the longest to connect.</h2><h4>src/torrent.cpp:7045</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			int f = m_ses.peer_classes().at(pc)-&gt;connection_limit_factor;
			if (connection_limit_factor &lt; f) connection_limit_factor = f;
		}
		if (connection_limit_factor == 0) connection_limit_factor = 100;

		boost::uint64_t limit = boost::uint64_t(m_max_connections) * 100 / connection_limit_factor;

		bool maybe_replace_peer = false;

		if (m_connections.size() &gt;= limit)
		{
			// if more than 10% of the connections are outgoing
			// connection attempts that haven't completed yet,
			// disconnect one of them and let this incoming
			// connection through.
			if (m_num_connecting &gt; m_max_connections / 10)
			{
				// find one of the connecting peers and disconnect it
				// find any peer that's connecting (i.e. a half-open TCP connection)
				// that's also not disconnecting
<div style="background: #ffff00" width="100%">				std::vector&lt;peer_connection*&gt;::iterator i = std::find_if(begin(), end()
</div>					, boost::bind(&amp;peer_connection::is_connecting, _1)
					&amp;&amp; !boost::bind(&amp;peer_connection::is_disconnecting, _1));

				if (i == end())
				{
					// this seems odd, but we might as well handle it
					p-&gt;disconnect(errors::too_many_connections, peer_connection_interface::op_bittorrent);
					return false;
				}
				(*i)-&gt;disconnect(errors::too_many_connections, peer_connection_interface::op_bittorrent);
            
				// if this peer was let in via connections slack,
				// it has done its duty of causing the disconnection
				// of another peer
				p-&gt;peer_disconnected_other();
			}
			else
			{
				maybe_replace_peer = true;
			}
		}

		TORRENT_TRY
		{
#ifndef TORRENT_DISABLE_EXTENSIONS
			for (extension_list_t::iterator i = m_extensions.begin()
				, end(m_extensions.end()); i != end; ++i)
			{
				boost::shared_ptr&lt;peer_plugin&gt; pp((*i)-&gt;new_connection(p));
				if (pp) p-&gt;add_extension(pp);
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(29)">src/torrent.cpp:7362</a></td><td>should disconnect all peers that have the pieces we have not just seeds. It would be pretty expensive to check all pieces for all peers though</td></tr><tr id="29" style="display: none;" colspan="3"><td colspan="3"><h2>should disconnect all peers that have the pieces we have
not just seeds. It would be pretty expensive to check all pieces
for all peers though</h2><h4>src/torrent.cpp:7362</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		TORRENT_ASSERT(is_finished());

		set_state(torrent_status::finished);
		set_queue_position(-1);

		// we have to call completed() before we start
		// disconnecting peers, since there's an assert
		// to make sure we're cleared the piece picker
		if (is_seed()) completed();

		send_upload_only();

		state_updated();

		m_completed_time = time(0);

		// disconnect all seeds
		if (settings().get_bool(settings_pack::close_redundant_connections))
		{
<div style="background: #ffff00" width="100%">			std::vector&lt;peer_connection*&gt; seeds;
</div>			for (peer_iterator i = m_connections.begin();
				i != m_connections.end(); ++i)
			{
				peer_connection* p = *i;
				TORRENT_ASSERT(p-&gt;associated_torrent().lock().get() == this);
				if (p-&gt;upload_only())
				{
#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_ERROR_LOGGING
					p-&gt;peer_log("*** SEED, CLOSING CONNECTION");
#endif
					seeds.push_back(p);
				}
			}
			std::for_each(seeds.begin(), seeds.end()
				, boost::bind(&amp;peer_connection::disconnect, _1, errors::torrent_finished
				, peer_connection_interface::op_bittorrent, 0));
		}

		if (m_abort) return;

		update_want_peers();

		TORRENT_ASSERT(m_storage);

		// we need to keep the object alive during this operation
		m_ses.disk_thread().async_release_files(m_storage.get()
			, boost::bind(&amp;torrent::on_cache_flushed, shared_from_this(), _1));
		
		// this torrent just completed downloads, which means it will fall
		// under a different limit with the auto-manager. Make sure we
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(30)">src/kademlia/node.cpp:707</a></td><td>find_node should write directly to the response entry</td></tr><tr id="30" style="display: none;" colspan="3"><td colspan="3"><h2>find_node should write directly to the response entry</h2><h4>src/kademlia/node.cpp:707</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		{
			TORRENT_LOG(node) &lt;&lt; " values: " &lt;&lt; reply["values"].list().size();
		}
#endif
	}
	else if (strcmp(query, "find_node") == 0)
	{
		key_desc_t msg_desc[] = {
			{"target", lazy_entry::string_t, 20, 0},
		};

		lazy_entry const* msg_keys[1];
		if (!verify_message(arg_ent, msg_desc, msg_keys, 1, error_string, sizeof(error_string)))
		{
			incoming_error(e, error_string);
			return;
		}

		sha1_hash target(msg_keys[0]-&gt;string_ptr());

<div style="background: #ffff00" width="100%">		nodes_t n;
</div>		m_table.find_node(target, n, 0);
		write_nodes_entry(reply, n);
	}
	else if (strcmp(query, "announce_peer") == 0)
	{
		key_desc_t msg_desc[] = {
			{"info_hash", lazy_entry::string_t, 20, 0},
			{"port", lazy_entry::int_t, 0, 0},
			{"token", lazy_entry::string_t, 0, 0},
			{"n", lazy_entry::string_t, 0, key_desc_t::optional},
			{"seed", lazy_entry::int_t, 0, key_desc_t::optional},
			{"implied_port", lazy_entry::int_t, 0, key_desc_t::optional},
		};

		lazy_entry const* msg_keys[6];
		if (!verify_message(arg_ent, msg_desc, msg_keys, 6, error_string, sizeof(error_string)))
		{
#ifdef TORRENT_DHT_VERBOSE_LOGGING
			++g_failed_announces;
#endif
			incoming_error(e, error_string);
			return;
		}

		int port = int(msg_keys[1]-&gt;int_value());

		// is the announcer asking to ignore the explicit
		// listen port and instead use the source port of the packet?
		if (msg_keys[5] &amp;&amp; msg_keys[5]-&gt;int_value() != 0)
			port = m.addr.port();
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(31)">include/libtorrent/ip_voter.hpp:100</a></td><td>instead, have one instance per possible subnet, global IPv4, global IPv6, loopback, 192.168.x.x, 10.x.x.x, etc.</td></tr><tr id="31" style="display: none;" colspan="3"><td colspan="3"><h2>instead, have one instance per possible subnet, global IPv4, global IPv6, loopback, 192.168.x.x, 10.x.x.x, etc.</h2><h4>include/libtorrent/ip_voter.hpp:100</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		bloom_filter&lt;32&gt; m_external_address_voters;
		std::vector&lt;external_ip_t&gt; m_external_addresses;
		address m_external_address;
	};

	// this keeps track of multiple external IPs (for now, just IPv6 and IPv4, but
	// it could be extended to deal with loopback and local network addresses as well)
	struct TORRENT_EXTRA_EXPORT external_ip
	{
		// returns true if a different IP is the top vote now
		// i.e. we changed our idea of what our external IP is
		bool cast_vote(address const&amp; ip, int source_type, address const&amp; source);

		// the external IP as it would be observed from `ip`
		address external_address(address const&amp; ip) const;

	private:

		// for now, assume one external IPv4 and one external IPv6 address
		// 0 = IPv4 1 = IPv6
<div style="background: #ffff00" width="100%">		ip_voter m_vote_group[2];
</div>	};

}

#endif

</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(32)">include/libtorrent/utp_stream.hpp:370</a></td><td>implement blocking write. Low priority since it's not used (yet)</td></tr><tr id="32" style="display: none;" colspan="3"><td colspan="3"><h2>implement blocking write. Low priority since it's not used (yet)</h2><h4>include/libtorrent/utp_stream.hpp:370</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		for (typename Mutable_Buffers::const_iterator i = buffers.begin()
			, end(buffers.end()); i != end; ++i)
		{
			using asio::buffer_cast;
			using asio::buffer_size;
			add_read_buffer(buffer_cast&lt;void*&gt;(*i), buffer_size(*i));
#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
			buf_size += buffer_size(*i);
#endif
		}
		std::size_t ret = read_some(true);
		TORRENT_ASSERT(ret &lt;= buf_size);
		TORRENT_ASSERT(ret &gt; 0);
		return ret;
	}

	template &lt;class Const_Buffers&gt;
	std::size_t write_some(Const_Buffers const&amp; buffers, error_code&amp; ec)
	{
		TORRENT_ASSERT(false &amp;&amp; "not implemented!");
<div style="background: #ffff00" width="100%">		return 0;
</div>	}

#ifndef BOOST_NO_EXCEPTIONS
	template &lt;class Mutable_Buffers&gt;
	std::size_t read_some(Mutable_Buffers const&amp; buffers)
	{
		error_code ec;
		std::size_t ret = read_some(buffers, ec);
		if (ec)
			boost::throw_exception(boost::system::system_error(ec));
		return ret;
	}

	template &lt;class Const_Buffers&gt;
	std::size_t write_some(Const_Buffers const&amp; buffers)
	{
		error_code ec;
		std::size_t ret = write_some(buffers, ec);
		if (ec)
			boost::throw_exception(boost::system::system_error(ec));
		return ret;
	}
#endif

	template &lt;class Const_Buffers, class Handler&gt;
	void async_write_some(Const_Buffers const&amp; buffers, Handler const&amp; handler)
	{
		if (m_impl == 0)
		{
			m_io_service.post(boost::bind&lt;void&gt;(handler, asio::error::not_connected, 0));
</pre></td></tr><tr style="background: #ccf"><td>relevance&nbsp;1</td><td><a href="javascript:expand(33)">include/libtorrent/web_peer_connection.hpp:121</a></td><td>if we make this be a disk_buffer_holder instead we would save a copy sometimes use allocate_disk_receive_buffer and release_disk_receive_buffer</td></tr><tr id="33" style="display: none;" colspan="3"><td colspan="3"><h2>if we make this be a disk_buffer_holder instead
we would save a copy sometimes
use allocate_disk_receive_buffer and release_disk_receive_buffer</h2><h4>include/libtorrent/web_peer_connection.hpp:121</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
	private:

		bool maybe_harvest_block();

		// returns the block currently being
		// downloaded. And the progress of that
		// block. If the peer isn't downloading
		// a piece for the moment, the boost::optional
		// will be invalid.
		boost::optional&lt;piece_block_progress&gt; downloading_piece_progress() const;

		// this has one entry per http-request
		// (might be more than the bt requests)
		std::deque&lt;int&gt; m_file_requests;

		std::string m_url;
			
		// this is used for intermediate storage of pieces
		// that are received in more than one HTTP response
<div style="background: #ffff00" width="100%">		std::vector&lt;char&gt; m_piece;
</div>		
		// the number of bytes received in the current HTTP
		// response. used to know where in the buffer the
		// next response starts
		size_type m_received_body;

		// position in the current range response
		size_type m_range_pos;

		// the position in the current block
		int m_block_pos;

		// this is the offset inside the current receive
		// buffer where the next chunk header will be.
		// this is updated for each chunk header that's
		// parsed. It does not necessarily point to a valid
		// offset in the receive buffer, if we haven't received
		// it yet. This offset never includes the HTTP header
		size_type m_chunk_pos;

		// this is the number of bytes we've already received
		// from the next chunk header we're waiting for
		int m_partial_chunk_header;
	};
}

#endif // TORRENT_WEB_PEER_CONNECTION_HPP_INCLUDED

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(34)">src/_storage.left.cpp:615</a></td><td>make this more generic to not just work if files have been renamed, but also if they have been merged into a single file for instance maybe use the same format as .torrent files and reuse some code from torrent_info</td></tr><tr id="34" style="display: none;" colspan="3"><td colspan="3"><h2>make this more generic to not just work if files have been
renamed, but also if they have been merged into a single file for instance
maybe use the same format as .torrent files and reuse some code from torrent_info</h2><h4>src/_storage.left.cpp:615</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		for (file_iter = files().begin();;)
		{
			if (file_offset &lt; file_iter-&gt;size)
				break;

			file_offset -= file_iter-&gt;size;
			++file_iter;
			TORRENT_ASSERT(file_iter != files().end());
		}
	
		error_code ec;
		boost::intrusive_ptr&lt;file&gt; file_handle = open_file(file_iter, file::read_only, ec);
		if (!file_handle || ec) return slot;

		size_type data_start = file_handle-&gt;sparse_end(file_offset);
		return int((data_start + m_files.piece_length() - 1) / m_files.piece_length());
	}

	bool default_storage::verify_resume_data(lazy_entry const&amp; rd, storage_error&amp; ec)
	{
<div style="background: #ffff00" width="100%">		lazy_entry const* mapped_files = rd.dict_find_list("mapped_files");
</div>		if (mapped_files &amp;&amp; mapped_files-&gt;list_size() == m_files.num_files())
		{
			m_mapped_files.reset(new file_storage(m_files));
			for (int i = 0; i &lt; m_files.num_files(); ++i)
			{
				std::string new_filename = mapped_files-&gt;list_string_value_at(i);
				if (new_filename.empty()) continue;
				m_mapped_files-&gt;rename_file(i, new_filename);
			}
		}
		
		lazy_entry const* file_priority = rd.dict_find_list("file_priority");
		if (file_priority &amp;&amp; file_priority-&gt;list_size()
			== files().num_files())
		{
			m_file_priority.resize(file_priority-&gt;list_size());
			for (int i = 0; i &lt; file_priority-&gt;list_size(); ++i)
				m_file_priority[i] = boost::uint8_t(file_priority-&gt;list_int_value_at(i, 1));
		}

		lazy_entry const* file_sizes_ent = rd.dict_find_list("file sizes");
		if (file_sizes_ent == 0)
		{
			ec.ec = errors::missing_file_sizes;
			return false;
		}
		
		if (file_sizes_ent-&gt;list_size() == 0)
		{
			ec.ec = errors::no_files_in_resume_data;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(35)">src/block_cache.cpp:844</a></td><td>it's somewhat expensive to iterate over this linked list. Presumably because of the random access of memory. It would be nice if pieces with no evictable blocks weren't in this list</td></tr><tr id="35" style="display: none;" colspan="3"><td colspan="3"><h2>it's somewhat expensive to iterate over
this linked list. Presumably because of the random access
of memory. It would be nice if pieces with no evictable
blocks weren't in this list</h2><h4>src/block_cache.cpp:844</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	else if (m_last_cache_op == ghost_hit_lru1)
	{
		// when we insert new items or move things from L1 to L2
		// evict blocks from L2
		lru_list[1] = &amp;m_lru[cached_piece_entry::read_lru2];
		lru_list[2] = &amp;m_lru[cached_piece_entry::read_lru1];
	}
	else
	{
		// when we get cache hits in L2 evict from L1
		lru_list[1] = &amp;m_lru[cached_piece_entry::read_lru1];
		lru_list[2] = &amp;m_lru[cached_piece_entry::read_lru2];
	}

	// end refers to which end of the ARC cache we're evicting
	// from. The LFU or the LRU end
	for (int end = 0; num &gt; 0 &amp;&amp; end &lt; 3; ++end)
	{
		// iterate over all blocks in order of last being used (oldest first) and as
		// long as we still have blocks to evict
<div style="background: #ffff00" width="100%">		for (list_iterator i = lru_list[end]-&gt;iterate(); i.get() &amp;&amp; num &gt; 0;)
</div>		{
			cached_piece_entry* pe = reinterpret_cast&lt;cached_piece_entry*&gt;(i.get());
			TORRENT_PIECE_ASSERT(pe-&gt;in_use, pe);
			i.next();

			if (pe == ignore)
				continue;

			if (pe-&gt;ok_to_evict())
			{
#ifdef TORRENT_DEBUG
				for (int j = 0; j &lt; pe-&gt;blocks_in_piece; ++j)
					TORRENT_PIECE_ASSERT(pe-&gt;blocks[j].buf == 0, pe);
#endif
				TORRENT_PIECE_ASSERT(pe-&gt;refcount == 0, pe);
				move_to_ghost(pe);
				continue;
			}

			TORRENT_PIECE_ASSERT(pe-&gt;num_dirty == 0, pe);

			// all blocks are pinned in this piece, skip it
			if (pe-&gt;num_blocks &lt;= pe-&gt;pinned) continue;

			// go through the blocks and evict the ones
			// that are not dirty and not referenced
			for (int j = 0; j &lt; pe-&gt;blocks_in_piece &amp;&amp; num &gt; 0; ++j)
			{
				cached_block_entry&amp; b = pe-&gt;blocks[j];

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(36)">src/block_cache.cpp:909</a></td><td>this should probably only be done every n:th time</td></tr><tr id="36" style="display: none;" colspan="3"><td colspan="3"><h2>this should probably only be done every n:th time</h2><h4>src/block_cache.cpp:909</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
			if (pe-&gt;ok_to_evict())
			{
#ifdef TORRENT_DEBUG
				for (int j = 0; j &lt; pe-&gt;blocks_in_piece; ++j)
					TORRENT_PIECE_ASSERT(pe-&gt;blocks[j].buf == 0, pe);
#endif
				move_to_ghost(pe);
			}
		}
	}

	// if we can't evict enough blocks from the read cache, also
	// look at write cache pieces for blocks that have already
	// been written to disk and can be evicted
	// the first pass, we only evict blocks that have
	// been hashed, the second pass we flush anything
	// this is potentially a very expensive operation, since
	// we're likely to have iterate every single block in the
	// cache, and we might not get to evict anything.
<div style="background: #ffff00" width="100%">	if (num &gt; 0 &amp;&amp; m_read_cache_size &gt; m_pinned_blocks)
</div>	{
		for (int pass = 0; pass &lt; 2 &amp;&amp; num &gt; 0; ++pass)
		{
			for (list_iterator i = m_lru[cached_piece_entry::write_lru].iterate(); i.get() &amp;&amp; num &gt; 0;)
			{
				cached_piece_entry* pe = reinterpret_cast&lt;cached_piece_entry*&gt;(i.get());
				TORRENT_PIECE_ASSERT(pe-&gt;in_use, pe);

				i.next();

				if (pe == ignore)
					continue;

				if (pe-&gt;ok_to_evict())
				{
#ifdef TORRENT_DEBUG
					for (int j = 0; j &lt; pe-&gt;blocks_in_piece; ++j)
						TORRENT_PIECE_ASSERT(pe-&gt;blocks[j].buf == 0, pe);
#endif
					TORRENT_PIECE_ASSERT(pe-&gt;refcount == 0, pe);
					erase_piece(pe);
					continue;
				}

				// all blocks in this piece are dirty
				if (pe-&gt;num_dirty == pe-&gt;num_blocks)
					continue;

				int end = pe-&gt;blocks_in_piece;

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(37)">src/bt_peer_connection.cpp:682</a></td><td>this could be optimized using knuth morris pratt</td></tr><tr id="37" style="display: none;" colspan="3"><td colspan="3"><h2>this could be optimized using knuth morris pratt</h2><h4>src/bt_peer_connection.cpp:682</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		if (m_encrypted &amp;&amp; m_rc4_encrypted)
		{
			fun = encrypt;
			userdata = m_enc_handler.get();
		}
#endif
		
		peer_connection::send_buffer(buf, size, flags, fun, userdata);
	}

	int bt_peer_connection::get_syncoffset(char const* src, int src_size,
		char const* target, int target_size) const
	{
		TORRENT_ASSERT(target_size &gt;= src_size);
		TORRENT_ASSERT(src_size &gt; 0);
		TORRENT_ASSERT(src);
		TORRENT_ASSERT(target);

		int traverse_limit = target_size - src_size;

<div style="background: #ffff00" width="100%">		for (int i = 0; i &lt; traverse_limit; ++i)
</div>		{
			char const* target_ptr = target + i;
			if (std::equal(src, src+src_size, target_ptr))
				return i;
		}

//	    // Partial sync
// 		for (int i = 0; i &lt; target_size; ++i)
// 		{
// 			// first is iterator in src[] at which mismatch occurs
// 			// second is iterator in target[] at which mismatch occurs
// 			std::pair&lt;const char*, const char*&gt; ret;
// 			int src_sync_size;
//  			if (i &gt; traverse_limit) // partial sync test
//  			{
//  				ret = std::mismatch(src, src + src_size - (i - traverse_limit), &amp;target[i]);
//  				src_sync_size = ret.first - src;
//  				if (src_sync_size == (src_size - (i - traverse_limit)))
//  					return i;
//  			}
//  			else // complete sync test
// 			{
// 				ret = std::mismatch(src, src + src_size, &amp;target[i]);
// 				src_sync_size = ret.first - src;
// 				if (src_sync_size == src_size)
// 					return i;
// 			}
// 		}

        // no complete sync
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(38)">src/bt_peer_connection.cpp:2151</a></td><td>if we're finished, send upload_only message</td></tr><tr id="38" style="display: none;" colspan="3"><td colspan="3"><h2>if we're finished, send upload_only message</h2><h4>src/bt_peer_connection.cpp:2151</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		}
		peer_log("==&gt; BITFIELD [ %s ]", bitfield_string.c_str());
#endif
#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
		m_sent_bitfield = true;
#endif

		send_buffer(msg, packet_size);

		m_ses.inc_stats_counter(counters::num_outgoing_bitfield);

		if (num_lazy_pieces &gt; 0)
		{
			for (int i = 0; i &lt; num_lazy_pieces; ++i)
			{
#ifdef TORRENT_VERBOSE_LOGGING
				peer_log("==&gt; HAVE    [ piece: %d ]", lazy_pieces[i]);
#endif
				write_have(lazy_pieces[i]);
			}
<div style="background: #ffff00" width="100%">		}
</div>
		if (m_supports_fast)
			send_allowed_set();
	}

#ifndef TORRENT_DISABLE_EXTENSIONS
	void bt_peer_connection::write_extensions()
	{
		INVARIANT_CHECK;

		TORRENT_ASSERT(m_supports_extensions);
		TORRENT_ASSERT(m_sent_handshake);

		entry handshake;
		entry::dictionary_type&amp; m = handshake["m"].dict();

		// only send the port in case we bade the connection
		// on incoming connections the other end already knows
		// our listen port
		if (!m_settings.get_bool(settings_pack::anonymous_mode))
		{
			if (is_outgoing()) handshake["p"] = m_ses.listen_port();
			handshake["v"] = m_settings.get_str(settings_pack::handshake_client_version).empty()
				? m_settings.get_str(settings_pack::user_agent)
				: m_settings.get_str(settings_pack::handshake_client_version);
		}

		std::string remote_address;
		std::back_insert_iterator&lt;std::string&gt; out(remote_address);
		detail::write_address(remote().address(), out);
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(39)">src/disk_io_thread.cpp:856</a></td><td>instead of doing a lookup each time through the loop, save cached_piece_entry pointers with piece_refcount incremented to pin them</td></tr><tr id="39" style="display: none;" colspan="3"><td colspan="3"><h2>instead of doing a lookup each time through the loop, save
cached_piece_entry pointers with piece_refcount incremented to pin them</h2><h4>src/disk_io_thread.cpp:856</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	// this is why we pass in 1 as cont_block to the flushing functions
	void disk_io_thread::try_flush_write_blocks(int num, tailqueue&amp; completed_jobs
		, mutex::scoped_lock&amp; l)
	{
		DLOG("try_flush_write_blocks: %d\n", num);

		list_iterator range = m_disk_cache.write_lru_pieces();
		std::vector&lt;std::pair&lt;piece_manager*, int&gt; &gt; pieces;
		pieces.reserve(m_disk_cache.num_write_lru_pieces());

		for (list_iterator p = range; p.get() &amp;&amp; num &gt; 0; p.next())
		{
			cached_piece_entry* e = (cached_piece_entry*)p.get();
			if (e-&gt;num_dirty == 0) continue;
			pieces.push_back(std::make_pair(e-&gt;storage.get(), e-&gt;piece));
		}

		for (std::vector&lt;std::pair&lt;piece_manager*, int&gt; &gt;::iterator i = pieces.begin()
			, end(pieces.end()); i != end; ++i)
		{
<div style="background: #ffff00" width="100%">			cached_piece_entry* pe = m_disk_cache.find_piece(i-&gt;first, i-&gt;second);
</div>			if (pe == NULL) continue;

			// another thread may flush this piece while we're looping and
			// evict it into a read piece and then also evict it to ghost
			if (pe-&gt;cache_state != cached_piece_entry::write_lru) continue;

#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
			pe-&gt;piece_log.push_back(piece_log_t(piece_log_t::try_flush_write_blocks, -1));
#endif
			++pe-&gt;piece_refcount;
			kick_hasher(pe, l);
			num -= try_flush_hashed(pe, 1, completed_jobs, l);
			--pe-&gt;piece_refcount;
		}

		// when the write cache is under high pressure, it is likely
		// counter productive to actually do this, since a piece may
		// not have had its flush_hashed job run on it 
		// so only do it if no other thread is currently flushing

		if (num == 0 || m_num_writing_threads &gt; 0) return;

		// if we still need to flush blocks, start over and flush
		// everything in LRU order (degrade to lru cache eviction)
		for (std::vector&lt;std::pair&lt;piece_manager*, int&gt; &gt;::iterator i = pieces.begin()
			, end(pieces.end()); i != end; ++i)
		{
			cached_piece_entry* pe = m_disk_cache.find_piece(i-&gt;first, i-&gt;second);
			if (pe == NULL) continue;
			if (pe-&gt;num_dirty == 0) continue;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(40)">src/disk_io_thread.cpp:1067</a></td><td>instead of doing this. pass in the settings to each storage_interface call. Each disk thread could hold its most recent understanding of the settings in a shared_ptr, and update it every time it wakes up from a job. That way each access to the settings won't require a mutex to be held.</td></tr><tr id="40" style="display: none;" colspan="3"><td colspan="3"><h2>instead of doing this. pass in the settings to each storage_interface
call. Each disk thread could hold its most recent understanding of the settings
in a shared_ptr, and update it every time it wakes up from a job. That way
each access to the settings won't require a mutex to be held.</h2><h4>src/disk_io_thread.cpp:1067</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	{
		INVARIANT_CHECK;
		TORRENT_ASSERT(j-&gt;next == 0);
		TORRENT_ASSERT((j-&gt;flags &amp; disk_io_job::in_progress) || !j-&gt;storage);

		mutex::scoped_lock l(m_cache_mutex);

		check_cache_level(l, completed_jobs);

		DLOG("perform_job job: %s ( %s%s) piece: %d offset: %d outstanding: %d\n"
			, job_action_name[j-&gt;action]
			, (j-&gt;flags &amp; disk_io_job::fence) ? "fence ": ""
			, (j-&gt;flags &amp; disk_io_job::force_copy) ? "force_copy ": ""
			, j-&gt;piece, j-&gt;d.io.offset
			, j-&gt;storage ? j-&gt;storage-&gt;num_outstanding_jobs() : -1);

		l.unlock();

		boost::intrusive_ptr&lt;piece_manager&gt; storage = j-&gt;storage;

<div style="background: #ffff00" width="100%">		if (storage &amp;&amp; storage-&gt;get_storage_impl()-&gt;m_settings == 0)
</div>			storage-&gt;get_storage_impl()-&gt;m_settings = &amp;m_settings;

		TORRENT_ASSERT(j-&gt;action &lt; sizeof(job_functions)/sizeof(job_functions[0]));

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(41)">src/disk_io_thread.cpp:1076</a></td><td>hold disk_io_thread mutex here!</td></tr><tr id="41" style="display: none;" colspan="3"><td colspan="3"><h2>hold disk_io_thread mutex here!</h2><h4>src/disk_io_thread.cpp:1076</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		mutex::scoped_lock l(m_cache_mutex);

		check_cache_level(l, completed_jobs);

		DLOG("perform_job job: %s ( %s%s) piece: %d offset: %d outstanding: %d\n"
			, job_action_name[j-&gt;action]
			, (j-&gt;flags &amp; disk_io_job::fence) ? "fence ": ""
			, (j-&gt;flags &amp; disk_io_job::force_copy) ? "force_copy ": ""
			, j-&gt;piece, j-&gt;d.io.offset
			, j-&gt;storage ? j-&gt;storage-&gt;num_outstanding_jobs() : -1);

		l.unlock();

		boost::intrusive_ptr&lt;piece_manager&gt; storage = j-&gt;storage;

		if (storage &amp;&amp; storage-&gt;get_storage_impl()-&gt;m_settings == 0)
			storage-&gt;get_storage_impl()-&gt;m_settings = &amp;m_settings;

		TORRENT_ASSERT(j-&gt;action &lt; sizeof(job_functions)/sizeof(job_functions[0]));

<div style="background: #ffff00" width="100%">		if (time_now() &gt; m_last_stats_flip + seconds(1)) flip_stats();
</div>
		ptime start_time = time_now_hires();

		++m_outstanding_jobs;

		// call disk function
		int ret = (this-&gt;*(job_functions[j-&gt;action]))(j, completed_jobs);

		--m_outstanding_jobs;

		if (ret == retry_job)
		{
			mutex::scoped_lock l(m_job_mutex);
			// to avoid busy looping here, give up
			// our quanta in case there aren't any other
			// jobs to run in between

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(42)">src/disk_io_thread.cpp:1095</a></td><td>a potentially more efficient solution would be to have a special queue for retry jobs, that's only ever run when a job completes, in any thread. It would only work if m_outstanding_jobs > 0</td></tr><tr id="42" style="display: none;" colspan="3"><td colspan="3"><h2>a potentially more efficient solution would be to have a special
queue for retry jobs, that's only ever run when a job completes, in
any thread. It would only work if m_outstanding_jobs > 0</h2><h4>src/disk_io_thread.cpp:1095</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		TORRENT_ASSERT(j-&gt;action &lt; sizeof(job_functions)/sizeof(job_functions[0]));

		if (time_now() &gt; m_last_stats_flip + seconds(1)) flip_stats();

		ptime start_time = time_now_hires();

		++m_outstanding_jobs;

		// call disk function
		int ret = (this-&gt;*(job_functions[j-&gt;action]))(j, completed_jobs);

		--m_outstanding_jobs;

		if (ret == retry_job)
		{
			mutex::scoped_lock l(m_job_mutex);
			// to avoid busy looping here, give up
			// our quanta in case there aren't any other
			// jobs to run in between

<div style="background: #ffff00" width="100%">
</div>			TORRENT_ASSERT((j-&gt;flags &amp; disk_io_job::in_progress) || !j-&gt;storage);
	
			bool need_sleep = m_queued_jobs.empty();
			m_queued_jobs.push_back(j);
			l.unlock();
			if (need_sleep) sleep(0);
			return;
		}

#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(43)">src/disk_io_thread.cpp:1109</a></td><td>it should clear the hash state even when there's an error, right?</td></tr><tr id="43" style="display: none;" colspan="3"><td colspan="3"><h2>it should clear the hash state even when there's an error, right?</h2><h4>src/disk_io_thread.cpp:1109</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		--m_outstanding_jobs;

		if (ret == retry_job)
		{
			mutex::scoped_lock l(m_job_mutex);
			// to avoid busy looping here, give up
			// our quanta in case there aren't any other
			// jobs to run in between


			TORRENT_ASSERT((j-&gt;flags &amp; disk_io_job::in_progress) || !j-&gt;storage);
	
			bool need_sleep = m_queued_jobs.empty();
			m_queued_jobs.push_back(j);
			l.unlock();
			if (need_sleep) sleep(0);
			return;
		}

#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
<div style="background: #ffff00" width="100%">		if (j-&gt;action == disk_io_job::hash &amp;&amp; !j-&gt;error.ec)
</div>		{
			// a hash job should never return without clearing pe-&gt;hash
			l.lock();
			cached_piece_entry* pe = m_disk_cache.find_piece(j);
			if (pe != NULL)
			{
				TORRENT_PIECE_ASSERT(pe-&gt;hash == NULL, pe);
			}
			l.unlock();
		}
#endif

		if (ret == defer_handler) return;

		j-&gt;ret = ret;

		ptime now = time_now_hires();
		m_job_time.add_sample(total_microseconds(now - start_time));
		completed_jobs.push_back(j);
	}

	int disk_io_thread::do_uncached_read(disk_io_job* j)
	{
		j-&gt;buffer = m_disk_cache.allocate_buffer("send buffer");
		if (j-&gt;buffer == 0)
		{
			j-&gt;error.ec = error::no_memory;
			j-&gt;error.operation = storage_error::alloc_cache_piece;
			return -1;
		}
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(44)">src/disk_io_thread.cpp:1702</a></td><td>maybe the tailqueue_iterator should contain a pointer-pointer instead and have an unlink function</td></tr><tr id="44" style="display: none;" colspan="3"><td colspan="3"><h2>maybe the tailqueue_iterator should contain a pointer-pointer
instead and have an unlink function</h2><h4>src/disk_io_thread.cpp:1702</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	{
		disk_io_job* j = allocate_job(disk_io_job::release_files);
		j-&gt;storage = storage;
		j-&gt;callback = handler;

		add_fence_job(storage, j);
	}

	void disk_io_thread::async_delete_files(piece_manager* storage
		, boost::function&lt;void(disk_io_job const*)&gt; const&amp; handler)
	{
		// remove cache blocks belonging to this torrent
		tailqueue completed_jobs;
		mutex::scoped_lock l(m_cache_mutex);
		flush_cache(storage, flush_delete_cache, completed_jobs, l);
		l.unlock();

		// remove outstanding jobs belonging to this torrent
		mutex::scoped_lock l2(m_job_mutex);

<div style="background: #ffff00" width="100%">		disk_io_job* qj = (disk_io_job*)m_queued_jobs.get_all();
</div>		tailqueue to_abort;

		while (qj)
		{
			disk_io_job* next = (disk_io_job*)qj-&gt;next;
#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
			qj-&gt;next = NULL;
#endif
			if (qj-&gt;storage == storage)
				to_abort.push_back(qj);
			else
				m_queued_jobs.push_back(qj);
			qj = next;
		}
		l2.unlock();

		if (completed_jobs.size())
			add_completed_jobs(completed_jobs);

		disk_io_job* j = allocate_job(disk_io_job::delete_files);
		j-&gt;storage = storage;
		j-&gt;callback = handler;
		add_fence_job(storage, j);

		fail_jobs_impl(storage_error(boost::asio::error::operation_aborted), to_abort, completed_jobs);
	}

	void disk_io_thread::async_check_fastresume(piece_manager* storage
		, lazy_entry const* resume_data
		, boost::function&lt;void(disk_io_job const*)&gt; const&amp; handler)
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(45)">src/disk_io_thread.cpp:1880</a></td><td>this is potentially very expensive. One way to solve it would be to have a fence for just this one piece.</td></tr><tr id="45" style="display: none;" colspan="3"><td colspan="3"><h2>this is potentially very expensive. One way to solve
it would be to have a fence for just this one piece.</h2><h4>src/disk_io_thread.cpp:1880</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		{
			tailqueue temp;
			m_disk_cache.evict_piece(*(i++), temp);
			jobs.append(temp);
		}
		fail_jobs(storage_error(boost::asio::error::operation_aborted), jobs);
	}

	void disk_io_thread::async_clear_piece(piece_manager* storage, int index
		, boost::function&lt;void(disk_io_job const*)&gt; const&amp; handler)
	{
		disk_io_job* j = allocate_job(disk_io_job::clear_piece);
		j-&gt;storage = storage;
		j-&gt;piece = index;
		j-&gt;callback = handler;

		// regular jobs are not guaranteed to be executed in-order
		// since clear piece must guarantee that all write jobs that
		// have been issued finish before the clear piece job completes

<div style="background: #ffff00" width="100%">		add_fence_job(storage, j);
</div>	}

	void disk_io_thread::clear_piece(piece_manager* storage, int index)	
	{
		mutex::scoped_lock l(m_cache_mutex);

		cached_piece_entry* pe = m_disk_cache.find_piece(storage, index);
		if (pe == 0) return;
		TORRENT_PIECE_ASSERT(pe-&gt;hashing == false, pe);
		pe-&gt;hashing_done = 0;
		delete pe-&gt;hash;
		pe-&gt;hash = NULL;

		// evict_piece returns true if the piece was in fact
		// evicted. A piece may fail to be evicted if there
		// are still outstanding operations on it, which should
		// never be the case when this function is used
		// in fact, no jobs should really be hung on this piece
		// at this point
		tailqueue jobs;
		bool ok = m_disk_cache.evict_piece(pe, jobs);
		TORRENT_PIECE_ASSERT(ok, pe);
		fail_jobs(storage_error(boost::asio::error::operation_aborted), jobs);
	}

	void disk_io_thread::kick_hasher(cached_piece_entry* pe, mutex::scoped_lock&amp; l)
	{
		if (!pe-&gt;hash) return;
		if (pe-&gt;hashing) return;

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(46)">src/disk_io_thread.cpp:2131</a></td><td>we should probably just hang the job on the piece and make sure the hasher gets kicked</td></tr><tr id="46" style="display: none;" colspan="3"><td colspan="3"><h2>we should probably just hang the job on the piece and make sure the hasher gets kicked</h2><h4>src/disk_io_thread.cpp:2131</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		if (pe == NULL)
		{
			int cache_state = (j-&gt;flags &amp; disk_io_job::volatile_read)
				? cached_piece_entry::volatile_read_lru
				: cached_piece_entry::read_lru1;
			pe = m_disk_cache.allocate_piece(j, cache_state);
		}
		if (pe == NULL)
		{
			j-&gt;error.ec = error::no_memory;
			j-&gt;error.operation = storage_error::alloc_cache_piece;
			return -1;
		}

		if (pe-&gt;hashing)
		{
			TORRENT_PIECE_ASSERT(pe-&gt;hash, pe);
			// another thread is hashing this piece right now
			// try again in a little bit
			DLOG("do_hash: retry\n");
<div style="background: #ffff00" width="100%">			return retry_job;
</div>		}

		pe-&gt;hashing = 1;

		TORRENT_PIECE_ASSERT(pe-&gt;cache_state &lt;= cached_piece_entry::read_lru1 || pe-&gt;cache_state == cached_piece_entry::read_lru2, pe);
		++pe-&gt;piece_refcount;

		if (pe-&gt;hash == NULL)
		{
			pe-&gt;hashing_done = 0;
			pe-&gt;hash = new partial_hash;
		}
		partial_hash* ph = pe-&gt;hash;

		int block_size = m_disk_cache.block_size();
		int blocks_in_piece = (piece_size + block_size - 1) / block_size;
		
		file::iovec_t iov;
		int ret = 0;

		// keep track of which blocks we have locked by incrementing
		// their refcounts. This is used to decrement only these blocks
		// later.
		int* locked_blocks = TORRENT_ALLOCA(int, blocks_in_piece);
		memset(locked_blocks, 0, blocks_in_piece * sizeof(int));
		int num_locked_blocks = 0;

		// increment the refcounts of all
		// blocks up front, and then hash them without holding the lock
		TORRENT_PIECE_ASSERT(ph-&gt;offset % block_size == 0, pe);
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(47)">src/disk_io_thread.cpp:2198</a></td><td>introduce a holder class that automatically increments and decrements the piece_refcount</td></tr><tr id="47" style="display: none;" colspan="3"><td colspan="3"><h2>introduce a holder class that automatically increments
and decrements the piece_refcount</h2><h4>src/disk_io_thread.cpp:2198</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		for (int i = ph-&gt;offset / block_size; i &lt; blocks_in_piece; ++i)
		{
			iov.iov_len = (std::min)(block_size, piece_size - ph-&gt;offset);

			if (next_locked_block &lt; num_locked_blocks
				&amp;&amp; locked_blocks[next_locked_block] == i)
			{
				++next_locked_block;
				TORRENT_PIECE_ASSERT(pe-&gt;blocks[i].buf, pe);
				TORRENT_PIECE_ASSERT(ph-&gt;offset == i * block_size, pe);
				ph-&gt;offset += iov.iov_len;
				ph-&gt;h.update(pe-&gt;blocks[i].buf, iov.iov_len);
			}
			else
			{
				iov.iov_base = m_disk_cache.allocate_buffer("hashing");

				if (iov.iov_base == NULL)
				{
					l.lock();
<div style="background: #ffff00" width="100%">
</div>					// decrement the refcounts of the blocks we just hashed
					for (int i = 0; i &lt; num_locked_blocks; ++i)
						m_disk_cache.dec_block_refcount(pe, locked_blocks[i], block_cache::ref_hashing);

					--pe-&gt;piece_refcount;
					pe-&gt;hashing = false;
					delete pe-&gt;hash;
					pe-&gt;hash = NULL;

					m_disk_cache.maybe_free_piece(pe);

					j-&gt;error.ec = errors::no_memory;
					j-&gt;error.operation = storage_error::alloc_cache_piece;
					return -1;
				}

				DLOG("do_hash: reading (piece: %d block: %d)\n", int(pe-&gt;piece), i);

				ptime start_time = time_now_hires();

				TORRENT_PIECE_ASSERT(ph-&gt;offset == i * block_size, pe);
				ret = j-&gt;storage-&gt;get_storage_impl()-&gt;readv(&amp;iov, 1, j-&gt;piece
						, ph-&gt;offset, file_flags, j-&gt;error);

				if (ret &lt; 0)
				{
					m_disk_cache.free_buffer((char*)iov.iov_base);
					l.lock();
					break;
				}
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(48)">src/disk_io_thread.cpp:2416</a></td><td>it would be nice to not have to lock the mutex every turn through this loop</td></tr><tr id="48" style="display: none;" colspan="3"><td colspan="3"><h2>it would be nice to not have to lock the mutex every
turn through this loop</h2><h4>src/disk_io_thread.cpp:2416</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		{
			j-&gt;error.ec = error::no_memory;
			j-&gt;error.operation = storage_error::alloc_cache_piece;
			return -1;
		}

#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
		pe-&gt;piece_log.push_back(piece_log_t(j-&gt;action));
#endif
		TORRENT_PIECE_ASSERT(pe-&gt;cache_state &lt;= cached_piece_entry::read_lru1 || pe-&gt;cache_state == cached_piece_entry::read_lru2, pe);
		++pe-&gt;piece_refcount;

		int block_size = m_disk_cache.block_size();
		int piece_size = j-&gt;storage-&gt;files()-&gt;piece_size(j-&gt;piece);
		int blocks_in_piece = (piece_size + block_size - 1) / block_size;
		
		file::iovec_t iov;
		int ret = 0;
		int offset = 0;

<div style="background: #ffff00" width="100%">		for (int i = 0; i &lt; blocks_in_piece; ++i)
</div>		{
			iov.iov_len = (std::min)(block_size, piece_size - offset);

			// is the block already in the cache?
			if (pe-&gt;blocks[i].buf) continue;
			l.unlock();

			iov.iov_base = m_disk_cache.allocate_buffer("read cache");

			if (iov.iov_base == NULL)
			{
				//#error introduce a holder class that automatically increments and decrements the piece_refcount
				--pe-&gt;piece_refcount;
				m_disk_cache.maybe_free_piece(pe);
				j-&gt;error.ec = errors::no_memory;
				j-&gt;error.operation = storage_error::alloc_cache_piece;
				return -1;
			}

			DLOG("do_cache_piece: reading (piece: %d block: %d)\n"
				, int(pe-&gt;piece), i);

			ptime start_time = time_now_hires();

			ret = j-&gt;storage-&gt;get_storage_impl()-&gt;readv(&amp;iov, 1, j-&gt;piece
				, offset, file_flags, j-&gt;error);

			if (ret &lt; 0)
			{
				l.lock();
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(49)">src/http_tracker_connection.cpp:100</a></td><td>support authentication (i.e. user name and password) in the URL</td></tr><tr id="49" style="display: none;" colspan="3"><td colspan="3"><h2>support authentication (i.e. user name and password) in the URL</h2><h4>src/http_tracker_connection.cpp:100</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		, aux::session_impl const&amp; ses
		, proxy_settings const&amp; ps
		, std::string const&amp; auth
#if TORRENT_USE_I2P
		, i2p_connection* i2p_conn
#endif
		)
		: tracker_connection(man, req, ios, c)
		, m_man(man)
		, m_ses(ses)
		, m_ps(ps)
		, m_cc(cc)
		, m_ios(ios)
#if TORRENT_USE_I2P
		, m_i2p_conn(i2p_conn)
#endif
	{}

	void http_tracker_connection::start()
	{
<div style="background: #ffff00" width="100%">		std::string url = tracker_req().url;
</div>
		if (tracker_req().kind == tracker_request::scrape_request)
		{
			// find and replace "announce" with "scrape"
			// in request

			std::size_t pos = url.find("announce");
			if (pos == std::string::npos)
			{
				m_ios.post(boost::bind(&amp;http_tracker_connection::fail_disp, self()
					, error_code(errors::scrape_not_available)));
				return;
			}
			url.replace(pos, 8, "scrape");
		}
		
#if TORRENT_USE_I2P
		bool i2p = is_i2p_url(url);
#else
		static const bool i2p = false;
#endif

		aux::session_settings const&amp; settings = m_ses.settings();

		// if request-string already contains
		// some parameters, append an ampersand instead
		// of a question mark
		size_t arguments_start = url.find('?');
		if (arguments_start != std::string::npos)
			url += "&amp;";
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(50)">src/metadata_transfer.cpp:365</a></td><td>this is not safe. The torrent could be unloaded while we're still sending the metadata</td></tr><tr id="50" style="display: none;" colspan="3"><td colspan="3"><h2>this is not safe. The torrent could be unloaded while
we're still sending the metadata</h2><h4>src/metadata_transfer.cpp:365</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">				char* ptr = msg;

#ifdef TORRENT_VERBOSE_LOGGING
				(*m_pc.m_logger) &lt;&lt; time_now_string()
					&lt;&lt; " ==&gt; METADATA [ start: " &lt;&lt; req.first
					&lt;&lt; " | size: " &lt;&lt; req.second
					&lt;&lt; " | offset: " &lt;&lt; offset.first
					&lt;&lt; " | byte_size: " &lt;&lt; offset.second
					&lt;&lt; " ]\n";
#endif
				// yes, we have metadata, send it
				detail::write_uint32(11 + offset.second, ptr);
				detail::write_uint8(bt_peer_connection::msg_extended, ptr);
				detail::write_uint8(m_message_index, ptr);
				// means 'data packet'
				detail::write_uint8(1, ptr);
				detail::write_uint32((int)m_tp.metadata().left(), ptr);
				detail::write_uint32(offset.first, ptr);
				m_pc.send_buffer(msg, sizeof(msg));

<div style="background: #ffff00" width="100%">				char const* metadata = m_tp.metadata().begin;
</div>				m_pc.append_const_send_buffer(metadata + offset.first, offset.second);
			}
			else
			{
#ifdef TORRENT_VERBOSE_LOGGING
				(*m_pc.m_logger) &lt;&lt; time_now_string()
					&lt;&lt; " ==&gt; DONT HAVE METADATA\n";
#endif
				char msg[4+3];
				char* ptr = msg;

				// we don't have the metadata, reply with
				// don't have-message
				detail::write_uint32(1 + 2, ptr);
				detail::write_uint8(bt_peer_connection::msg_extended, ptr);
				detail::write_uint8(m_message_index, ptr);
				// means 'have no data'
				detail::write_uint8(2, ptr);
				m_pc.send_buffer(msg, sizeof(msg));
			}
			m_pc.setup_send();
		}

		virtual bool on_extended(int length
			, int msg, buffer::const_interval body)
		{
			if (msg != 14) return false;
			if (m_message_index == 0) return false;

			if (length &gt; 500 * 1024)
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(51)">src/packet_buffer.cpp:176</a></td><td>use compare_less_wrap for this comparison as well</td></tr><tr id="51" style="display: none;" colspan="3"><td colspan="3"><h2>use compare_less_wrap for this comparison as well</h2><h4>src/packet_buffer.cpp:176</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		while (new_size &lt; size)
			new_size &lt;&lt;= 1;

		void** new_storage = (void**)malloc(sizeof(void*) * new_size);

		for (index_type i = 0; i &lt; new_size; ++i)
			new_storage[i] = 0;

		for (index_type i = m_first; i &lt; (m_first + m_capacity); ++i)
			new_storage[i &amp; (new_size - 1)] = m_storage[i &amp; (m_capacity - 1)];

		free(m_storage);

		m_storage = new_storage;
		m_capacity = new_size;
	}

	void* packet_buffer::remove(index_type idx)
	{
		INVARIANT_CHECK;
<div style="background: #ffff00" width="100%">		if (idx &gt;= m_first + m_capacity)
</div>			return 0;

		if (compare_less_wrap(idx, m_first, 0xffff))
			return 0;

		const int mask = (m_capacity - 1);
		void* old_value = m_storage[idx &amp; mask];
		m_storage[idx &amp; mask] = 0;

		if (old_value)
		{
			--m_size;
			if (m_size == 0) m_last = m_first;
		}

		if (idx == m_first &amp;&amp; m_size != 0)
		{
			++m_first;
			for (boost::uint32_t i = 0; i &lt; m_capacity; ++i, ++m_first)
				if (m_storage[m_first &amp; mask]) break;
			m_first &amp;= 0xffff;
		}

		if (((idx + 1) &amp; 0xffff) == m_last &amp;&amp; m_size != 0)
		{
			--m_last;
			for (boost::uint32_t i = 0; i &lt; m_capacity; ++i, --m_last)
				if (m_storage[m_last &amp; mask]) break;
			++m_last;
			m_last &amp;= 0xffff;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(52)">src/part_file.cpp:240</a></td><td>what do we do if someone is currently reading from the disk from this piece? does it matter? Since we won't actively erase the data from disk, but it may be overwritten soon, it's probably not that big of a deal</td></tr><tr id="52" style="display: none;" colspan="3"><td colspan="3"><h2>what do we do if someone is currently reading from the disk
from this piece? does it matter? Since we won't actively erase the
data from disk, but it may be overwritten soon, it's probably not that
big of a deal</h2><h4>src/part_file.cpp:240</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		return m_file.readv(slot_offset + offset, bufs, num_bufs, ec);
	}

	void part_file::open_file(int mode, error_code&amp; ec)
	{
		if (m_file.is_open()
			&amp;&amp; ((m_file.open_mode() &amp; file::rw_mask) == mode
				|| mode == file::read_only)) return;

		std::string fn = combine_path(m_path, m_name);
		m_file.open(fn, mode, ec);
	}

	void part_file::free_piece(int piece, error_code&amp; ec)
	{
		mutex::scoped_lock l(m_mutex);

		boost::unordered_map&lt;int, int&gt;::iterator i = m_piece_map.find(piece);
		if (i == m_piece_map.end()) return;

<div style="background: #ffff00" width="100%">
</div>		m_free_slots.push_back(i-&gt;second);
		m_piece_map.erase(i);
		m_dirty_metadata = true;
	}

	void part_file::move_partfile(std::string const&amp; path, error_code&amp; ec)
	{
		mutex::scoped_lock l(m_mutex);

		flush_metadata_impl(ec);
		if (ec) return;

		if (!m_piece_map.empty())
		{
			std::string old_path = combine_path(m_path, m_name);
			std::string new_path = combine_path(path, m_name);

			rename(old_path, new_path, ec);
			if (ec == boost::system::errc::no_such_file_or_directory)
				ec.clear();

			if (ec)
			{
				copy_file(old_path, new_path, ec);
				if (ec) return;
				remove(old_path, ec);
			}
		}
		m_path = path;
	}
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(53)">src/part_file.cpp:330</a></td><td>instead of rebuilding the whole file header and flushing it, update the slot entries as we go</td></tr><tr id="53" style="display: none;" colspan="3"><td colspan="3"><h2>instead of rebuilding the whole file header
and flushing it, update the slot entries as we go</h2><h4>src/part_file.cpp:330</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">				if (block_to_copy == m_piece_size)
				{
					m_free_slots.push_back(i-&gt;second);
					m_piece_map.erase(i);
					m_dirty_metadata = true;
				}
			}
			file_offset += block_to_copy;
			piece_offset = 0;
			size -= block_to_copy;
		}
	}

	void part_file::flush_metadata(error_code&amp; ec)
	{
		mutex::scoped_lock l(m_mutex);

		flush_metadata_impl(ec);
	}

<div style="background: #ffff00" width="100%">	void part_file::flush_metadata_impl(error_code&amp; ec)
</div>	{
		// do we need to flush the metadata?
		if (m_dirty_metadata == false) return;

		if (m_piece_map.empty())
		{
			// if we don't have any pieces left in the
			// part file, remove it
			std::string p = combine_path(m_path, m_name);
			remove(p, ec);
		
			if (ec == boost::system::errc::no_such_file_or_directory)
				ec.clear();
			return;
		}

		open_file(file::read_write, ec);
		if (ec) return;

		boost::scoped_array&lt;boost::uint32_t&gt; header(new boost::uint32_t[m_header_size]);

		using namespace libtorrent::detail;

		char* ptr = (char*)header.get();

		write_uint32(m_max_pieces, ptr);
		write_uint32(m_piece_size, ptr);

		for (int piece = 0; piece &lt; m_max_pieces; ++piece)
		{
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(54)">src/peer_connection.cpp:3174</a></td><td>sort the allowed fast set in priority order</td></tr><tr id="54" style="display: none;" colspan="3"><td colspan="3"><h2>sort the allowed fast set in priority order</h2><h4>src/peer_connection.cpp:3174</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		// if the peer has the piece and we want
		// to download it, request it
		if (int(m_have_piece.size()) &gt; index
			&amp;&amp; m_have_piece[index]
			&amp;&amp; !t-&gt;has_piece_passed(index)
			&amp;&amp; t-&gt;valid_metadata()
			&amp;&amp; t-&gt;has_picker()
			&amp;&amp; !t-&gt;has_piece_passed(index)
			&amp;&amp; t-&gt;picker().piece_priority(index) &gt; 0)
		{
			t-&gt;peer_is_interesting(*this);
		}
	}

	std::vector&lt;int&gt; const&amp; peer_connection::allowed_fast()
	{
		boost::shared_ptr&lt;torrent&gt; t = m_torrent.lock();
		TORRENT_ASSERT(t);

<div style="background: #ffff00" width="100%">		return m_allowed_fast;
</div>	}

	bool peer_connection::can_request_time_critical() const
	{
		if (has_peer_choked() || !is_interesting()) return false;
		if ((int)m_download_queue.size() + (int)m_request_queue.size()
			&gt; m_desired_queue_size * 2) return false;
		if (on_parole()) return false; 
		if (m_disconnecting) return false;
		boost::shared_ptr&lt;torrent&gt; t = m_torrent.lock();
		TORRENT_ASSERT(t);
		if (t-&gt;upload_mode()) return false;
		return true;
	}

	void peer_connection::make_time_critical(piece_block const&amp; block)
	{
		std::vector&lt;pending_block&gt;::iterator rit = std::find_if(m_request_queue.begin()
			, m_request_queue.end(), has_block(block));
		if (rit == m_request_queue.end()) return;
#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
		boost::shared_ptr&lt;torrent&gt; t = m_torrent.lock();
		TORRENT_ASSERT(t);
		TORRENT_ASSERT(t-&gt;has_picker());
		TORRENT_ASSERT(t-&gt;picker().is_requested(block));
#endif
		// ignore it if it's already time critical
		if (rit - m_request_queue.begin() &lt; m_queued_time_critical) return;
		pending_block b = *rit;
		m_request_queue.erase(rit);
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(55)">src/piece_picker.cpp:2335</a></td><td>when expanding pieces for cache stripe reasons, the !downloading condition doesn't make much sense</td></tr><tr id="55" style="display: none;" colspan="3"><td colspan="3"><h2>when expanding pieces for cache stripe reasons,
the !downloading condition doesn't make much sense</h2><h4>src/piece_picker.cpp:2335</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		TORRENT_ASSERT(index &lt; (int)m_piece_map.size() || m_piece_map.empty());
		if (index+1 == (int)m_piece_map.size())
			return m_blocks_in_last_piece;
		else
			return m_blocks_per_piece;
	}

	bool piece_picker::is_piece_free(int piece, bitfield const&amp; bitmask) const
	{
		TORRENT_ASSERT(piece &gt;= 0 &amp;&amp; piece &lt; int(m_piece_map.size()));
		return bitmask[piece]
			&amp;&amp; !m_piece_map[piece].have()
			&amp;&amp; !m_piece_map[piece].filtered();
	}

	bool piece_picker::can_pick(int piece, bitfield const&amp; bitmask) const
	{
		TORRENT_ASSERT(piece &gt;= 0 &amp;&amp; piece &lt; int(m_piece_map.size()));
		return bitmask[piece]
			&amp;&amp; !m_piece_map[piece].have()
<div style="background: #ffff00" width="100%">			&amp;&amp; !m_piece_map[piece].downloading()
</div>			&amp;&amp; !m_piece_map[piece].filtered();
	}

#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
	void piece_picker::check_peers()
	{
		for (std::vector&lt;block_info&gt;::iterator i = m_block_info.begin()
			, end(m_block_info.end()); i != end; ++i)
		{
			TORRENT_ASSERT(i-&gt;peer == 0 || static_cast&lt;torrent_peer*&gt;(i-&gt;peer)-&gt;in_use);
		}
	}
#endif

	void piece_picker::clear_peer(void* peer)
	{
		for (std::vector&lt;block_info&gt;::iterator i = m_block_info.begin()
			, end(m_block_info.end()); i != end; ++i)
		{
			if (i-&gt;peer == peer) i-&gt;peer = 0;
		}
	}

	namespace
	{
		// the first bool is true if this is the only peer that has requested and downloaded
		// blocks from this piece.
		// the second bool is true if this is the only active peer that is requesting
		// and downloading blocks from this piece. Active means having a connection.
		boost::tuple&lt;bool, bool&gt; requested_from(piece_picker::downloading_piece const&amp; p
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(56)">src/session_impl.cpp:799</a></td><td>there's no rule here to make uTP connections not have the global or local rate limits apply to it. This used to be the default.</td></tr><tr id="56" style="display: none;" colspan="3"><td colspan="3"><h2>there's no rule here to make uTP connections not have the global or
local rate limits apply to it. This used to be the default.</h2><h4>src/session_impl.cpp:799</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		m_global_class = m_classes.new_peer_class("global");
		m_tcp_peer_class = m_classes.new_peer_class("tcp");
		m_local_peer_class = m_classes.new_peer_class("local");
		// local peers are always unchoked
		m_classes.at(m_local_peer_class)-&gt;ignore_unchoke_slots = true;
		// local peers are allowed to exceed the normal connection
		// limit by 50%
		m_classes.at(m_local_peer_class)-&gt;connection_limit_factor = 150;

		TORRENT_ASSERT(m_global_class == session::global_peer_class_id);
		TORRENT_ASSERT(m_tcp_peer_class == session::tcp_peer_class_id);
		TORRENT_ASSERT(m_local_peer_class == session::local_peer_class_id);

		init_peer_class_filter(true);

		// TCP, SSL/TCP and I2P connections should be assigned the TCP peer class
		m_peer_class_type_filter.add(peer_class_type_filter::tcp_socket, m_tcp_peer_class);
		m_peer_class_type_filter.add(peer_class_type_filter::ssl_tcp_socket, m_tcp_peer_class);
		m_peer_class_type_filter.add(peer_class_type_filter::i2p_socket, m_tcp_peer_class);

<div style="background: #ffff00" width="100%">
</div>#ifdef TORRENT_UPNP_LOGGING
		m_upnp_log.open("upnp.log", std::ios::in | std::ios::out | std::ios::trunc);
#endif

#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_LOGGING || defined TORRENT_ERROR_LOGGING

		char tmp[300];
		snprintf(tmp, sizeof(tmp), "libtorrent configuration: %s\n"
			"libtorrent version: %s\n"
			"libtorrent revision: %s\n\n"
		  	, TORRENT_CFG_STRING
			, LIBTORRENT_VERSION
			, LIBTORRENT_REVISION);
		(*m_logger) &lt;&lt; tmp;

		logger&amp; l = *m_logger;

		int temp = 0;
		int prev_size = 0;

		PRINT_SIZEOF(piece_picker::piece_pos)

		PRINT_SIZEOF(cached_piece_entry)
		PRINT_OFFSETOF(cached_piece_entry, prev)
		PRINT_OFFSETOF(cached_piece_entry, next)
		PRINT_OFFSETOF(cached_piece_entry, storage)
		PRINT_OFFSETOF(cached_piece_entry, jobs)
		PRINT_OFFSETOF(cached_piece_entry, read_jobs)
		PRINT_OFFSETOF(cached_piece_entry, hash)
		PRINT_OFFSETOF(cached_piece_entry, last_requester)
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(57)">src/session_impl.cpp:3231</a></td><td>should this function take a shared_ptr instead?</td></tr><tr id="57" style="display: none;" colspan="3"><td colspan="3"><h2>should this function take a shared_ptr instead?</h2><h4>src/session_impl.cpp:3231</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	{
#if defined TORRENT_ASIO_DEBUGGING
		complete_async("session_impl::on_socks_accept");
#endif
		m_socks_listen_socket.reset();
		if (e == asio::error::operation_aborted) return;
		if (e)
		{
			if (m_alerts.should_post&lt;listen_failed_alert&gt;())
				m_alerts.post_alert(listen_failed_alert(tcp::endpoint(
					address_v4::any(), m_listen_interface.port()), listen_failed_alert::accept, e));
			return;
		}
		open_new_incoming_socks_connection();
		incoming_connection(s);
	}

	// if cancel_with_cq is set, the peer connection is
	// currently expected to be scheduled for a connection
	// with the connection queue, and should be cancelled
<div style="background: #ffff00" width="100%">	void session_impl::close_connection(peer_connection* p
</div>		, error_code const&amp; ec, bool cancel_with_cq)
	{
		TORRENT_ASSERT(is_single_thread());
		boost::shared_ptr&lt;peer_connection&gt; sp(p-&gt;self());

		if (cancel_with_cq) m_half_open.cancel(p);

		// someone else is holding a reference, it's important that
		// it's destructed from the network thread. Make sure the
		// last reference is held by the network thread.
		if (!sp.unique())
			m_undead_peers.push_back(sp);

// too expensive
//		INVARIANT_CHECK;

#ifdef TORRENT_DEBUG
//		for (aux::session_impl::torrent_map::const_iterator i = m_torrents.begin()
//			, end(m_torrents.end()); i != end; ++i)
//			TORRENT_ASSERT(!i-&gt;second-&gt;has_peer((peer_connection*)p));
#endif

#if defined(TORRENT_LOGGING)
		session_log(" CLOSING CONNECTION %s : %s"
			, print_endpoint(p-&gt;remote()).c_str(), ec.message().c_str());
#endif

		TORRENT_ASSERT(p-&gt;is_disconnecting());

		if (!p-&gt;is_choked() &amp;&amp; !p-&gt;ignore_unchoke_slots()) --m_num_unchoked;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(58)">src/session_impl.cpp:3608</a></td><td>have a separate list for these connections, instead of having to loop through all of them</td></tr><tr id="58" style="display: none;" colspan="3"><td colspan="3"><h2>have a separate list for these connections, instead of having to loop through all of them</h2><h4>src/session_impl.cpp:3608</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		if (m_auto_manage_time_scaler &lt; 0)
		{
			INVARIANT_CHECK;
			m_auto_manage_time_scaler = settings().get_int(settings_pack::auto_manage_interval);
			recalculate_auto_managed_torrents();
		}

		// --------------------------------------------------------------
		// check for incoming connections that might have timed out
		// --------------------------------------------------------------

		for (connection_map::iterator i = m_connections.begin();
			i != m_connections.end();)
		{
			peer_connection* p = (*i).get();
			++i;
			// ignore connections that already have a torrent, since they
			// are ticked through the torrents' second_tick
			if (!p-&gt;associated_torrent().expired()) continue;

<div style="background: #ffff00" width="100%">			if (m_last_tick - p-&gt;connected_time()
</div>				&gt; seconds(m_settings.get_int(settings_pack::handshake_timeout)))
				p-&gt;disconnect(errors::timed_out, peer_connection::op_bittorrent);
		}

		// --------------------------------------------------------------
		// second_tick every torrent (that wants it)
		// --------------------------------------------------------------

		std::vector&lt;torrent*&gt;&amp; want_tick = m_torrent_lists[torrent_want_tick];
		for (int i = 0; i &lt; int(want_tick.size()); ++i)
		{
			torrent&amp; t = *want_tick[i];
			TORRENT_ASSERT(t.want_tick());
			TORRENT_ASSERT(!t.is_aborted());

			t.second_tick(tick_interval_ms, m_tick_residual / 1000);

			// if the call to second_tick caused the torrent
			// to no longer want to be ticked (i.e. it was
			// removed from the list) we need to back up the counter
			// to not miss the torrent after it
			if (!t.want_tick()) --i;
		}

#ifndef TORRENT_DISABLE_DHT
		if (m_dht)
		{
			int dht_down;
			int dht_up;
			m_dht-&gt;network_stats(dht_up, dht_down);
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(59)">src/session_impl.cpp:3645</a></td><td>this should apply to all bandwidth channels</td></tr><tr id="59" style="display: none;" colspan="3"><td colspan="3"><h2>this should apply to all bandwidth channels</h2><h4>src/session_impl.cpp:3645</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			t.second_tick(tick_interval_ms, m_tick_residual / 1000);

			// if the call to second_tick caused the torrent
			// to no longer want to be ticked (i.e. it was
			// removed from the list) we need to back up the counter
			// to not miss the torrent after it
			if (!t.want_tick()) --i;
		}

#ifndef TORRENT_DISABLE_DHT
		if (m_dht)
		{
			int dht_down;
			int dht_up;
			m_dht-&gt;network_stats(dht_up, dht_down);
			m_stat.sent_dht_bytes(dht_up);
			m_stat.received_dht_bytes(dht_down);
		}
#endif

<div style="background: #ffff00" width="100%">		if (m_settings.get_bool(settings_pack::rate_limit_ip_overhead))
</div>		{
			peer_class* gpc = m_classes.at(m_global_class);

			gpc-&gt;channel[peer_connection::download_channel].use_quota(
#ifndef TORRENT_DISABLE_DHT
				m_stat.download_dht() +
#endif
				m_stat.download_tracker());

			gpc-&gt;channel[peer_connection::upload_channel].use_quota(
#ifndef TORRENT_DISABLE_DHT
				m_stat.upload_dht() +
#endif
				m_stat.upload_tracker());

			int up_limit = upload_rate_limit(m_global_class);
			int down_limit = download_rate_limit(m_global_class);

			if (down_limit &gt; 0
				&amp;&amp; m_stat.download_ip_overhead() &gt;= down_limit
				&amp;&amp; m_alerts.should_post&lt;performance_alert&gt;())
			{
				m_alerts.post_alert(performance_alert(torrent_handle()
					, performance_alert::download_limit_too_low));
			}

			if (up_limit &gt; 0
				&amp;&amp; m_stat.upload_ip_overhead() &gt;= up_limit
				&amp;&amp; m_alerts.should_post&lt;performance_alert&gt;())
			{
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(60)">src/session_impl.cpp:4626</a></td><td>these vectors could be copied from m_torrent_lists, if we would maintain them. That way the first pass over all torrents could be avoided. It would be especially efficient if most torrents are not auto-managed whenever we receive a scrape response (or anything that may change the rank of a torrent) that one torrent could re-sort itself in a list that's kept sorted at all times. That way, this pass over all torrents could be avoided alltogether.</td></tr><tr id="60" style="display: none;" colspan="3"><td colspan="3"><h2>these vectors could be copied from m_torrent_lists,
if we would maintain them. That way the first pass over
all torrents could be avoided. It would be especially
efficient if most torrents are not auto-managed
whenever we receive a scrape response (or anything
that may change the rank of a torrent) that one torrent
could re-sort itself in a list that's kept sorted at all
times. That way, this pass over all torrents could be
avoided alltogether.</h2><h4>src/session_impl.cpp:4626</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_LOGGING
				if (t-&gt;allows_peers())
					t-&gt;log_to_all_peers("AUTO MANAGER PAUSING TORRENT");
#endif
				// use graceful pause for auto-managed torrents
				t-&gt;set_allow_peers(false, true);
			}
		}
	}

	void session_impl::recalculate_auto_managed_torrents()
	{
		INVARIANT_CHECK;

		m_need_auto_manage = false;

		if (is_paused()) return;

		// these vectors are filled with auto managed torrents

<div style="background: #ffff00" width="100%">		std::vector&lt;torrent*&gt; checking;
</div>		std::vector&lt;torrent*&gt; downloaders;
		downloaders.reserve(m_torrents.size());
		std::vector&lt;torrent*&gt; seeds;
		seeds.reserve(m_torrents.size());

		// these counters are set to the number of torrents
		// of each kind we're allowed to have active
		int num_downloaders = settings().get_int(settings_pack::active_downloads);
		int num_seeds = settings().get_int(settings_pack::active_seeds);
		int checking_limit = 1;
		int dht_limit = settings().get_int(settings_pack::active_dht_limit);
		int tracker_limit = settings().get_int(settings_pack::active_tracker_limit);
		int lsd_limit = settings().get_int(settings_pack::active_lsd_limit);
		int hard_limit = settings().get_int(settings_pack::active_limit);

		if (num_downloaders == -1)
			num_downloaders = (std::numeric_limits&lt;int&gt;::max)();
		if (num_seeds == -1)
			num_seeds = (std::numeric_limits&lt;int&gt;::max)();
		if (hard_limit == -1)
			hard_limit = (std::numeric_limits&lt;int&gt;::max)();
		if (dht_limit == -1)
			dht_limit = (std::numeric_limits&lt;int&gt;::max)();
		if (lsd_limit == -1)
			lsd_limit = (std::numeric_limits&lt;int&gt;::max)();
		if (tracker_limit == -1)
			tracker_limit = (std::numeric_limits&lt;int&gt;::max)();
            
		for (torrent_map::iterator i = m_torrents.begin()
			, end(m_torrents.end()); i != end; ++i)
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(61)">src/session_impl.cpp:4711</a></td><td>allow extensions to sort torrents for queuing</td></tr><tr id="61" style="display: none;" colspan="3"><td colspan="3"><h2>allow extensions to sort torrents for queuing</h2><h4>src/session_impl.cpp:4711</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">					continue;
				}
				TORRENT_ASSERT(t-&gt;m_resume_data_loaded || !t-&gt;valid_metadata());
				--hard_limit;
			  	if (is_active(t, settings()))
				{
					// this is not an auto managed torrent,
					// if it's running and active, decrease the
					// counters.
					if (t-&gt;is_finished())
						--num_seeds;
					else
						--num_downloaders;
				}
			}
		}

		bool handled_by_extension = false;

#ifndef TORRENT_DISABLE_EXTENSIONS
<div style="background: #ffff00" width="100%">#endif
</div>
		if (!handled_by_extension)
		{
			std::sort(downloaders.begin(), downloaders.end()
				, boost::bind(&amp;torrent::sequence_number, _1) &lt; boost::bind(&amp;torrent::sequence_number, _2));

			std::sort(seeds.begin(), seeds.end()
				, boost::bind(&amp;torrent::seed_rank, _1, boost::ref(m_settings))
				&gt; boost::bind(&amp;torrent::seed_rank, _2, boost::ref(m_settings)));
		}

		auto_manage_torrents(checking, checking_limit, dht_limit, tracker_limit, lsd_limit
			, hard_limit, num_downloaders);

		if (settings().get_bool(settings_pack::auto_manage_prefer_seeds))
		{
			auto_manage_torrents(seeds, checking_limit, dht_limit, tracker_limit, lsd_limit
				, hard_limit, num_seeds);
			auto_manage_torrents(downloaders, checking_limit, dht_limit, tracker_limit, lsd_limit
				, hard_limit, num_downloaders);
		}
		else
		{
			auto_manage_torrents(downloaders, checking_limit, dht_limit, tracker_limit, lsd_limit
				, hard_limit, num_downloaders);
			auto_manage_torrents(seeds, checking_limit, dht_limit, tracker_limit, lsd_limit
				, hard_limit, num_seeds);
		}
	}

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(62)">src/session_impl.cpp:4877</a></td><td>use a lower limit than m_settings.connections_limit to allocate the to 10% or so of connection slots for incoming connections</td></tr><tr id="62" style="display: none;" colspan="3"><td colspan="3"><h2>use a lower limit than m_settings.connections_limit
to allocate the to 10% or so of connection slots for incoming
connections</h2><h4>src/session_impl.cpp:4877</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		// if we don't have any free slots, return
		if (free_slots &lt;= -m_half_open.limit()) return;

		// boost connections are connections made by torrent connection
		// boost, which are done immediately on a tracker response. These
		// connections needs to be deducted from this second
		if (m_boost_connections &gt; 0)
		{
			if (m_boost_connections &gt; max_connections)
			{
				m_boost_connections -= max_connections;
				max_connections = 0;
			}
			else
			{
				max_connections -= m_boost_connections;
				m_boost_connections = 0;
			}
		}

<div style="background: #ffff00" width="100%">		int limit = (std::min)(m_settings.get_int(settings_pack::connections_limit)
</div>			- num_connections(), free_slots);

		// this logic is here to smooth out the number of new connection
		// attempts over time, to prevent connecting a large number of
		// sockets, wait 10 seconds, and then try again
		if (m_settings.get_bool(settings_pack::smooth_connects) &amp;&amp; max_connections &gt; (limit+1) / 2)
			max_connections = (limit+1) / 2;

		std::vector&lt;torrent*&gt;&amp; want_peers_download = m_torrent_lists[torrent_want_peers_download];
		std::vector&lt;torrent*&gt;&amp; want_peers_finished = m_torrent_lists[torrent_want_peers_finished];

		// if no torrent want any peers, just return
		if (want_peers_download.empty() &amp;&amp; want_peers_finished.empty()) return;

		// if we don't have any connection attempt quota, return
		if (max_connections &lt;= 0) return;

		INVARIANT_CHECK;

		int steps_since_last_connect = 0;
		int num_torrents = int(want_peers_finished.size() + want_peers_download.size());
		for (;;)
		{
			if (m_next_downloading_connect_torrent &gt;= int(want_peers_download.size()))
				m_next_downloading_connect_torrent = 0;

			if (m_next_finished_connect_torrent &gt;= int(want_peers_finished.size()))
				m_next_finished_connect_torrent = 0;

			torrent* t = NULL;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(63)">src/session_impl.cpp:5071</a></td><td>make configurable</td></tr><tr id="63" style="display: none;" colspan="3"><td colspan="3"><h2>make configurable</h2><h4>src/session_impl.cpp:5071</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
#ifdef TORRENT_DEBUG
			for (std::vector&lt;peer_connection*&gt;::const_iterator i = peers.begin()
				, end(peers.end()), prev(peers.end()); i != end; ++i)
			{
				if (prev != end)
				{
					boost::shared_ptr&lt;torrent&gt; t1 = (*prev)-&gt;associated_torrent().lock();
					TORRENT_ASSERT(t1);
					boost::shared_ptr&lt;torrent&gt; t2 = (*i)-&gt;associated_torrent().lock();
					TORRENT_ASSERT(t2);
					TORRENT_ASSERT((*prev)-&gt;uploaded_in_last_round() * 1000
						* (1 + t1-&gt;priority()) / total_milliseconds(unchoke_interval)
						&gt;= (*i)-&gt;uploaded_in_last_round() * 1000
						* (1 + t2-&gt;priority()) / total_milliseconds(unchoke_interval));
				}
				prev = i;
			}
#endif

<div style="background: #ffff00" width="100%">			int rate_threshold = 1024;
</div>
			for (std::vector&lt;peer_connection*&gt;::const_iterator i = peers.begin()
				, end(peers.end()); i != end; ++i)
			{
				peer_connection const&amp; p = **i;
				int rate = int(p.uploaded_in_last_round()
					* 1000 / total_milliseconds(unchoke_interval));

				if (rate &lt; rate_threshold) break;

				++m_allowed_upload_slots;

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(64)">src/session_impl.cpp:5085</a></td><td>make configurable</td></tr><tr id="64" style="display: none;" colspan="3"><td colspan="3"><h2>make configurable</h2><h4>src/session_impl.cpp:5085</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">						&gt;= (*i)-&gt;uploaded_in_last_round() * 1000
						* (1 + t2-&gt;priority()) / total_milliseconds(unchoke_interval));
				}
				prev = i;
			}
#endif

			int rate_threshold = 1024;

			for (std::vector&lt;peer_connection*&gt;::const_iterator i = peers.begin()
				, end(peers.end()); i != end; ++i)
			{
				peer_connection const&amp; p = **i;
				int rate = int(p.uploaded_in_last_round()
					* 1000 / total_milliseconds(unchoke_interval));

				if (rate &lt; rate_threshold) break;

				++m_allowed_upload_slots;

<div style="background: #ffff00" width="100%">				rate_threshold += 1024;
</div>			}
			// allow one optimistic unchoke
			++m_allowed_upload_slots;
		}

		if (m_settings.get_int(settings_pack::choking_algorithm) == settings_pack::bittyrant_choker)
		{
			// if we're using the bittyrant choker, sort peers by their return
			// on investment. i.e. download rate / upload rate
			std::sort(peers.begin(), peers.end()
				, boost::bind(&amp;peer_connection::bittyrant_unchoke_compare, _1, _2));
		}
		else
		{
			// sorts the peers that are eligible for unchoke by download rate and secondary
			// by total upload. The reason for this is, if all torrents are being seeded,
			// the download rate will be 0, and the peers we have sent the least to should
			// be unchoked
			std::sort(peers.begin(), peers.end()
				, boost::bind(&amp;peer_connection::unchoke_compare, _1, _2));
		}

		// auto unchoke
		peer_class* gpc = m_classes.at(m_global_class);
		int upload_limit = gpc-&gt;channel[peer_connection::upload_channel].throttle();
		if (m_settings.get_int(settings_pack::choking_algorithm) == settings_pack::auto_expand_choker
			&amp;&amp; upload_limit &gt; 0)
		{
			// if our current upload rate is less than 90% of our 
			// limit
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(65)">src/session_impl.cpp:5164</a></td><td>this should be called for all peers!</td></tr><tr id="65" style="display: none;" colspan="3"><td colspan="3"><h2>this should be called for all peers!</h2><h4>src/session_impl.cpp:5164</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">				// measurement of the peak, use that + 10kB/s, otherwise
				// assume 20 kB/s
				upload_capacity_left = (std::max)(20000, m_peak_up_rate + 10000);
				if (m_alerts.should_post&lt;performance_alert&gt;())
					m_alerts.post_alert(performance_alert(torrent_handle()
						, performance_alert::bittyrant_with_no_uplimit));
			}
		}

		m_num_unchoked = 0;
		// go through all the peers and unchoke the first ones and choke
		// all the other ones.
		for (std::vector&lt;peer_connection*&gt;::iterator i = peers.begin()
			, end(peers.end()); i != end; ++i)
		{
			peer_connection* p = *i;
			TORRENT_ASSERT(p);
			TORRENT_ASSERT(!p-&gt;ignore_unchoke_slots());

			// this will update the m_uploaded_at_last_unchoke
<div style="background: #ffff00" width="100%">			p-&gt;reset_choke_counters();
</div>
			torrent* t = p-&gt;associated_torrent().lock().get();
			TORRENT_ASSERT(t);

			// if this peer should be unchoked depends on different things
			// in different unchoked schemes
			bool unchoke = false;
			if (m_settings.get_int(settings_pack::choking_algorithm) == settings_pack::bittyrant_choker)
			{
				unchoke = p-&gt;est_reciprocation_rate() &lt;= upload_capacity_left;
			}
			else
			{
				unchoke = unchoke_set_size &gt; 0;
			}

			if (unchoke)
			{
				upload_capacity_left -= p-&gt;est_reciprocation_rate();

				// yes, this peer should be unchoked
				if (p-&gt;is_choked())
				{
					if (!t-&gt;unchoke_peer(*p))
						continue;
				}

				--unchoke_set_size;
				++m_num_unchoked;

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(66)">src/session_impl.cpp:5569</a></td><td>it might be a nice feature here to limit the number of torrents to send in a single update. By just posting the first n torrents, they would nicely be round-robined because the torrent lists are always pushed back</td></tr><tr id="66" style="display: none;" colspan="3"><td colspan="3"><h2>it might be a nice feature here to limit the number of torrents
to send in a single update. By just posting the first n torrents, they
would nicely be round-robined because the torrent lists are always
pushed back</h2><h4>src/session_impl.cpp:5569</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			t-&gt;status(&amp;*i, flags);
		}
	}
	
	void session_impl::post_torrent_updates()
	{
		INVARIANT_CHECK;

		TORRENT_ASSERT(is_single_thread());

		std::auto_ptr&lt;state_update_alert&gt; alert(new state_update_alert());
		std::vector&lt;torrent*&gt;&amp; state_updates
			= m_torrent_lists[aux::session_impl::torrent_state_updates];

		alert-&gt;status.reserve(state_updates.size());

#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
		m_posting_torrent_updates = true;
#endif

<div style="background: #ffff00" width="100%">		for (std::vector&lt;torrent*&gt;::iterator i = state_updates.begin()
</div>			, end(state_updates.end()); i != end; ++i)
		{
			torrent* t = *i;
			TORRENT_ASSERT(t-&gt;m_links[aux::session_impl::torrent_state_updates].in_list());
			alert-&gt;status.push_back(torrent_status());
			// querying accurate download counters may require
			// the torrent to be loaded. Loading a torrent, and evicting another
			// one will lead to calling state_updated(), which screws with
			// this list while we're working on it, and break things
			t-&gt;status(&amp;alert-&gt;status.back(), ~torrent_handle::query_accurate_download_counters);
			t-&gt;clear_in_state_update();
		}
		state_updates.clear();

#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
		m_posting_torrent_updates = false;
#endif

		m_alerts.post_alert_ptr(alert.release());
	}

	void session_impl::post_session_stats()
	{
		std::auto_ptr&lt;session_stats_alert&gt; alert(new session_stats_alert());
		std::vector&lt;boost::uint64_t&gt;&amp; values = alert-&gt;values;
		values.resize(counters::num_counters, 0);

		m_disk_thread.update_stats_counters(m_stats_counters);

		for (int i = 0; i &lt; counters::num_counters; ++i)
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(67)">src/session_impl.cpp:6062</a></td><td>make m_listen_interface a list of interfaces we're listening on</td></tr><tr id="67" style="display: none;" colspan="3"><td colspan="3"><h2>make m_listen_interface a list of interfaces we're listening on</h2><h4>src/session_impl.cpp:6062</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
#ifndef TORRENT_DISABLE_DHT
		if (m_next_dht_torrent == m_torrents.end())
			m_next_dht_torrent = m_torrents.begin();
#endif
		if (m_next_lsd_torrent == m_torrents.end())
			m_next_lsd_torrent = m_torrents.begin();

		// this torrent may open up a slot for a queued torrent
		trigger_auto_manage();

		TORRENT_ASSERT(m_torrents.find(i_hash) == m_torrents.end());
	}

	void session_impl::update_listen_interfaces()
	{
		INVARIANT_CHECK;

		std::string net_interface = m_settings.get_str(settings_pack::listen_interfaces);

<div style="background: #ffff00" width="100%">		tcp::endpoint new_interface;
</div>		if (!net_interface.empty())
		{
			error_code ec;
			new_interface = parse_endpoint(net_interface, ec);
			if (ec)
			{
				if (m_alerts.should_post&lt;listen_failed_alert&gt;())
					m_alerts.post_alert(listen_failed_alert(new_interface, listen_failed_alert::parse_addr, ec));

#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_LOGGING || defined TORRENT_ERROR_LOGGING
				session_log("listen_on: %s failed: %s"
					, net_interface.c_str(), ec.message().c_str());
#endif
				return;
			}
		}
		else
		{
			new_interface = tcp::endpoint(address_v4::any(), 6881);
		}

		m_listen_port_retries = m_settings.get_int(settings_pack::max_retry_port_bind);

		// if the interface is the same and the socket is open
		// don't do anything
		if (new_interface == m_listen_interface
			&amp;&amp; !m_listen_sockets.empty())
			return;

		m_listen_interface = new_interface;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(68)">src/storage.cpp:693</a></td><td>make this more generic to not just work if files have been renamed, but also if they have been merged into a single file for instance maybe use the same format as .torrent files and reuse some code from torrent_info</td></tr><tr id="68" style="display: none;" colspan="3"><td colspan="3"><h2>make this more generic to not just work if files have been
renamed, but also if they have been merged into a single file for instance
maybe use the same format as .torrent files and reuse some code from torrent_info</h2><h4>src/storage.cpp:693</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		for (file_iter = files().begin();;)
		{
			if (file_offset &lt; file_iter-&gt;size)
				break;

			file_offset -= file_iter-&gt;size;
			++file_iter;
			TORRENT_ASSERT(file_iter != files().end());
		}
	
		error_code ec;
		file_handle handle = open_file(file_iter, file::read_only, ec);
		if (!handle || ec) return slot;

		size_type data_start = handle-&gt;sparse_end(file_offset);
		return int((data_start + m_files.piece_length() - 1) / m_files.piece_length());
	}

	bool default_storage::verify_resume_data(lazy_entry const&amp; rd, storage_error&amp; ec)
	{
<div style="background: #ffff00" width="100%">		lazy_entry const* mapped_files = rd.dict_find_list("mapped_files");
</div>		if (mapped_files &amp;&amp; mapped_files-&gt;list_size() == m_files.num_files())
		{
			m_mapped_files.reset(new file_storage(m_files));
			for (int i = 0; i &lt; m_files.num_files(); ++i)
			{
				std::string new_filename = mapped_files-&gt;list_string_value_at(i);
				if (new_filename.empty()) continue;
				m_mapped_files-&gt;rename_file(i, new_filename);
			}
		}
		
		lazy_entry const* file_priority = rd.dict_find_list("file_priority");
		if (file_priority &amp;&amp; file_priority-&gt;list_size()
			== files().num_files())
		{
			m_file_priority.resize(file_priority-&gt;list_size());
			for (int i = 0; i &lt; file_priority-&gt;list_size(); ++i)
				m_file_priority[i] = boost::uint8_t(file_priority-&gt;list_int_value_at(i, 1));
		}

		lazy_entry const* file_sizes_ent = rd.dict_find_list("file sizes");
		if (file_sizes_ent == 0)
		{
			ec.ec = errors::missing_file_sizes;
			return false;
		}
		
		if (file_sizes_ent-&gt;list_size() == 0)
		{
			ec.ec = errors::no_files_in_resume_data;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(69)">src/storage.cpp:980</a></td><td>if everything moves OK, except for the partfile we currently won't update the save path, which breaks things. it would probably make more sense to give up on the partfile</td></tr><tr id="69" style="display: none;" colspan="3"><td colspan="3"><h2>if everything moves OK, except for the partfile
we currently won't update the save path, which breaks things.
it would probably make more sense to give up on the partfile</h2><h4>src/storage.cpp:980</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">					if (ec)
					{
						ec.file = i-&gt;second;
						ec.operation = storage_error::copy;
					}
					else
					{
						// ignore errors when removing
						error_code e;
						remove_all(old_path, e);
					}
					break;
				}
			}
		}

		if (!ec)
		{
			if (m_part_file)
			{
<div style="background: #ffff00" width="100%">				m_part_file-&gt;move_partfile(save_path, ec.ec);
</div>				if (ec)
				{
					ec.file = -1;
					ec.operation = storage_error::partfile;
					return piece_manager::fatal_disk_error; 
				}
			}

			m_save_path = save_path;
		}
		return ret;
	}

	int default_storage::readv(file::iovec_t const* bufs, int num_bufs
		, int slot, int offset, int flags, storage_error&amp; ec)
	{
		fileop op = { &amp;file::readv
			, file::read_only | flags };
#ifdef TORRENT_SIMULATE_SLOW_READ
		boost::thread::sleep(boost::get_system_time()
			+ boost::posix_time::milliseconds(1000));
#endif
		return readwritev(bufs, slot, offset, num_bufs, op, ec);
	}

	int default_storage::writev(file::iovec_t const* bufs, int num_bufs
		, int slot, int offset, int flags, storage_error&amp; ec)
	{
		fileop op = { &amp;file::writev
			, file::read_write | flags };
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(70)">src/torrent.cpp:582</a></td><td>if the existing torrent doesn't have metadata, insert the metadata we just downloaded into it.</td></tr><tr id="70" style="display: none;" colspan="3"><td colspan="3"><h2>if the existing torrent doesn't have metadata, insert
the metadata we just downloaded into it.</h2><h4>src/torrent.cpp:582</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		m_torrent_file = tf;

		// now, we might already have this torrent in the session.
		boost::shared_ptr&lt;torrent&gt; t = m_ses.find_torrent(m_torrent_file-&gt;info_hash()).lock();
		if (t)
		{
			if (!m_uuid.empty() &amp;&amp; t-&gt;uuid().empty())
				t-&gt;set_uuid(m_uuid);
			if (!m_url.empty() &amp;&amp; t-&gt;url().empty())
				t-&gt;set_url(m_url);
			if (!m_source_feed_url.empty() &amp;&amp; t-&gt;source_feed_url().empty())
				t-&gt;set_source_feed_url(m_source_feed_url);

			// insert this torrent in the uuid index
			if (!m_uuid.empty() || !m_url.empty())
			{
				m_ses.insert_uuid_torrent(m_uuid.empty() ? m_url : m_uuid, t);
			}

<div style="background: #ffff00" width="100%">
</div>			set_error(error_code(errors::duplicate_torrent, get_libtorrent_category()), error_file_url);
			abort();
			return;
		}

		m_ses.insert_torrent(m_torrent_file-&gt;info_hash(), me, m_uuid);

		TORRENT_ASSERT(num_torrents == int(m_ses.m_torrents.size()));

		// if the user added any trackers while downloading the
		// .torrent file, serge them into the new tracker list
		std::vector&lt;announce_entry&gt; new_trackers = m_torrent_file-&gt;trackers();
		for (std::vector&lt;announce_entry&gt;::iterator i = m_trackers.begin()
			, end(m_trackers.end()); i != end; ++i)
		{
			// if we already have this tracker, ignore it
			if (std::find_if(new_trackers.begin(), new_trackers.end()
				, boost::bind(&amp;announce_entry::url, _1) == i-&gt;url) != new_trackers.end())
				continue;

			// insert the tracker ordered by tier
			new_trackers.insert(std::find_if(new_trackers.begin(), new_trackers.end()
				, boost::bind(&amp;announce_entry::tier, _1) &gt;= i-&gt;tier), *i);
		}
		m_trackers.swap(new_trackers);

#ifndef TORRENT_DISABLE_ENCRYPTION
		hasher h;
		h.update("req2", 4);
		h.update((char*)&amp;m_torrent_file-&gt;info_hash()[0], 20);
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(71)">src/torrent.cpp:733</a></td><td>if the existing torrent doesn't have metadata, insert the metadata we just downloaded into it.</td></tr><tr id="71" style="display: none;" colspan="3"><td colspan="3"><h2>if the existing torrent doesn't have metadata, insert
the metadata we just downloaded into it.</h2><h4>src/torrent.cpp:733</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		m_torrent_file = tf;

		// now, we might already have this torrent in the session.
		boost::shared_ptr&lt;torrent&gt; t = m_ses.find_torrent(m_torrent_file-&gt;info_hash()).lock();
		if (t)
		{
			if (!m_uuid.empty() &amp;&amp; t-&gt;uuid().empty())
				t-&gt;set_uuid(m_uuid);
			if (!m_url.empty() &amp;&amp; t-&gt;url().empty())
				t-&gt;set_url(m_url);
			if (!m_source_feed_url.empty() &amp;&amp; t-&gt;source_feed_url().empty())
				t-&gt;set_source_feed_url(m_source_feed_url);

			// insert this torrent in the uuid index
			if (!m_uuid.empty() || !m_url.empty())
			{
				m_ses.insert_uuid_torrent(m_uuid.empty() ? m_url : m_uuid, t);
			}

<div style="background: #ffff00" width="100%">
</div>			set_error(error_code(errors::duplicate_torrent, get_libtorrent_category()), error_file_url);
			abort();
			return;
		}

		m_ses.insert_torrent(m_torrent_file-&gt;info_hash(), me, m_uuid);

		// if the user added any trackers while downloading the
		// .torrent file, merge them into the new tracker list
		std::vector&lt;announce_entry&gt; new_trackers = m_torrent_file-&gt;trackers();
		for (std::vector&lt;announce_entry&gt;::iterator i = m_trackers.begin()
			, end(m_trackers.end()); i != end; ++i)
		{
			// if we already have this tracker, ignore it
			if (std::find_if(new_trackers.begin(), new_trackers.end()
				, boost::bind(&amp;announce_entry::url, _1) == i-&gt;url) != new_trackers.end())
				continue;

			// insert the tracker ordered by tier
			new_trackers.insert(std::find_if(new_trackers.begin(), new_trackers.end()
				, boost::bind(&amp;announce_entry::tier, _1) &gt;= i-&gt;tier), *i);
		}
		m_trackers.swap(new_trackers);

#ifndef TORRENT_DISABLE_ENCRYPTION
		hasher h;
		h.update("req2", 4);
		h.update((char*)&amp;m_torrent_file-&gt;info_hash()[0], 20);
		m_ses.add_obfuscated_hash(h.final(), shared_from_this());
#endif
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(72)">src/torrent.cpp:1839</a></td><td>instead of creating the picker up front here, maybe this whole section should move to need_picker()</td></tr><tr id="72" style="display: none;" colspan="3"><td colspan="3"><h2>instead of creating the picker up front here,
maybe this whole section should move to need_picker()</h2><h4>src/torrent.cpp:1839</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">				m_resume_data.reset();
			}
			else
			{
				read_resume_data(m_resume_data-&gt;entry);
			}
		}
	
#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
		m_resume_data_loaded = true;
#endif

		TORRENT_ASSERT(block_size() &gt; 0);
		int file = 0;
		for (file_storage::iterator i = m_torrent_file-&gt;files().begin()
			, end(m_torrent_file-&gt;files().end()); i != end; ++i, ++file)
		{
			if (!i-&gt;pad_file || i-&gt;size == 0) continue;
			m_padding += i-&gt;size;
			
<div style="background: #ffff00" width="100%">			need_picker();
</div>
			peer_request pr = m_torrent_file-&gt;map_file(file, 0, m_torrent_file-&gt;file_at(file).size);
			int off = pr.start &amp; (block_size()-1);
			if (off != 0) { pr.length -= block_size() - off; pr.start += block_size() - off; }
			TORRENT_ASSERT((pr.start &amp; (block_size()-1)) == 0);

			int block = block_size();
			int blocks_per_piece = m_torrent_file-&gt;piece_length() / block;
			piece_block pb(pr.piece, pr.start / block);
			for (; pr.length &gt;= block; pr.length -= block, ++pb.block_index)
			{
				if (int(pb.block_index) == blocks_per_piece) { pb.block_index = 0; ++pb.piece_index; }
				m_picker-&gt;mark_as_finished(pb, 0);
			}
			// ugly edge case where padfiles are not used they way they're
			// supposed to be. i.e. added back-to back or at the end
			if (int(pb.block_index) == blocks_per_piece) { pb.block_index = 0; ++pb.piece_index; }
			if (pr.length &gt; 0 &amp;&amp; ((boost::next(i) != end &amp;&amp; boost::next(i)-&gt;pad_file)
				|| boost::next(i) == end))
			{
				m_picker-&gt;mark_as_finished(pb, 0);
			}
		}

		if (m_padding &gt; 0)
		{
			// if we marked an entire piece as finished, we actually
			// need to consider it finished

			std::vector&lt;piece_picker::downloading_piece&gt; dq
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(73)">src/torrent.cpp:2029</a></td><td>there may be peer extensions relying on the torrent extension still being alive. Only do this if there are no peers. And when the last peer is disconnected, if the torrent is unloaded, clear the extensions m_extensions.clear();</td></tr><tr id="73" style="display: none;" colspan="3"><td colspan="3"><h2>there may be peer extensions relying on the torrent extension
still being alive. Only do this if there are no peers. And when the last peer
is disconnected, if the torrent is unloaded, clear the extensions
m_extensions.clear();</h2><h4>src/torrent.cpp:2029</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		// pinned torrents are not allowed to be swapped out
		TORRENT_ASSERT(!m_pinned);

		m_should_be_loaded = false;

		// make sure it's not unloaded in the middle of some operation that uses it
		if (m_refcount &gt; 0) return;

		// call on_unload() on extensions
#ifndef TORRENT_DISABLE_EXTENSIONS
		for (extension_list_t::iterator i = m_extensions.begin()
			, end(m_extensions.end()); i != end; ++i)
		{
			TORRENT_TRY {
				(*i)-&gt;on_unload();
			} TORRENT_CATCH (std::exception&amp;) {}
		}

		// also remove extensions and re-instantiate them when the torrent is loaded again
		// they end up using a significant amount of memory
<div style="background: #ffff00" width="100%">#endif
</div>
		// someone else holds a reference to the torrent_info
		// make the torrent release its reference to it,
		// after making a copy and then unloading that version
		// as soon as the user is done with its copy of torrent_info
		// it will be freed, and we'll have the unloaded version left
		if (!m_torrent_file.unique())
			m_torrent_file = boost::make_shared&lt;torrent_info&gt;(*m_torrent_file);

		m_torrent_file-&gt;unload();
		m_ses.inc_stats_counter(counters::num_loaded_torrents, -1);

		m_storage.reset();

		state_updated();
	}

	bt_peer_connection* torrent::find_introducer(tcp::endpoint const&amp; ep) const
	{
#ifndef TORRENT_DISABLE_EXTENSIONS
		for (const_peer_iterator i = m_connections.begin(); i != m_connections.end(); ++i)
		{
			if ((*i)-&gt;type() != peer_connection::bittorrent_connection) continue;
			bt_peer_connection* p = (bt_peer_connection*)(*i);
			if (!p-&gt;supports_holepunch()) continue;
			peer_plugin const* pp = p-&gt;find_plugin("ut_pex");
			if (!pp) continue;
			if (was_introduced_by(pp, ep)) return (bt_peer_connection*)p;
		}
#endif
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(74)">src/torrent.cpp:2610</a></td><td>this pattern is repeated in a few places. Factor this into a function and generalize the concept of a torrent having a dedicated listen port</td></tr><tr id="74" style="display: none;" colspan="3"><td colspan="3"><h2>this pattern is repeated in a few places. Factor this into
a function and generalize the concept of a torrent having a
dedicated listen port</h2><h4>src/torrent.cpp:2610</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		// if the files haven't been checked yet, we're
		// not ready for peers
		if (!m_files_checked) return;

		if (!m_announce_to_lsd) return;

		// private torrents are never announced on LSD
		if (m_torrent_file-&gt;is_valid() &amp;&amp; m_torrent_file-&gt;priv()) return;

		// i2p torrents are also never announced on LSD
		// unless we allow mixed swarms
		if (m_torrent_file-&gt;is_valid()
			&amp;&amp; (torrent_file().is_i2p() &amp;&amp; !settings().get_bool(settings_pack::allow_i2p_mixed)))
			return;

		if (is_paused()) return;

		if (!m_ses.has_lsd()) return;

<div style="background: #ffff00" width="100%">#ifdef TORRENT_USE_OPENSSL
</div>		int port = is_ssl_torrent() ? m_ses.ssl_listen_port() : m_ses.listen_port();
#else
		int port = m_ses.listen_port();
#endif

		// announce with the local discovery service
		m_ses.announce_lsd(m_torrent_file-&gt;info_hash(), port
			, m_ses.settings().get_bool(settings_pack::broadcast_lsd) &amp;&amp; m_lsd_seq == 0);
		++m_lsd_seq;
	}

#ifndef TORRENT_DISABLE_DHT

	void torrent::dht_announce()
	{
		TORRENT_ASSERT(m_ses.is_single_thread());
		if (!m_ses.dht()) return;
		if (!should_announce_dht()) return;

		TORRENT_ASSERT(m_allow_peers);

#ifdef TORRENT_USE_OPENSSL
		int port = is_ssl_torrent() ? m_ses.ssl_listen_port() : m_ses.listen_port();
#else
		int port = m_ses.listen_port();
#endif

#if defined TORRENT_LOGGING || defined TORRENT_ERROR_LOGGING
		debug_log("START DHT announce");
		m_dht_start_time = time_now_hires();
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(75)">src/torrent.cpp:3083</a></td><td>instead, borrow host resolvers from a pool in session_impl. That would make the torrent object smaller</td></tr><tr id="75" style="display: none;" colspan="3"><td colspan="3"><h2>instead, borrow host resolvers from a pool in session_impl. That
would make the torrent object smaller</h2><h4>src/torrent.cpp:3083</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">						, boost::bind(&amp;torrent::on_i2p_resolve
						, shared_from_this(), _1));
					*/
					// it seems like you're not supposed to do a name lookup
					// on the peers returned from the tracker, but just strip
					// the .i2p and use it as a destination
					i-&gt;ip.resize(i-&gt;ip.size() - 4);
					torrent_state st = get_policy_state();
					need_policy();
					if (m_policy-&gt;add_i2p_peer(i-&gt;ip.c_str(), peer_info::tracker, 0, &amp;st))
						state_updated();
					peers_erased(st.erased);
				}
				else
#endif
				{
#if defined TORRENT_ASIO_DEBUGGING
					add_outstanding_async("torrent::on_peer_name_lookup");
#endif
					tcp::resolver::query q(i-&gt;ip, to_string(i-&gt;port).elems);
<div style="background: #ffff00" width="100%">					m_host_resolver.async_resolve(q,
</div>						boost::bind(&amp;torrent::on_peer_name_lookup, shared_from_this(), _1, _2));
				}
			}
			else
			{
				// ignore local addresses from the tracker (unless the tracker is local too)
				// there are 2 reasons to allow this:
				// 1. retrackers are popular in russia, where an ISP runs a tracker within
				//    the AS (but not on the local network) giving out peers only from the
				//    local network
				// 2. it might make sense to have a tracker extension in the future where
				//    trackers records a peer's internal and external IP, and match up
				//    peers on the same local network
//				if (is_local(a.address()) &amp;&amp; !is_local(tracker_ip)) continue;
				if (add_peer(a, peer_info::tracker))
					state_updated();
			}
		}
		update_want_peers();

		if (m_ses.alerts().should_post&lt;tracker_reply_alert&gt;())
		{
			m_ses.alerts().post_alert(tracker_reply_alert(
				get_handle(), peer_list.size(), r.url));
		}
		m_got_tracker_response = true;

		// we're listening on an interface type that was not used
		// when talking to the tracker. If there is a matching interface
		// type in the tracker IP list, make another tracker request
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(76)">src/torrent.cpp:4238</a></td><td>update suggest_piece?</td></tr><tr id="76" style="display: none;" colspan="3"><td colspan="3"><h2>update suggest_piece?</h2><h4>src/torrent.cpp:4238</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
	void torrent::peer_has_all(peer_connection const* peer)
	{
		if (has_picker())
		{
			m_picker-&gt;inc_refcount_all(peer);
		}
#ifdef TORRENT_DEBUG
		else
		{
			TORRENT_ASSERT(is_seed() || !m_have_all);
		}
#endif
	}

	void torrent::peer_lost(bitfield const&amp; bits, peer_connection const* peer)
	{
		if (has_picker())
		{
			m_picker-&gt;dec_refcount(bits, peer);
<div style="background: #ffff00" width="100%">		}
</div>#ifdef TORRENT_DEBUG
		else
		{
			TORRENT_ASSERT(is_seed() || !m_have_all);
		}
#endif
	}

	void torrent::peer_lost(int index, peer_connection const* peer)
	{
		if (m_picker.get())
		{
			m_picker-&gt;dec_refcount(index, peer);
			update_suggest_piece(index, -1);
		}
#ifdef TORRENT_DEBUG
		else
		{
			TORRENT_ASSERT(is_seed() || !m_have_all);
		}
#endif
	}

	void torrent::add_suggest_piece(int index)
	{
		int num_peers = m_picker-&gt;get_availability(index);

		TORRENT_ASSERT(has_piece_passed(index));

		// in order to avoid unnecessary churn in the suggested pieces
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(77)">src/torrent.cpp:4374</a></td><td>really, we should just keep the picker around in this case to maintain the availability counters</td></tr><tr id="77" style="display: none;" colspan="3"><td colspan="3"><h2>really, we should just keep the picker around
in this case to maintain the availability counters</h2><h4>src/torrent.cpp:4374</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		std::sort(cs.pieces.begin(), cs.pieces.end()
			, boost::bind(&amp;cached_piece_info::last_use, _1)
			&lt; boost::bind(&amp;cached_piece_info::last_use, _2));

		for (std::vector&lt;cached_piece_info&gt;::iterator i = cs.pieces.begin()
			, end(cs.pieces.end()); i != end; ++i)
		{
			TORRENT_ASSERT(i-&gt;storage == m_storage.get());
			// we might have flushed this to disk, but not yet completed the
			// hash check. We'll add it as a suggest piece once we do though
			if (!have_piece(i-&gt;piece)) continue;
			suggest_piece_t p;
			p.piece_index = i-&gt;piece;
			if (has_picker())
			{
				p.num_peers = m_picker-&gt;get_availability(i-&gt;piece);
			}
			else
			{
<div style="background: #ffff00" width="100%">				p.num_peers = 0;
</div>				for (const_peer_iterator i = m_connections.begin()
					, end(m_connections.end()); i != end; ++i)
				{
					peer_connection* peer = *i;
					if (peer-&gt;has_piece(p.piece_index)) ++p.num_peers;
				}
			}
			pieces.push_back(p);
		}

		// sort by rarity (stable, to maintain sort
		// by last use)
		std::stable_sort(pieces.begin(), pieces.end());

		// only suggest half of the pieces
		pieces.resize(pieces.size() / 2);

		// send new suggests to peers
		// the peers will filter out pieces we've
		// already suggested to them
		for (std::vector&lt;suggest_piece_t&gt;::iterator i = pieces.begin()
			, end(pieces.end()); i != end; ++i)
		{
			for (peer_iterator p = m_connections.begin();
				p != m_connections.end(); ++p)
				(*p)-&gt;send_suggest(i-&gt;piece_index);
		}
		m_need_suggest_pieces_refresh = false;
	}

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(78)">src/torrent.cpp:6067</a></td><td>make this more generic to not just work if files have been renamed, but also if they have been merged into a single file for instance maybe use the same format as .torrent files and reuse some code from torrent_info The mapped_files needs to be read both in the network thread and in the disk thread, since they both have their own mapped files structures which are kept in sync</td></tr><tr id="78" style="display: none;" colspan="3"><td colspan="3"><h2>make this more generic to not just work if files have been
renamed, but also if they have been merged into a single file for instance
maybe use the same format as .torrent files and reuse some code from torrent_info
The mapped_files needs to be read both in the network thread
and in the disk thread, since they both have their own mapped files structures
which are kept in sync</h2><h4>src/torrent.cpp:6067</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			m_verifying.resize(m_torrent_file-&gt;num_pieces(), false);
		}
		super_seeding(rd.dict_find_int_value("super_seeding", 0));

		m_last_scrape = rd.dict_find_int_value("last_scrape", 0);
		m_last_download = rd.dict_find_int_value("last_download", 0);
		m_last_upload = rd.dict_find_int_value("last_upload", 0);

		m_url = rd.dict_find_string_value("url");
		m_uuid = rd.dict_find_string_value("uuid");
		m_source_feed_url = rd.dict_find_string_value("feed");

		if (!m_uuid.empty() || !m_url.empty())
		{
			boost::shared_ptr&lt;torrent&gt; me(shared_from_this());

			// insert this torrent in the uuid index
			m_ses.insert_uuid_torrent(m_uuid.empty() ? m_url : m_uuid, me);
		}

<div style="background: #ffff00" width="100%">		lazy_entry const* mapped_files = rd.dict_find_list("mapped_files");
</div>		if (mapped_files &amp;&amp; mapped_files-&gt;list_size() == m_torrent_file-&gt;num_files())
		{
			for (int i = 0; i &lt; m_torrent_file-&gt;num_files(); ++i)
			{
				std::string new_filename = mapped_files-&gt;list_string_value_at(i);
				if (new_filename.empty()) continue;
				m_torrent_file-&gt;rename_file(i, new_filename);
			}
		}
		
		m_added_time = rd.dict_find_int_value("added_time", m_added_time);
		m_completed_time = rd.dict_find_int_value("completed_time", m_completed_time);
		if (m_completed_time != 0 &amp;&amp; m_completed_time &lt; m_added_time)
			m_completed_time = m_added_time;

		lazy_entry const* file_priority = rd.dict_find_list("file_priority");
		if (file_priority &amp;&amp; file_priority-&gt;list_size()
			== m_torrent_file-&gt;num_files())
		{
			int num_files = m_torrent_file-&gt;num_files();
			m_file_priority.resize(num_files);
			for (int i = 0; i &lt; num_files; ++i)
				m_file_priority[i] = file_priority-&gt;list_int_value_at(i, 1);
			// unallocated slots are assumed to be priority 1, so cut off any
			// trailing ones
			int end_range = num_files - 1;
			for (; end_range &gt;= 0; --end_range) if (m_file_priority[end_range] != 1) break;
			m_file_priority.resize(end_range + 1);

			update_piece_priorities();
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(79)">src/torrent.cpp:6222</a></td><td>if this is a merkle torrent and we can't restore the tree, we need to wipe all the bits in the have array, but not necessarily we might want to do a full check to see if we have all the pieces. This is low priority since almost no one uses merkle torrents</td></tr><tr id="79" style="display: none;" colspan="3"><td colspan="3"><h2>if this is a merkle torrent and we can't
restore the tree, we need to wipe all the
bits in the have array, but not necessarily
we might want to do a full check to see if we have
all the pieces. This is low priority since almost
no one uses merkle torrents</h2><h4>src/torrent.cpp:6222</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">				add_web_seed(url, web_seed_entry::http_seed);
			}
		}

		if (m_torrent_file-&gt;is_merkle_torrent())
		{
			lazy_entry const* mt = rd.dict_find_string("merkle tree");
			if (mt)
			{
				std::vector&lt;sha1_hash&gt; tree;
				tree.resize(m_torrent_file-&gt;merkle_tree().size());
				std::memcpy(&amp;tree[0], mt-&gt;string_ptr()
					, (std::min)(mt-&gt;string_length(), int(tree.size()) * 20));
				if (mt-&gt;string_length() &lt; int(tree.size()) * 20)
					std::memset(&amp;tree[0] + mt-&gt;string_length() / 20, 0
						, tree.size() - mt-&gt;string_length() / 20);
				m_torrent_file-&gt;set_merkle_tree(tree);
			}
			else
			{
<div style="background: #ffff00" width="100%">				TORRENT_ASSERT(false);
</div>			}
		}
	}

	boost::shared_ptr&lt;torrent_info&gt; torrent::get_torrent_copy()
	{
		if (!m_torrent_file-&gt;is_valid()) return boost::shared_ptr&lt;torrent_info&gt;();
		if (!need_loaded()) return boost::shared_ptr&lt;torrent_info&gt;();

		return m_torrent_file;
	}
	
	void torrent::write_resume_data(entry&amp; ret) const
	{
		using namespace libtorrent::detail; // for write_*_endpoint()
		ret["file-format"] = "libtorrent resume file";
		ret["file-version"] = 1;
		ret["libtorrent-version"] = LIBTORRENT_VERSION;

		ret["total_uploaded"] = m_total_uploaded;
		ret["total_downloaded"] = m_total_downloaded;

		ret["active_time"] = m_active_time;
		ret["finished_time"] = m_finished_time;
		ret["seeding_time"] = m_seeding_time;
		ret["last_seen_complete"] = m_last_seen_complete;

		ret["num_complete"] = m_complete;
		ret["num_incomplete"] = m_incomplete;
		ret["num_downloaded"] = m_downloaded;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(80)">src/torrent.cpp:6412</a></td><td>make this more generic to not just work if files have been renamed, but also if they have been merged into a single file for instance. using file_base</td></tr><tr id="80" style="display: none;" colspan="3"><td colspan="3"><h2>make this more generic to not just work if files have been
renamed, but also if they have been merged into a single file for instance.
using file_base</h2><h4>src/torrent.cpp:6412</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		pieces.resize(m_torrent_file-&gt;num_pieces());
		if (!has_picker())
		{
			std::memset(&amp;pieces[0], m_have_all, pieces.size());
		}
		else
		{
			for (int i = 0, end(pieces.size()); i &lt; end; ++i)
				pieces[i] = m_picker-&gt;have_piece(i) ? 1 : 0;
		}

		if (m_seed_mode)
		{
			TORRENT_ASSERT(m_verified.size() == pieces.size());
			TORRENT_ASSERT(m_verifying.size() == pieces.size());
			for (int i = 0, end(pieces.size()); i &lt; end; ++i)
				pieces[i] |= m_verified[i] ? 2 : 0;
		}

		// write renamed files
<div style="background: #ffff00" width="100%">		if (&amp;m_torrent_file-&gt;files() != &amp;m_torrent_file-&gt;orig_files()
</div>			&amp;&amp; m_torrent_file-&gt;files().num_files() == m_torrent_file-&gt;orig_files().num_files())
		{
			entry::list_type&amp; fl = ret["mapped_files"].list();
			for (torrent_info::file_iterator i = m_torrent_file-&gt;begin_files()
				, end(m_torrent_file-&gt;end_files()); i != end; ++i)
			{
				fl.push_back(m_torrent_file-&gt;files().file_path(*i));
			}
		}

		// write local peers

		std::back_insert_iterator&lt;entry::string_type&gt; peers(ret["peers"].string());
		std::back_insert_iterator&lt;entry::string_type&gt; banned_peers(ret["banned_peers"].string());
#if TORRENT_USE_IPV6
		std::back_insert_iterator&lt;entry::string_type&gt; peers6(ret["peers6"].string());
		std::back_insert_iterator&lt;entry::string_type&gt; banned_peers6(ret["banned_peers6"].string());
#endif

		// failcount is a 5 bit value
		int max_failcount = (std::min)(settings().get_int(settings_pack::max_failcount), 31);

		int num_saved_peers = 0;

		if (m_policy)
		{
			for (policy::const_iterator i = m_policy-&gt;begin_peer()
				, end(m_policy-&gt;end_peer()); i != end; ++i)
			{
				error_code ec;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(81)">src/torrent.cpp:8218</a></td><td>add a flag to ignore stats, and only care about resume data for content. For unchanged files, don't trigger a load of the metadata just to save an empty resume data file</td></tr><tr id="81" style="display: none;" colspan="3"><td colspan="3"><h2>add a flag to ignore stats, and only care about resume data for
content. For unchanged files, don't trigger a load of the metadata
just to save an empty resume data file</h2><h4>src/torrent.cpp:8218</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		if (m_complete != 0xffffff) seeds = m_complete;
		else seeds = m_policy ? m_policy-&gt;num_seeds() : 0;

		if (m_incomplete != 0xffffff) downloaders = m_incomplete;
		else downloaders = m_policy ? m_policy-&gt;num_peers() - m_policy-&gt;num_seeds() : 0;

		if (seeds == 0)
		{
			ret |= no_seeds;
			ret |= downloaders &amp; prio_mask;
		}
		else
		{
			ret |= ((1 + downloaders) * scale / seeds) &amp; prio_mask;
		}

		return ret;
	}

	// this is an async operation triggered by the client	
<div style="background: #ffff00" width="100%">	void torrent::save_resume_data(int flags)
</div>	{
		TORRENT_ASSERT(m_ses.is_single_thread());
		INVARIANT_CHECK;
	
		if (!valid_metadata())
		{
			alerts().post_alert(save_resume_data_failed_alert(get_handle()
				, errors::no_metadata));
			return;
		}

		if (!m_storage.get())
		{
			alerts().post_alert(save_resume_data_failed_alert(get_handle()
				, errors::destructing_torrent));
			return;
		}

		m_need_save_resume_data = false;
		m_last_saved_resume = m_ses.session_time();
		m_save_resume_flags = boost::uint8_t(flags);
		state_updated();

		TORRENT_ASSERT(m_storage);
		if (m_state == torrent_status::checking_files
			|| m_state == torrent_status::checking_resume_data)
		{
			if (!need_loaded())
			{
				alerts().post_alert(save_resume_data_failed_alert(get_handle()
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(82)">src/torrent.cpp:9033</a></td><td>go through the pieces we have and count the total number of downloaders we have. Only count peers that are interested in us since some peers might not send have messages for pieces we have it num_interested == 0, we need to pick a new piece</td></tr><tr id="82" style="display: none;" colspan="3"><td colspan="3"><h2>go through the pieces we have and count the total number
of downloaders we have. Only count peers that are interested in us
since some peers might not send have messages for pieces we have
it num_interested == 0, we need to pick a new piece</h2><h4>src/torrent.cpp:9033</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			}

			rarest_pieces.clear();
			rarest_rarity = pp.peer_count;
			rarest_pieces.push_back(i);
		}

		update_gauge();
		update_want_peers();

		// now, rarest_pieces is a list of all pieces that are the rarest ones.
		// and rarest_rarity is the number of peers that have the rarest pieces

		// if there's only a single peer that doesn't have the rarest piece
		// it's impossible for us to download one piece and upload it
		// twice. i.e. we cannot get a positive share ratio
		if (num_peers - rarest_rarity &lt; settings().get_int(settings_pack::share_mode_target)) return;

		// we might be able to do better than a share ratio of 2 if there are
		// enough downloaders of the pieces we already have.
<div style="background: #ffff00" width="100%">
</div>		// now, pick one of the rarest pieces to download
		int pick = random() % rarest_pieces.size();
		bool was_finished = is_finished();
		m_picker-&gt;set_piece_priority(rarest_pieces[pick], 1);
		update_gauge();
		update_peer_interest(was_finished);

		update_want_peers();
	}

	void torrent::refresh_explicit_cache(int cache_size)
	{
		TORRENT_ASSERT(m_ses.is_single_thread());
		if (!ready_for_connections()) return;

		if (m_abort) return;

		// rotate the cached pieces
		cache_status status;
		m_ses.disk_thread().get_cache_info(&amp;status, false, m_storage.get());

		// add blocks_per_piece / 2 in order to round to closest whole piece
		int blocks_per_piece = m_torrent_file-&gt;piece_length() / block_size();
		int num_cache_pieces = (cache_size + blocks_per_piece / 2) / blocks_per_piece;
		if (num_cache_pieces &gt; m_torrent_file-&gt;num_pieces())
			num_cache_pieces = m_torrent_file-&gt;num_pieces();

		std::vector&lt;int&gt; avail_vec;
		if (has_picker())
		{
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(83)">src/torrent_peer.cpp:178</a></td><td>how do we deal with our external address changing?</td></tr><tr id="83" style="display: none;" colspan="3"><td colspan="3"><h2>how do we deal with our external address changing?</h2><h4>src/torrent_peer.cpp:178</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		, is_v6_addr(false)
#endif
#if TORRENT_USE_I2P
		, is_i2p_addr(false)
#endif
		, on_parole(false)
		, banned(false)
		, supports_utp(true) // assume peers support utp
		, confirmed_supports_utp(false)
		, supports_holepunch(false)
		, web_seed(false)
#if defined TORRENT_DEBUG || TORRENT_RELEASE_ASSERTS
		, in_use(false)
#endif
	{
		TORRENT_ASSERT((src &amp; 0xff) == src);
	}

	boost::uint32_t torrent_peer::rank(external_ip const&amp; external, int external_port) const
	{
<div style="background: #ffff00" width="100%">		if (peer_rank == 0)
</div>			peer_rank = peer_priority(
				tcp::endpoint(external.external_address(this-&gt;address()), external_port)
				, tcp::endpoint(this-&gt;address(), this-&gt;port));
		return peer_rank;
	}

	boost::uint64_t torrent_peer::total_download() const
	{
		if (connection != 0)
		{
			TORRENT_ASSERT(prev_amount_download == 0);
			return connection-&gt;statistics().total_payload_download();
		}
		else
		{
			return boost::uint64_t(prev_amount_download) &lt;&lt; 10;
		}
	}

	boost::uint64_t torrent_peer::total_upload() const
	{
		if (connection != 0)
		{
			TORRENT_ASSERT(prev_amount_upload == 0);
			return connection-&gt;statistics().total_payload_upload();
		}
		else
		{
			return boost::uint64_t(prev_amount_upload) &lt;&lt; 10;
		}
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(84)">src/udp_tracker_connection.cpp:550</a></td><td>it would be more efficient to not use a string here. however, the problem is that some trackers will respond with actual strings. For example i2p trackers</td></tr><tr id="84" style="display: none;" colspan="3"><td colspan="3"><h2>it would be more efficient to not use a string here.
however, the problem is that some trackers will respond
with actual strings. For example i2p trackers</h2><h4>src/udp_tracker_connection.cpp:550</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		}

		boost::shared_ptr&lt;request_callback&gt; cb = requester();
#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_LOGGING
		if (cb)
		{
			boost::shared_ptr&lt;request_callback&gt; cb = requester();
			cb-&gt;debug_log("&lt;== UDP_TRACKER_RESPONSE [ url: %s ]", tracker_req().url.c_str());
		}
#endif

		if (!cb)
		{
			close();
			return true;
		}

		std::vector&lt;peer_entry&gt; peer_list;
		for (int i = 0; i &lt; num_peers; ++i)
		{
<div style="background: #ffff00" width="100%">			peer_entry e;
</div>			char ip_string[100];
			unsigned int a = detail::read_uint8(buf);
			unsigned int b = detail::read_uint8(buf);
			unsigned int c = detail::read_uint8(buf);
			unsigned int d = detail::read_uint8(buf);
			snprintf(ip_string, 100, "%u.%u.%u.%u", a, b, c, d);
			e.ip = ip_string;
			e.port = detail::read_uint16(buf);
			e.pid.clear();
			peer_list.push_back(e);
		}

		std::list&lt;address&gt; ip_list;
		for (std::list&lt;tcp::endpoint&gt;::const_iterator i = m_endpoints.begin()
			, end(m_endpoints.end()); i != end; ++i)
		{
			ip_list.push_back(i-&gt;address());
		}

		cb-&gt;tracker_response(tracker_req(), m_target.address(), ip_list
			, peer_list, interval, min_interval, complete, incomplete, 0, address(), "" /*trackerid*/);

		close();
		return true;
	}

	bool udp_tracker_connection::on_scrape_response(char const* buf, int size)
	{
		restart_read_timeout();
		int action = detail::read_int32(buf);
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(85)">src/ut_metadata.cpp:319</a></td><td>we really need to increment the refcounter on the torrent while this buffer is still in the peer's send buffer</td></tr><tr id="85" style="display: none;" colspan="3"><td colspan="3"><h2>we really need to increment the refcounter on the torrent
while this buffer is still in the peer's send buffer</h2><h4>src/ut_metadata.cpp:319</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">				if (!m_tp.need_loaded()) return;
				metadata = m_tp.metadata().begin + offset;
				metadata_piece_size = (std::min)(
					int(m_tp.get_metadata_size() - offset), 16 * 1024);
				TORRENT_ASSERT(metadata_piece_size &gt; 0);
				TORRENT_ASSERT(offset &gt;= 0);
				TORRENT_ASSERT(offset + metadata_piece_size &lt;= int(m_tp.get_metadata_size()));
			}

			char msg[200];
			char* header = msg;
			char* p = &amp;msg[6];
			int len = bencode(p, e);
			int total_size = 2 + len + metadata_piece_size;
			namespace io = detail;
			io::write_uint32(total_size, header);
			io::write_uint8(bt_peer_connection::msg_extended, header);
			io::write_uint8(m_message_index, header);

			m_pc.send_buffer(msg, len + 6);
<div style="background: #ffff00" width="100%">			if (metadata_piece_size) m_pc.append_const_send_buffer(
</div>				metadata, metadata_piece_size);

			m_pc.ses().inc_stats_counter(counters::num_outgoing_extended);
			m_pc.ses().inc_stats_counter(counters::num_outgoing_metadata);
		}

		virtual bool on_extended(int length
			, int extended_msg, buffer::const_interval body)
		{
			if (extended_msg != 2) return false;
			if (m_message_index == 0) return false;

			if (length &gt; 17 * 1024)
			{
#ifdef TORRENT_VERBOSE_LOGGING
				m_pc.peer_log("&lt;== UT_METADATA [ packet too big %d ]", length);
#endif
				m_pc.disconnect(errors::invalid_metadata_message, peer_connection_interface::op_bittorrent, 2);
				return true;
			}

			if (!m_pc.packet_finished()) return true;

			int len;
			entry msg = bdecode(body.begin, body.end, len);
			if (msg.type() == entry::undefined_t)
			{
#ifdef TORRENT_VERBOSE_LOGGING
				m_pc.peer_log("&lt;== UT_METADATA [ not a dictionary ]");
#endif
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(86)">src/web_connection_base.cpp:76</a></td><td>introduce a web-seed default class which has a low download priority</td></tr><tr id="86" style="display: none;" colspan="3"><td colspan="3"><h2>introduce a web-seed default class which has a low download priority</h2><h4>src/web_connection_base.cpp:76</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	web_connection_base::web_connection_base(
		aux::session_interface&amp; ses
		, aux::session_settings const&amp; sett
		, buffer_allocator_interface&amp; allocator
		, disk_interface&amp; disk_thread
		, boost::weak_ptr&lt;torrent&gt; t
		, boost::shared_ptr&lt;socket_type&gt; s
		, web_seed_entry&amp; web)
		: peer_connection(ses, sett, allocator, disk_thread, ses.get_io_service()
			, t, s, web.endpoint, &amp;web.peer_info)
		, m_parser(http_parser::dont_parse_chunks)
		, m_external_auth(web.auth)
		, m_extra_headers(web.extra_headers)
		, m_first_request(true)
		, m_ssl(false)
		, m_body_start(0)
	{
		INVARIANT_CHECK;

		// we only want left-over bandwidth
<div style="background: #ffff00" width="100%">		
</div>		// since this is a web seed, change the timeout
		// according to the settings.
		set_timeout(m_settings.get_int(settings_pack::urlseed_timeout));

		std::string protocol;
		error_code ec;
		boost::tie(protocol, m_basic_auth, m_host, m_port, m_path)
			= parse_url_components(web.url, ec);
		TORRENT_ASSERT(!ec);

		if (m_port == -1 &amp;&amp; protocol == "http")
			m_port = 80;

#ifdef TORRENT_USE_OPENSSL
		if (protocol == "https")
		{
			m_ssl = true;
			if (m_port == -1) m_port = 443;
		}
#endif

		if (!m_basic_auth.empty())
			m_basic_auth = base64encode(m_basic_auth);

		m_server_string = "URL seed @ ";
		m_server_string += m_host;
	}

	void web_connection_base::start()
	{
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(87)">include/libtorrent/add_torrent_params.hpp:133</a></td><td>this should not be a pointer</td></tr><tr id="87" style="display: none;" colspan="3"><td colspan="3"><h2>this should not be a pointer</h2><h4>include/libtorrent/add_torrent_params.hpp:133</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			flag_sequential_download = 0x800,
			flag_pinned = 0x1000,

			default_flags = flag_update_subscribe | flag_auto_managed | flag_paused | flag_apply_ip_filter
#ifndef TORRENT_NO_DEPRECATE
			, flag_ignore_flags = 0x80000000
#endif
		};
	
		// libtorrent version. Used for forward binary compatibility
		int version;
		boost::shared_ptr&lt;torrent_info&gt; ti;
#ifndef TORRENT_NO_DEPRECATE
		char const* tracker_url;
#endif
		std::vector&lt;std::string&gt; trackers;
		std::vector&lt;std::pair&lt;std::string, int&gt; &gt; dht_nodes;
		sha1_hash info_hash;
		std::string name;
		std::string save_path;
<div style="background: #ffff00" width="100%">		std::vector&lt;char&gt;* resume_data;
</div>		storage_mode_t storage_mode;
		storage_constructor_type storage;
		void* userdata;
		std::vector&lt;boost::uint8_t&gt; const* file_priorities;
		std::string trackerid;
		std::string url;
		std::string uuid;
		std::string source_feed_url;
		boost::uint64_t flags;
#ifndef TORRENT_NO_DEPRECATE
		bool seed_mode;
		bool override_resume_data;
		bool upload_mode;
		bool share_mode;
		bool apply_ip_filter;
		bool paused;
		bool auto_managed;
		bool duplicate_is_error;
		bool merge_resume_trackers;
#endif
		// -1 means unlimited on these settings
		// just like their counterpart functions
		// on torrent_handle
		int max_uploads;
		int max_connections;
		int upload_limit;
		int download_limit;
	};
}

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(88)">include/libtorrent/bitfield.hpp:308</a></td><td>make this operate on words instead of bytes. i.e. uintptr_t probably</td></tr><tr id="88" style="display: none;" colspan="3"><td colspan="3"><h2>make this operate on words instead of bytes. i.e. uintptr_t probably</h2><h4>include/libtorrent/bitfield.hpp:308</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			{
				m_bytes = (unsigned char*)std::malloc(b);
				m_own = true;
			}
			m_size = bits;
			clear_trailing_bits();
		}

		void free() { dealloc(); m_size = 0; }

	private:

		void clear_trailing_bits()
		{
			// clear the tail bits in the last byte
			if (m_size &amp; 7) m_bytes[(m_size + 7) / 8 - 1] &amp;= 0xff &lt;&lt; (8 - (m_size &amp; 7));
		}

		void dealloc() { if (m_own) std::free(m_bytes); m_bytes = 0; }

<div style="background: #ffff00" width="100%">		unsigned char* m_bytes;
</div>		int m_size:31; // in bits
		bool m_own:1;
	};

}

#endif // TORRENT_BITFIELD_HPP_INCLUDED

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(89)">include/libtorrent/block_cache.hpp:209</a></td><td>make this 32 bits and to count seconds since the block cache was created</td></tr><tr id="89" style="display: none;" colspan="3"><td colspan="3"><h2>make this 32 bits and to count seconds since the block cache was created</h2><h4>include/libtorrent/block_cache.hpp:209</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		bool operator==(cached_piece_entry const&amp; rhs) const
		{ return storage.get() == rhs.storage.get() &amp;&amp; piece == rhs.piece; }

		// if this is set, we'll be calculating the hash
		// for this piece. This member stores the interim
		// state while we're calulcating the hash.
		partial_hash* hash;

		// set to a unique identifier of a peer that last
		// requested from this piece.
		void* last_requester;

		// the pointers to the block data. If this is a ghost
		// cache entry, there won't be any data here
		boost::shared_array&lt;cached_block_entry&gt; blocks;

		// the last time a block was written to this piece
		// plus the minimum amount of time the block is guaranteed
		// to stay in the cache
<div style="background: #ffff00" width="100%">		ptime expire;
</div>
		boost::uint64_t piece:22;

		// the number of dirty blocks in this piece
		boost::uint64_t num_dirty:14;
		
		// the number of blocks in the cache for this piece
		boost::uint64_t num_blocks:14;

		// the total number of blocks in this piece (and the number
		// of elements in the blocks array)
		boost::uint64_t blocks_in_piece:14;

		// ---- 64 bit boundary ----

		// while we have an outstanding async hash operation
		// working on this piece, 'hashing' is set to 1
		// When the operation returns, this is set to 0.
		boost::uint32_t hashing:1;

		// if we've completed at least one hash job on this
		// piece, and returned it. This is set to one
		boost::uint32_t hashing_done:1;

		// if this is true, whenever refcount hits 0, 
		// this piece should be deleted
		boost::uint32_t marked_for_deletion:1;

		// this is set to true once we flush blocks past
		// the hash cursor. Once this happens, there's
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(90)">include/libtorrent/config.hpp:346</a></td><td>Make this count Unicode characters instead of bytes on windows</td></tr><tr id="90" style="display: none;" colspan="3"><td colspan="3"><h2>Make this count Unicode characters instead of bytes on windows</h2><h4>include/libtorrent/config.hpp:346</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">#define TORRENT_USE_WRITEV 0
#define TORRENT_USE_READV 0

#else
#warning unknown OS, assuming BSD
#define TORRENT_BSD
#endif

#if defined __GNUC__ &amp;&amp; !(defined TORRENT_USE_OSATOMIC \
	|| defined TORRENT_USE_INTERLOCKED_ATOMIC \
	|| defined TORRENT_USE_BEOS_ATOMIC \
	|| defined TORRENT_USE_SOLARIS_ATOMIC)
// atomic operations in GCC were introduced in 4.1.1
# if (__GNUC__ &gt;= 4 &amp;&amp; __GNUC_MINOR__ &gt;= 1 &amp;&amp; __GNUC_PATCHLEVEL__ &gt;= 1) || __GNUC__ &gt; 4
#  define TORRENT_USE_GCC_ATOMIC 1
# endif
#endif

// on windows, NAME_MAX refers to Unicode characters
// on linux it refers to bytes (utf-8 encoded)
<div style="background: #ffff00" width="100%">
</div>// windows
#if defined FILENAME_MAX
#define TORRENT_MAX_PATH FILENAME_MAX

// beos
#elif defined B_PATH_NAME_LENGTH
#define TORRENT_MAX_PATH B_PATH_NAME_LENGTH

// solaris
#elif defined MAXPATH
#define TORRENT_MAX_PATH MAXPATH

// posix
#elif defined NAME_MAX
#define TORRENT_MAX_PATH NAME_MAX

// none of the above
#else
// this is the maximum number of characters in a
// path element / filename on windows
#define TORRENT_MAX_PATH 255
#warning unknown platform, assuming the longest path is 255

#endif

#if defined TORRENT_WINDOWS &amp;&amp; !defined TORRENT_MINGW

#include &lt;stdarg.h&gt;

inline int snprintf(char* buf, int len, char const* fmt, ...)
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(91)">include/libtorrent/debug.hpp:166</a></td><td>rewrite this class to use FILE* instead and have a printf-like interface</td></tr><tr id="91" style="display: none;" colspan="3"><td colspan="3"><h2>rewrite this class to use FILE* instead and
have a printf-like interface</h2><h4>include/libtorrent/debug.hpp:166</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">#endif
}

#if defined TORRENT_VERBOSE_LOGGING || defined TORRENT_LOGGING || defined TORRENT_ERROR_LOGGING

#include &lt;cstring&gt;
#include "libtorrent/config.hpp"
#include "libtorrent/file.hpp"
#include "libtorrent/thread.hpp"

#if TORRENT_USE_IOSTREAM
#include &lt;string&gt;
#include &lt;fstream&gt;
#include &lt;iostream&gt;
#endif

namespace libtorrent
{
	// DEBUG API
	
<div style="background: #ffff00" width="100%">	struct logger
</div>	{
#if TORRENT_USE_IOSTREAM
		// all log streams share a single file descriptor
		// and re-opens the file for each log line
		// these members are defined in session_impl.cpp
		static std::ofstream log_file;
		static std::string open_filename;
		static mutex file_mutex;
#endif

		~logger()
		{
			mutex::scoped_lock l(file_mutex);
			log_file.close();
			open_filename.clear();
		}

		logger(std::string const&amp; logpath, std::string const&amp; filename
			, int instance, bool append)
		{
			char log_name[512];
			snprintf(log_name, sizeof(log_name), "libtorrent_logs%d", instance);
			std::string dir(complete(combine_path(combine_path(logpath, log_name), filename)) + ".log");
			error_code ec;
			if (!exists(parent_path(dir)))
				create_directories(parent_path(dir), ec);
			m_filename = dir;

			mutex::scoped_lock l(file_mutex);
			open(!append);
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(92)">include/libtorrent/disk_buffer_pool.hpp:138</a></td><td>try to remove the observers, only using the async_allocate handlers</td></tr><tr id="92" style="display: none;" colspan="3"><td colspan="3"><h2>try to remove the observers, only using the async_allocate handlers</h2><h4>include/libtorrent/disk_buffer_pool.hpp:138</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		// number of bytes per block. The BitTorrent
		// protocol defines the block size to 16 KiB.
		const int m_block_size;

		// number of disk buffers currently allocated
		int m_in_use;

		// cache size limit
		int m_max_use;

		// if we have exceeded the limit, we won't start
		// allowing allocations again until we drop below
		// this low watermark
		int m_low_watermark;

		// if we exceed the max number of buffers, we start
		// adding up callbacks to this queue. Once the number
		// of buffers in use drops below the low watermark,
		// we start calling these functions back
<div style="background: #ffff00" width="100%">		std::vector&lt;boost::shared_ptr&lt;disk_observer&gt; &gt; m_observers;
</div>
		// these handlers are executed when a new buffer is available
		std::vector&lt;handler_t&gt; m_handlers;

		// callback used to tell the cache it needs to free up some blocks
		boost::function&lt;void()&gt; m_trigger_cache_trim;

		// set to true to throttle more allocations
		bool m_exceeded_max_size;

		// this is the main thread io_service. Callbacks are
		// posted on this in order to have them execute in
		// the main thread.
		io_service&amp; m_ios;

	private:

		void check_buffer_level(mutex::scoped_lock&amp; l);

		mutable mutex m_pool_mutex;

		int m_cache_buffer_chunk_size;
		bool m_lock_disk_cache;

#if TORRENT_HAVE_MMAP
		// the file descriptor of the cache mmap file
		int m_cache_fd;
		// the pointer to the block of virtual address space
		// making up the mmapped cache space
		char* m_cache_pool;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(93)">include/libtorrent/peer_connection.hpp:738</a></td><td>factor this out into its own class with a virtual interface torrent and session should implement this interface</td></tr><tr id="93" style="display: none;" colspan="3"><td colspan="3"><h2>factor this out into its own class with a virtual interface
torrent and session should implement this interface</h2><h4>include/libtorrent/peer_connection.hpp:738</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		void normalize_receive_buffer();
		void set_soft_packet_size(int size) { m_soft_packet_size = size; }

		// if allow_encrypted is false, and the torrent 'ih' turns out
		// to be an encrypted torrent (AES-256 encrypted) the peer will
		// be disconnected. This is to prevent non-encrypted peers to
		// attach to an encrypted torrent
		void attach_to_torrent(sha1_hash const&amp; ih, bool allow_encrypted);

		bool verify_piece(peer_request const&amp; p) const;

		void update_desired_queue_size();

		// number of bytes this peer can send and receive
		int m_quota[2];

	private:
		// statistics about upload and download speeds
		// and total amount of uploads and downloads for
		// this peer
<div style="background: #ffff00" width="100%">		stat m_statistics;
</div>	protected:

		// a back reference to the session
		// the peer belongs to.
		aux::session_interface&amp; m_ses;

		// the disk thread to use to issue disk jobs to
		disk_interface&amp; m_disk_thread;

		// settings that apply to this peer
		aux::session_settings const&amp; m_settings;
		
		// used to allocate and free disk buffers
		buffer_allocator_interface&amp; m_allocator;

		// io service
		io_service&amp; m_ios;

		// called from the main loop when this connection has any
		// work to do.
		void on_send_data(error_code const&amp; error
			, std::size_t bytes_transferred);
		void on_receive_data(error_code const&amp; error
			, std::size_t bytes_transferred);

		// _nb means null_buffers. i.e. we just know the socket is
		// readable at this point, we don't know how much has been received
		void on_receive_data_nb(error_code const&amp; error
			, std::size_t bytes_transferred);

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(94)">include/libtorrent/peer_connection_interface.hpp:45</a></td><td>make this interface smaller!</td></tr><tr id="94" style="display: none;" colspan="3"><td colspan="3"><h2>make this interface smaller!</h2><h4>include/libtorrent/peer_connection_interface.hpp:45</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.

*/

#ifndef TORRENT_PEER_CONNECTION_INTERFACE_HPP
#define TORRENT_PEER_CONNECTION_INTERFACE_HPP

#include "libtorrent/socket.hpp"
#include "libtorrent/error_code.hpp"

namespace libtorrent
{
	struct torrent_peer;
	class stat;
	struct peer_info;

<div style="background: #ffff00" width="100%">	struct peer_connection_interface
</div>	{
		// these constants are used to identify the operation
		// that failed, causing a peer to disconnect
		enum operation_t
		{
			// this is used when the bittorrent logic
			// determines to disconnect
			op_bittorrent = 0,
			op_iocontrol,
			op_getpeername,
			op_getname,
			op_alloc_recvbuf,
			op_alloc_sndbuf,
			op_file_write,
			op_file_read,
			op_file,
			op_sock_write,
			op_sock_read,
			op_sock_open,
			op_sock_bind,
			op_available,
			op_encryption,
			op_connect,
			op_ssl_handshake,
		};

		virtual tcp::endpoint const&amp; remote() const = 0;
		virtual tcp::endpoint local_endpoint() const = 0;
		virtual void disconnect(error_code const&amp; ec, operation_t op, int error = 0) = 0;
		virtual peer_id const&amp; pid() const = 0;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(95)">include/libtorrent/performance_counters.hpp:130</a></td><td>should keepalives be in here too? how about dont-have, share-mode, upload-only</td></tr><tr id="95" style="display: none;" colspan="3"><td colspan="3"><h2>should keepalives be in here too?
how about dont-have, share-mode, upload-only</h2><h4>include/libtorrent/performance_counters.hpp:130</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			// a connect candidate
			connection_attempt_loops,
			// successful incoming connections (not rejected for any reason)
			incoming_connections,

			// counts events where the network
			// thread wakes up
			on_read_counter,
			on_write_counter,
			on_tick_counter,
			on_lsd_counter,
			on_lsd_peer_counter,
			on_udp_counter,
			on_accept_counter,
			on_disk_queue_counter,
			on_disk_counter,

			torrent_evicted_counter,

			// bittorrent message counters
<div style="background: #ffff00" width="100%">			num_incoming_choke,
</div>			num_incoming_unchoke,
			num_incoming_interested,
			num_incoming_not_interested,
			num_incoming_have,
			num_incoming_bitfield,
			num_incoming_request,
			num_incoming_piece,
			num_incoming_cancel,
			num_incoming_dht_port,
			num_incoming_suggest,
			num_incoming_have_all,
			num_incoming_have_none,
			num_incoming_reject,
			num_incoming_allowed_fast,
			num_incoming_ext_handshake,
			num_incoming_pex,
			num_incoming_metadata,
			num_incoming_extended,

			num_outgoing_choke,
			num_outgoing_unchoke,
			num_outgoing_interested,
			num_outgoing_not_interested,
			num_outgoing_have,
			num_outgoing_bitfield,
			num_outgoing_request,
			num_outgoing_piece,
			num_outgoing_cancel,
			num_outgoing_dht_port,
			num_outgoing_suggest,
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(96)">include/libtorrent/performance_counters.hpp:283</a></td><td>some space could be saved here by making gauges 32 bits</td></tr><tr id="96" style="display: none;" colspan="3"><td colspan="3"><h2>some space could be saved here by making gauges 32 bits</h2><h4>include/libtorrent/performance_counters.hpp:283</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			dht_nodes,
			dht_node_cache,
			dht_torrents,
			dht_peers,
			dht_immutable_data,
			dht_mutable_data,
			dht_allocated_observers,

			num_counters,
			num_gauge_counters = num_counters - num_stats_counters
		};

		counters();
		void inc_stats_counter(int c, int value = 1);
		boost::int64_t operator[](int i) const;

		void set_value(int c, int value);

	private:

<div style="background: #ffff00" width="100%">		boost::int64_t m_stats_counter[num_counters];
</div>
	};
}

#endif

</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(97)">include/libtorrent/piece_picker.hpp:671</a></td><td>should this be allocated lazily?</td></tr><tr id="97" style="display: none;" colspan="3"><td colspan="3"><h2>should this be allocated lazily?</h2><h4>include/libtorrent/piece_picker.hpp:671</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		// the following vectors are mutable because they sometimes may
		// be updated lazily, triggered by const functions

		// this vector contains all piece indices that are pickable
		// sorted by priority. Pieces are in random random order
		// among pieces with the same priority
		mutable std::vector&lt;int&gt; m_pieces;

		// these are indices to the priority boundries inside
		// the m_pieces vector. priority 0 always start at
		// 0, priority 1 starts at m_priority_boundries[0] etc.
		mutable std::vector&lt;int&gt; m_priority_boundries;

		// this maps indices to number of peers that has this piece and
		// index into the m_piece_info vectors.
		// piece_pos::we_have_index means that we have the piece, so it
		// doesn't exist in the piece_info buckets
		// pieces with the filtered flag set doesn't have entries in
		// the m_piece_info buckets either
<div style="background: #ffff00" width="100%">		mutable std::vector&lt;piece_pos&gt; m_piece_map;
</div>
		// each piece that's currently being downloaded
		// has an entry in this list with block allocations.
		// i.e. it says wich parts of the piece that
		// is being downloaded. This list is ordered
		// by piece index to make lookups efficient
		// there are 3 buckets of downloading pieces, each
		// is individually sorted by piece index.
		// 0: downloading pieces with unrequested blocks
		// 1: downloading pieces where every block is busy
		//    and some are still in the requested state
		// 2: downloading pieces where every block is
		//    finished or writing
		// 3: partial pieces whose priority is 0
		enum { num_download_categories = 4 };
		std::vector&lt;downloading_piece&gt; m_downloads[num_download_categories];

		// this holds the information of the
		// blocks in partially downloaded pieces.
		// the downloading_piece::info pointers
		// point into this vector for its storage
		std::vector&lt;block_info&gt; m_block_info;

		int m_blocks_per_piece;
		int m_blocks_in_last_piece;

		// the number of filtered pieces that we don't already
		// have. total_number_of_pieces - number_of_pieces_we_have
		// - num_filtered is supposed to the number of pieces
		// we still want to download
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(98)">include/libtorrent/proxy_base.hpp:152</a></td><td>it would be nice to remember the bind port and bind once we know where the proxy is m_sock.bind(endpoint, ec);</td></tr><tr id="98" style="display: none;" colspan="3"><td colspan="3"><h2>it would be nice to remember the bind port and bind once we know where the proxy is
m_sock.bind(endpoint, ec);</h2><h4>include/libtorrent/proxy_base.hpp:152</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">	{
		return m_sock.set_option(opt, ec);
	}

#ifndef BOOST_NO_EXCEPTIONS
	void bind(endpoint_type const&amp; endpoint)
	{
//		m_sock.bind(endpoint);
	}
#endif

	void bind(endpoint_type const&amp; endpoint, error_code&amp; ec)
	{
		// the reason why we ignore binds here is because we don't
		// (necessarily) yet know what address family the proxy
		// will resolve to, and binding to the wrong one would
		// break our connection attempt later. The caller here
		// doesn't necessarily know that we're proxying, so this
		// bind address is based on the final endpoint, not the
		// proxy.
<div style="background: #ffff00" width="100%">	}
</div>
#ifndef BOOST_NO_EXCEPTIONS
	void open(protocol_type const&amp; p)
	{
//		m_sock.open(p);
	}
#endif

	void open(protocol_type const&amp; p, error_code&amp; ec)
	{
		// we need to ignore this for the same reason as stated
		// for ignoring bind()
//		m_sock.open(p, ec);
	}

#ifndef BOOST_NO_EXCEPTIONS
	void close()
	{
		m_remote_endpoint = endpoint_type();
		m_sock.close();
		m_resolver.cancel();
	}
#endif

	void close(error_code&amp; ec)
	{
		m_remote_endpoint = endpoint_type();
		m_sock.close(ec);
		m_resolver.cancel();
	}
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(99)">include/libtorrent/settings_pack.hpp:980</a></td><td>deprecate this ``max_rejects`` is the number of piece requests we will reject in a row while a peer is choked before the peer is considered abusive and is disconnected.</td></tr><tr id="99" style="display: none;" colspan="3"><td colspan="3"><h2>deprecate this
``max_rejects`` is the number of piece requests we will reject in a row
while a peer is choked before the peer is considered abusive and is
disconnected.</h2><h4>include/libtorrent/settings_pack.hpp:980</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			auto_manage_startup,

			// ``seeding_piece_quota`` is the number of pieces to send to a peer,
			// when seeding, before rotating in another peer to the unchoke set.
			// It defaults to 3 pieces, which means that when seeding, any peer we've
			// sent more than this number of pieces to will be unchoked in favour of
			// a choked peer.
			seeding_piece_quota,

			// ``max_sparse_regions`` is a limit of the number of *sparse regions* in
			// a torrent. A sparse region is defined as a hole of pieces we have not
			// yet downloaded, in between pieces that have been downloaded. This is
			// used as a hack for windows vista which has a bug where you cannot
			// write files with more than a certain number of sparse regions. This
			// limit is not hard, it will be exceeded. Once it's exceeded, pieces
			// that will maintain or decrease the number of sparse regions are
			// prioritized. To disable this functionality, set this to 0. It defaults
			// to 0 on all platforms except windows.
			max_sparse_regions,

<div style="background: #ffff00" width="100%">			max_rejects,
</div>
			// ``recv_socket_buffer_size`` and ``send_socket_buffer_size`` specifies
			// the buffer sizes set on peer sockets. 0 (which is the default) means
			// the OS default (i.e. don't change the buffer sizes). The socket buffer
			// sizes are changed using setsockopt() with SOL_SOCKET/SO_RCVBUF and
			// SO_SNDBUFFER.
 			recv_socket_buffer_size,
			send_socket_buffer_size,

			// ``file_checks_delay_per_block`` is the number of milliseconds to sleep
			// in between disk read operations when checking torrents. This defaults
			// to 0, but can be set to higher numbers to slow down the rate at which
			// data is read from the disk while checking. This may be useful for
			// background tasks that doesn't matter if they take a bit longer, as long
			// as they leave disk I/O time for other processes.
			file_checks_delay_per_block,

			// ``read_cache_line_size`` is the number of blocks to read into the read
			// cache when a read cache miss occurs. Setting this to 0 is essentially
			// the same thing as disabling read cache. The number of blocks read
			// into the read cache is always capped by the piece boundry.
			// 
			// When a piece in the write cache has ``write_cache_line_size`` contiguous
			// blocks in it, they will be flushed. Setting this to 1 effectively
			// disables the write cache.
			read_cache_line_size,
			write_cache_line_size,

			// ``optimistic_disk_retry`` is the number of seconds from a disk write
			// errors occur on a torrent until libtorrent will take it out of the
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(100)">include/libtorrent/size_type.hpp:48</a></td><td>remove these and just use boost's types directly</td></tr><tr id="100" style="display: none;" colspan="3"><td colspan="3"><h2>remove these and just use boost's types directly</h2><h4>include/libtorrent/size_type.hpp:48</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.

*/

#ifndef TORRENT_SIZE_TYPE_HPP_INCLUDED
#define TORRENT_SIZE_TYPE_HPP_INCLUDED

#ifdef _MSC_VER
#pragma warning(push, 1)
#endif

#include &lt;boost/cstdint.hpp&gt;

#ifdef _MSC_VER
#pragma warning(pop)
#endif

namespace libtorrent
{
<div style="background: #ffff00" width="100%">	typedef boost::int64_t size_type;
</div>	typedef boost::uint64_t unsigned_size_type;
}


#endif
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(101)">include/libtorrent/torrent.hpp:1059</a></td><td>this wastes 5 bits per piece</td></tr><tr id="101" style="display: none;" colspan="3"><td colspan="3"><h2>this wastes 5 bits per piece</h2><h4>include/libtorrent/torrent.hpp:1059</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">
		// used for tracker announces
		deadline_timer m_tracker_timer;

		// this is the upload and download statistics for the whole torrent.
		// it's updated from all its peers once every second.
		libtorrent::stat m_stat;

		// -----------------------------

		// a back reference to the session
		// this torrent belongs to.
		aux::session_interface&amp; m_ses;

		// used to resolve hostnames for web seeds
		mutable tcp::resolver m_host_resolver;

		// this vector is allocated lazily. If no file priorities are
		// ever changed, this remains empty. Any unallocated slot
		// implicitly means the file has priority 1.
<div style="background: #ffff00" width="100%">		std::vector&lt;boost::uint8_t&gt; m_file_priority;
</div>
		// this vector contains the number of bytes completely
		// downloaded (as in passed-hash-check) in each file.
		// this lets us trigger on individual files completing
		// the vector is allocated lazily, when file progress
		// is first queried by the client
		std::vector&lt;boost::uint64_t&gt; m_file_progress;

		// these are the pieces we're currently
		// suggesting to peers.
		std::vector&lt;suggest_piece_t&gt; m_suggested_pieces;
		
		// the piece picker. This is allocated lazily. When we don't
		// have anything in the torrent (for instance, if it hasn't
		// been started yet) or if we have everything, there is no
		// picker. It's allocated on-demand the first time we need
		// it in torrent::need_picker(). In order to tell the
		// difference between having everything and nothing in
		// the case there is no piece picker, see m_have_all.
		boost::scoped_ptr&lt;piece_picker&gt; m_picker;

		std::vector&lt;announce_entry&gt; m_trackers;
		// this is an index into m_trackers

		struct time_critical_piece
		{
			// when this piece was first requested
			ptime first_requested;
			// when this piece was last requested
			ptime last_requested;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(102)">include/libtorrent/torrent.hpp:1142</a></td><td>These two bitfields should probably be coalesced into one</td></tr><tr id="102" style="display: none;" colspan="3"><td colspan="3"><h2>These two bitfields should probably be coalesced into one</h2><h4>include/libtorrent/torrent.hpp:1142</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		std::string m_source_feed_url;

		// this is used as temporary storage while downloading
		// the .torrent file from m_url
//		std::vector&lt;char&gt; m_torrent_file_buf;

		// this is a list of all pieces that we have announced
		// as having, without actually having yet. If we receive
		// a request for a piece in this list, we need to hold off
		// on responding until we have completed the piece and
		// verified its hash. If the hash fails, send reject to
		// peers with outstanding requests, and dont_have to other
		// peers. This vector is ordered, to make lookups fast.
		std::vector&lt;int&gt; m_predictive_pieces;

		// each bit represents a piece. a set bit means
		// the piece has had its hash verified. This
		// is only used in seed mode (when m_seed_mode
		// is true)

<div style="background: #ffff00" width="100%">		bitfield m_verified;
</div>		// this means there is an outstanding, async, operation
		// to verify each piece that has a 1
		bitfield m_verifying;

		// set if there's an error on this torrent
		error_code m_error;

		// used if there is any resume data
		boost::scoped_ptr&lt;resume_data_t&gt; m_resume_data;

		// if the torrent is started without metadata, it may
		// still be given a name until the metadata is received
		// once the metadata is received this field will no
		// longer be used and will be reset
		boost::scoped_ptr&lt;std::string&gt; m_name;

		storage_constructor_type m_storage_constructor;

		// the posix time this torrent was added and when
		// it was completed. If the torrent isn't yet
		// completed, m_completed_time is 0
		time_t m_added_time;
		time_t m_completed_time;

		// this was the last time _we_ saw a seed in this swarm
		time_t m_last_seen_complete;

		// this is the time last any of our peers saw a seed
		// in this swarm
		time_t m_swarm_last_seen_complete;
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(103)">include/libtorrent/torrent_info.hpp:113</a></td><td>include the number of peers received from this tracker, at last announce</td></tr><tr id="103" style="display: none;" colspan="3"><td colspan="3"><h2>include the number of peers received from this tracker, at last announce</h2><h4>include/libtorrent/torrent_info.hpp:113</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		std::string url;
		std::string trackerid;

		// if this tracker has returned an error or warning message
		// that message is stored here
		std::string message;

		// if this tracker failed the last time it was contacted
		// this error code specifies what error occurred
		error_code last_error;

		int next_announce_in() const;
		int min_announce_in() const;

		// the time of next tracker announce
		ptime next_announce;

		// no announces before this time
		ptime min_announce;

<div style="background: #ffff00" width="100%">
</div>		// if this tracker has returned scrape data, these fields are filled
		// in with valid numbers. Otherwise they are set to -1.
		// the number of current downloaders
		int scrape_incomplete;
		// the number of current seeds
		int scrape_complete;
		// the cumulative number of completed downloads, ever
		int scrape_downloaded;

		// the tier this tracker belongs to
		boost::uint8_t tier;

		// the number of times this tracker can fail
		// in a row before it's removed. 0 means unlimited
		boost::uint8_t fail_limit;

		// the number of times in a row this tracker has failed
		boost::uint8_t fails:7;

		// true if we're currently trying to announce with 
		// this tracker
		bool updating:1;

		enum tracker_source
		{
			source_torrent = 1,
			source_client = 2,
			source_magnet_link = 4,
			source_tex = 8
		};
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(104)">include/libtorrent/aux_/session_impl.hpp:399</a></td><td>move the login info into the tracker_request object</td></tr><tr id="104" style="display: none;" colspan="3"><td colspan="3"><h2>move the login info into the tracker_request object</h2><h4>include/libtorrent/aux_/session_impl.hpp:399</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">			void on_lsd_announce(error_code const&amp; e);

			// called when a port mapping is successful, or a router returns
			// a failure to map a port
			void on_port_mapping(int mapping, address const&amp; ip, int port
				, error_code const&amp; ec, int nat_transport);

			bool is_aborted() const { return m_abort; }
			bool is_paused() const { return m_paused; }

			void pause();
			void resume();

			void set_ip_filter(ip_filter const&amp; f);
			ip_filter const&amp; get_ip_filter() const;
			
			void set_port_filter(port_filter const&amp; f);
			port_filter const&amp; get_port_filter() const;


<div style="background: #ffff00" width="100%">			void queue_tracker_request(tracker_request&amp; req
</div>				, std::string login, boost::weak_ptr&lt;request_callback&gt; c);

			// ==== peer class operations ====

			// implements session_interface
			void set_peer_classes(peer_class_set* s, address const&amp; a, int st);
			peer_class_pool const&amp; peer_classes() const { return m_classes; }
			peer_class_pool&amp; peer_classes() { return m_classes; }
			bool ignore_unchoke_slots_set(peer_class_set const&amp; set) const;
			int copy_pertinent_channels(peer_class_set const&amp; set
				, int channel, bandwidth_channel** dst, int max);
			int use_quota_overhead(peer_class_set&amp; set, int amount_down, int amount_up);
			bool use_quota_overhead(bandwidth_channel* ch, int channel, int amount);

			int create_peer_class(char const* name);
			void delete_peer_class(int cid);
			void set_peer_class_filter(ip_filter const&amp; f);
			ip_filter const&amp; get_peer_class_filter() const;
			
			void set_peer_class_type_filter(peer_class_type_filter f);
			peer_class_type_filter get_peer_class_type_filter();

			peer_class_info get_peer_class(int cid);
			void set_peer_class(int cid, peer_class_info const&amp; pci);

			bool is_listening() const;

#ifndef TORRENT_DISABLE_EXTENSIONS
			void add_extensions_to_torrent(
				boost::shared_ptr&lt;torrent&gt; const&amp; torrent_ptr, void* userdata);
</pre></td></tr><tr style="background: #ccc"><td>relevance&nbsp;0</td><td><a href="javascript:expand(105)">include/libtorrent/aux_/session_interface.hpp:198</a></td><td>it would be nice to not have this be part of session_interface</td></tr><tr id="105" style="display: none;" colspan="3"><td colspan="3"><h2>it would be nice to not have this be part of session_interface</h2><h4>include/libtorrent/aux_/session_interface.hpp:198</h4><pre style="background: #f6f6f6; border: solid 1px #ddd;">		virtual boost::uint16_t ssl_listen_port() const = 0;

		// used to (potentially) issue socket write calls onto multiple threads
		virtual void post_socket_job(socket_job&amp; j) = 0;

		// when binding outgoing connections, this provides a round-robin
		// port selection
		virtual int next_port() = 0;

		// load the specified torrent. also evict one torrent, except
		// for the one specified, if we are at the limit of loaded torrents
		virtual bool load_torrent(torrent* t) = 0;

		// bump the specified torrent to make it the most recently used one
		// in the torrent LRU (i.e. the least likely to get unloaded)
		virtual void bump_torrent(torrent* t, bool back = true) = 0;

		// ask for which interface and port to bind outgoing peer connections on
		virtual tcp::endpoint get_interface() const = 0;

<div style="background: #ffff00" width="100%">		virtual void set_proxy(proxy_settings const&amp; s) = 0;
</div>		virtual proxy_settings const&amp; proxy() const = 0;

#if TORRENT_USE_I2P
		virtual proxy_settings const&amp; i2p_proxy() const = 0;
		virtual char const* i2p_session() const = 0;
#endif

		virtual void prioritize_connections(boost::weak_ptr&lt;torrent&gt; t) = 0;

		virtual tcp::endpoint get_ipv6_interface() const = 0;
		virtual tcp::endpoint get_ipv4_interface() const = 0;

		virtual void trigger_auto_manage() = 0;

		virtual void apply_settings_pack(settings_pack* pack) = 0;
		virtual session_settings const&amp; settings() const = 0;

		virtual void queue_tracker_request(tracker_request&amp; req
			, std::string login, boost::weak_ptr&lt;request_callback&gt; c) = 0;

		// peer-classes
		virtual void set_peer_classes(peer_class_set* s, address const&amp; a, int st) = 0;
		virtual peer_class_pool const&amp; peer_classes() const = 0;
		virtual peer_class_pool&amp; peer_classes() = 0;
		virtual bool ignore_unchoke_slots_set(peer_class_set const&amp; set) const = 0;
		virtual int copy_pertinent_channels(peer_class_set const&amp; set
			, int channel, bandwidth_channel** dst, int max) = 0;
		virtual int use_quota_overhead(peer_class_set&amp; set, int amount_down, int amount_up) = 0;

		virtual bandwidth_manager* get_bandwidth_manager(int channel) = 0;
</pre></td></tr></table></body></html>